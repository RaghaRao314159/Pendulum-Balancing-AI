{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7c1b7128c0924db3bec98cb07aa59ba4",
    "deepnote_cell_height": 142,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# IIA project SF3: Machine Learning\n",
    "\n",
    "Easter 2025<br>\n",
    "Project Leader: Jose Miguel Hernandez Lobato (jmh233) and Carl E. Rasmussen (cer54)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "717aa16548f24207b3c7901600719bc9",
    "deepnote_cell_height": 1201,
    "deepnote_cell_type": "markdown",
    "owner_user_id": "61bef1ae-8549-4162-b989-01c78a3f94df"
   },
   "source": [
    "## Important dates\n",
    "\n",
    "Project start: __Friday May 16 2026 9:15am GMT+1 (UK summer time)__ \n",
    "\n",
    "Interim report deadline: __Friday 23 May 2025, 4pm__ (electronic submission via Moodle)\n",
    "\n",
    "(Interim report should contain report on tasks up to and including the linear modelling of the dynamics)\n",
    "\n",
    "Final project report deadline: __Friday 13 June 2025,  4pm__ (electronic submission via Moodle)\n",
    "\n",
    "\n",
    "## Project notes\n",
    "\n",
    "- You should spend about 20 hours a week on the project, basically half of your time.\n",
    "- Project is to be carried out on your own computer or here on Deepnote. You can download this notebook and use it with a normal Jupyter server, or duplicate it here in your Deepnote account. If you do the latter, you can share and show your work easily. The computational resources on Deepnote are limited, so you may find it more convenient to run the programs on your own computer in the later parts of the project. When you need to ask a question about a specific piece of code, you can still use the Deepnote system to share a notebook. \n",
    "- Make your own schedule. Help is available from the project leader during scheduled sessions:\n",
    "    - 9:15am -- 10:45am on Fridays in LR11 (except on 16 May, which will be in LT1 and on 6 June, which will be in CB-seminar room BE4-38).\n",
    "    - 2:00pm -- 3:30pm on Fridays in LR11 (except on 6 June, which will be in CB-seminar room BE4-38).\n",
    "    - 11:00am -- 12:30pm on Tuesdays in LR11.\n",
    "None of the sessions are compulsory, but you are strongly encouraged to seek verbal feedback after your interim report. \n",
    "- Project carries 80 marks overall:\n",
    "  - 20 marks for interim report\n",
    "  - 60 marks for final report \n",
    "- Project report\n",
    "  - Should be clearly broken down by _Tasks_ (see below), any notes you wish to make in how you structured and carried out the tasks, and most importantly your __results__ in the form of completely labelled graphs, and __accompanying conclusions__ you draw from your results. \n",
    "  - Should be maximum 12 pages (Interim report maximum 8 pages) when converted to a PDF (excluding appendices such as attached code, but _including_ figures). The final report can be an extension of the interim report, but make sure you take into account the feedback you receive for your interim report.  \n",
    "  - When deciding what to include in your report, how to organise it and what to emphasize, please prioritise communicating understanding over formalities - We would like give you marks for doing the right thing and showing that you did it and understand it. If we have to wade through pages of undigested data and graphs shown just because it was there, we will feel less generous. \n",
    "  - __All code__ that you used during your project must be included as a zip file in your submission. If you modified the `CartPole.py` file, include it. \n",
    "  - A jupyter or Deepnote notebook are acceptable as a report, as long as it is \"clean\" (its main section includes text and figures) and reads like a report, and can be converted to a PDF for the moodle upload.\n",
    "\n",
    "## Approximate Schedule\n",
    "\n",
    "- Week 1: Software tools, simulation of cart-pole system, linear modelling of dynamics\n",
    "  - Interim report (up to linear modelling)\n",
    "- Week 2: Nonlinear modelling of dynamics\n",
    "- Week 3: Linear control\n",
    "- Week 4: Sensitivity analysis\n",
    "  - Final report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b2030a29593d4b42b63785fcc337860c",
    "deepnote_cell_height": 70,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<IMG src=\"cartpole.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7b4f083698bf4061ae6c28b1eceab42e",
    "deepnote_cell_height": 118,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Week 1\n",
    "\n",
    "### Dynamical simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "50b37d1c9cd04b30ade77a23cf245f60",
    "deepnote_cell_height": 74,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Consider the inverted pendulum system (\"cartpole\") drawn above, familiar from the coursework of 3F2, with a freely moving cart and freely rotating pendulum attached to the cart, moving under the action of an external action force and gravity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a9ea957eecc2444989c449284040dea8",
    "deepnote_cell_height": 172,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "\n",
    "The equations of motion of the system are \n",
    "\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "3 \\ddot x \\cos \\theta  + 2 L \\ddot \\theta & = &  3 g \\sin \\theta - 6 \\mu_\\theta \\dot\\theta/mL\\\\\n",
    "(m+M) \\ddot x + \\frac12 m L\\ddot\\theta\\cos\\theta - \\frac12 mL{\\dot\\theta}^2 \\sin\\theta &=& F - \\mu_x \\dot x\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "where the stationary points are $\\theta=0$ (unstable) and $\\theta=\\pi$ (stable), and $F$ is the external _action_ (force) on the cart, $\\mu_x$ and $\\mu_\\theta$ are the friction coefficients of the cart and the pole, respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d31cfd474cca45dda804fbd2ffacf8ec",
    "deepnote_cell_height": 118,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "The state of the system is described by the following variables: position and velocity of the cart $x, \\dot x$, angle and angular velocity of the pole $\\theta, \\dot\\theta$, with the angle being periodic on $[-\\pi,\\pi]$. The center position of the cart corresponds to $x=0$, and the pole hanging vertically down corresponds to $\\theta=\\pi$. If you are interested in deriving the equations of motion for yourself, use Lagrange's equation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5ec5681a9c2342eb896becfd1c6f5f23",
    "deepnote_cell_height": 394,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### Task 1.1\n",
    "\n",
    "Study the code in the `CartPole.py` file, which creates a Python class to describe the system. Note the variables that describe the state of system, and the `performAction()` function that updates the state variables using the _Euler_ algorithm (it does a small number of steps), using a given force (which is the 'action') on the cart. Passing a zero value for the force corresponds to free dynamics. \n",
    "\n",
    "Write code to simulate a “rollout” (i.e. a run with specified initial condition simulated for a number of time steps) using the `performAction` function in a loop, starting from the stable equilibrium position and some nonzero initial cart velocity or angular velocity, and no applied force. Plot the resulting time evolution of the system variables. Vary the size of the initial velocities to realize different behaviours: simple oscillation around the stable equilibrium, and also the complete rotation of the pendulum. Useful ranges are as follows. Cart velocity: $[-10,10]$, pole angle: $[-\\pi,\\pi]$, pole (angular) velocity: $[-15,15]$.\n",
    "\n",
    "You can plot all variables as a function of time, and also pairs of variables against one another (similar to phase portraits).\n",
    "\n",
    "\n",
    "Note how the angle is used in the dynamics as a continous variable, rather than just in the range $[-\\pi,\\pi]$. There is a `remap_angle` function in the `CartPole` module that you can use to get the angle in the usual range. _This will be an important consideration later on when we develop models of the dynamics._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "28301c70d7a6484d911d51d9b0f4bf80",
    "deepnote_cell_height": 188,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Changes of state\n",
    "\n",
    "You know from 3F2 that a simple linear controller works for this system, as long as you know where the stationary point is, and have access to the equations of motion so that you can linearise them. But in general, we do not know the equations behind the evolution of a physical system, and so we will take a different approach. What do have are _observations_ of the time evolution of the system. So we will use the simulations like the ones you did above to gather data about the system, and develop a _model_ for this time evolution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "58b8d09826b14508b73e11cd9cafce6a",
    "deepnote_cell_height": 146,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "\n",
    "We will want to build a _model_ for the time evolution of the system. The model is a function $f(X)$ that takes the current state of the system, and maps it onto a new state, which is its prediction for the state at a later time. Let the state of the system be described by a vector X, given by\n",
    "\n",
    "$$\n",
    "X = [x, \\dot x, \\theta, \\dot \\theta]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "aa90b0615a794a28abcda01d0985d3eb",
    "deepnote_cell_height": 74,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Given the current state $X$, let us call $Y$ the state of the system after a single call to the `PerformAction` function (with 0.0 as the force argument, or no argument, which is equivalent). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c25e0f6a853a474e9f535371bab74acb",
    "deepnote_cell_height": 132,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### Task 1.2\n",
    "\n",
    "To investigate and visualise the functional relationship between $X$ and $Y$, initialise the system using a random value for all state variables, and then scan through one of the state variables in a suitable range (don't forget to reset all the state variables after each call to `PerformAction`), and plot $Y$ as a function of your scan. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "066769a15e7241a6843a329abffacd6a",
    "deepnote_cell_height": 278,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "You will observe that the relationship between $X$ and $Y$ as defined above is nearly linear, which is not surprising because the change in one step is small.\n",
    "\n",
    "We can take account of this and model the _change_ in state vector, rather than taking the new state vector itself as the target of our model. So we define the new target for the modelling as $Y\\equiv X(T)-X(0)$, where $X(t)$ represents the time evolution of the state under the dynamics, and T corresponds to a single call to `PerformAction`. Note that in principle we could model changes corresponding arbitrary time shifts, rather than a single call to `PerformAction`, but the longer the time shift, the more complex the model would have to be. \n",
    "\n",
    "Explore this new functional relationship again (i) using scans of single variables, and (ii) contour plots where you take slices of the data in two of the variables while you keep the other two variables fixed (the `tricontourf` function of `matplotlib` is very useful). One of the variables has no effect on the next step - which one? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "aa69f3fc19d84c4a9c80bc33921ecbe0",
    "deepnote_cell_height": 62,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b1cd60be654c4886857167deff44e526",
    "deepnote_cell_height": 124,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "\n",
    "The simplest model is a linear one, where the target $Y$ is assumed to be linear function of the current state $X$,\n",
    "$$\n",
    "f(X) = {\\bf C} X\n",
    "$$\n",
    "\n",
    "where ${\\bf C}$ is a $4\\times 4$ matrix of coefficients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "044568031d2c4dbd9ad012a19b656003",
    "deepnote_cell_height": 132,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### Task 1.3\n",
    "\n",
    "By initialising the simulator in a completely random state (using suitable ranges) and running it for _one_ step, gather data in the form of pairs of state vectors (X, Y), where X represents a state of the system at step $n$, so $X\\equiv X(n)$ and Y represent the change in state after a single call to `performAction` (with zero force), so $Y\\equiv X(n+1)-X(n)$. Start with 500 data points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "14af2954c1314c378ec9e09ca6c1f454",
    "deepnote_cell_height": 184,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Using your data set, do linear regression to find the optimal coefficient matrix. Test your predictions against the data. One way to plot the results is to put the input state variable on the horizontal axis and on the vertical axis put the predicted state variable (i.e. what should be the \"next step\") and the real next step. Another way is to put the target data (i.e. the real \"next step\") on the horizontal axis and the predicted \"next step\" on the vertical axis. In this latter plot, a perfect prediction would correspond to a perfect straight line. You should also repeat the \"scans\" from the previous task, and plot simultaneously the real change in state with your predicted change in state as a function of your scan. Which variables are predicted well by the linear model and which ones are not? Why ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0558e218ea264c83a24ae9a1ebcdd895",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### Task 1.4\n",
    "\n",
    "The true test of the model is not how it matches with the gathered data it was fit to, but whether it can predict the time evolution of the physical system. Iterate the model to predict the time evolution of the system, and compare using various initial conditions how accurate the predictions are with respect to the true dynamics started from the same initial conditions. (Note that the model is being used deterministically, with no noise added)\n",
    "\n",
    "Since your models above predict the _change_ in the state variable, the iterated time evolution is\n",
    "$$\n",
    "X_{n+1} \\leftarrow X_n + f(X_n)\n",
    "$$\n",
    "\n",
    "Plot the true time evolution of the system as well as that of your fitted models for many cycles, and for different initial conditions, including ones where the pole makes a full circle. \n",
    "\n",
    "_Angle range_ If you leave the angle without remapping, your solution with the iterated model will diverge. Why is that? Ensure that you remap the angle during the above iterations. (Note how remapping is not needed in the true dynamics, since that is nonlinear, and the angle only appears inside trigonometric functions that are periodic anyway)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "12d818f413fa4f82bf942f4a935fab75",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Week 2\n",
    "\n",
    "### Nonlinear model\n",
    "As you observed above, the linear model is not particularly good. In order to do better, we need nonlinear modelling. Next you are going to build a nonlinear model using a linear regression with nonlinear basis functions. Given a data set of (X,Y) pairs, the model function is given by\n",
    "\n",
    "$$\n",
    "f(X) = \\sum_i \\alpha_i K(X, X_i)\n",
    "$$\n",
    "\n",
    "where the sum runs over the basis functions, $\\alpha_i$ are the corresponding coefficients, and $K$ is a _kernel function_ that is used to define the nonlinear basis. The kernel function takes two arguments, the first one $X$ is the state vector where you evaluate the basis function, and the second argument, $X_i$ is another state vector which we use to place the basis function somewhere in the state space. To make the basis functions relevant, we take the set of locations $\\{X_i\\}$ to be a subset of the gathered data points.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e117a0b7e6de4a51abcfc06d593938ea",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "If you place a basis functions on every location at which you have data, the functional form above is equivalent to the mean of a _Gaussian process_ with covariance given by the kernel _K_. This view of the regression problem is particularly helpful if the data is stochastic, i.e. it has some noise component which we can model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d5a38b9560d548e58fd64a68d9a9ae4d",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "For the present problem, let us use a Gaussian kernel function,\n",
    "\n",
    "$$\n",
    "K(X,X') = e^{-\\sum_j \\frac{\\left(X^{(j)}-X'^{(j)}\\right)^2}{2\\sigma_j^2}}\n",
    "$$\n",
    "\n",
    "Here $X^{(j)}$ refers to the $j$th component of the state vector. There is one caveat for using this kernel function in our current situation: one of our state vector components, $\\theta$ is periodic. It helps quite a bit if we introduce this periodicity in our kernel function, and we can do that by using $\\sin^2\\left( (\\theta - \\theta')/2 \\right)$ in place of $\\left(\\theta -\\theta' \\right)^2$ in the part of the kernel function that corresponds to the angle variable (note the factor of 1/2 that ensures that the periodicity is $2\\pi$ and the kernel value remains between zero and one). The parameters $\\sigma_j$ are _length scale_ hyperparameters of the model, and need to be known, guessed or fitted. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "889416aee35f42808e682af08853111b",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "If we have $N$ data locations (each is an (X,Y) pair but remember that here X is a vector and Y is a scalar), substituting this data into the model functional form yields the following linear system\n",
    "\n",
    "$$\n",
    "K_{NN} \\alpha_N = Y_N\n",
    "$$\n",
    "\n",
    "where the subscript $N$ was used to emphasize the size of the array rather than an index. The unknown coefficients are collected into the vector $\\alpha_N$, the elements of the matrix are given by the kernel function, \n",
    "\n",
    "$$\n",
    "[K_{NN}]_{i,i'} = K(X_i,X_{i'})\n",
    "$$\n",
    "\n",
    "and $Y_N$ is a vector of the target function values. With Gaussian basis functions, the condition number of the matrix is enormous, and a direct solution of the above linear system would be rather unstable. One way to get around this is to _regularise_ the linear system. Tikhonov regularisation is to modify it to \n",
    "\n",
    "$$\n",
    "(K_{NN} + \\lambda I) \\alpha_N = Y_N\n",
    "$$\n",
    "with solution\n",
    "$$\n",
    "\\alpha_N = [K_{NN} + \\lambda I]^{-1} Y_N\n",
    "$$\n",
    "\n",
    "where $\\lambda$ is a parameter. The smaller the values of $\\lambda$, the closer is the fit to the data, but the more unstable the linear system. Interestingly, this is also exactly the form of the (mean) solution in the Gaussian process regression problem of inference in the presence of noisy input data, with the identification that $\\lambda$ is the variance of the data noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6be4f148f5eb4695835e3a15fdf11cfc",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Suppose we collected $N$ pairs of $(X,Y)$ data points, and we choose a subset $M$ of the $X$ locations to serve as basis function centres. The linear system is then not square:\n",
    "$$\n",
    "K_{NM} \\alpha_M = Y_N\n",
    "$$\n",
    "where again the subscripts indicate dimensions, $K_{MN}$ is an $M \\times N$ matrix with elements corresponding to the $M$ basis locations and all the $N$ data point locations. We have fewer unknown coefficients than data points, so the problem is over-determined. The least squares solution would be\n",
    "$$\n",
    "\\alpha_M = [K_{MN} K_{NM}]^{-1} K_{MN} Y_N\n",
    "$$\n",
    "i.e. using the pseudoinverse rather than the inverse. The matrix in square brackets could be badly conditioned, so again we may need to regularise. Interestingly, rather just adding a multiple of the identity matrix like in the square case, we can look to Gaussian process inference for a better idea. It turns out that a _sparse Gaussian process_ precisely corresponds to this case. There, the model is written as a conditional probability not on the original $N$ data values directly, but on the unknown function values at the $M$ data locations that are chosen for the basis function centers. The vector of linear coefficients of the fitted model are then given by \n",
    "\n",
    "$$\n",
    "\\alpha^{(j)}_M = \\left(K_{MN}K_{NM} + \\lambda K_{MM} \\right)^{-1} K_{MN}  Y_N^{(j)}\n",
    "$$\n",
    "\n",
    "where $K_{MM}$ is an $M \\times M$ matrix with elements that are given by the kernel function evaluated between the locations\n",
    "selected as basis locations. The interpretation of this is that the least squares system is Tikhonov regularised but the regulariser\n",
    "is evaluated in the kernel-norm, rather than the Euclidean norm. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d75014f741a947ceaa5aea242ef4e8b9",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "To apply all the above to the cartpole system, we have to create four separate models for the four components of the state vector, these are indexed by $j$. In the absence of a method to guide the selection of $\\lambda$, you need to experiment with a few different values (e.g. between 1E-6 and 1E-1, on a log scale) and see which one works better on validation data. You will also need to select the length scale parameters $\\sigma_j$ for each state variable. A reasonable value is the standard deviation of the state variable in your dataset.\n",
    "\n",
    "**Note: You should never use the `np.linalg.inv` function to invert the matrix when solving a linear system, because that can be\n",
    "numerically unstable for such ill-conditioned matrices, but instead use `np.linalg.lstsq`, which solves equations of the\n",
    "form $Ax=b$ directly in a least-squares sense.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "800ed2e56ba84b4dade7d982cedd6f6f",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### Task 2.1\n",
    "\n",
    "Fit a model of the system using the data you gathered earlier. Your target function could be either again the change in state after one step as before, or the _error of your linear model_ in the change in state. Verify using scatterplots that the nonlinear model indeed fits the data. Study the convergence of the model (i.e. the systematic reduction in error) as a function of increasing data amount, and the increasing number of basis functions (e.g. start with $M=10$ and increase by factors of 2, select the data locations for the basis randomly from the data). Also plot 2D slices of your target function and the fit, as well as do roll-outs to see how closely the iterated model matches the real dynamics for a wide range of sensible initial conditions. How long does your model show reasonable agreement with the real dynamics? Quantify this in units of time and also in the number of oscillation cycles. How does this correlate with the pointwise accuracy you measure on random test data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "76ea2af271784603aa70bfec22a7997e",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Gradient based hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "27666b2f3a6b4f04a38e746296b14175",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "A limitation of the previous models is that the hyper-parameter values for $\\lambda$ and the length scale parameters $\\sigma_j$ are chosen by trial and error given a few candidate values. Instead, tuning these hyper-parameters by gradient-based optimization is a better alternative. For this, we can use the python library jax:\n",
    "\n",
    "https://docs.jax.dev\n",
    "\n",
    "Jax offers efficient evaluation of gradients via its automatic differentiation transformations. By importing jax.numpy as jnp, we can replace most standard calls to numpy functions with their corresponding jax versions. For example, np.tanh becomes jnp.tanh, with the advantage that we can obtain a function that calculates the gradient of the operations done by our code right away through jax.grad. For example, to calculate the gradient of the tanh function we would use jax.grad(jnp.tanh) which returns a new function that calculates the gradient. \n",
    "\n",
    "Other advantages of jax include built-in Just-In-Time (JIT) compilation: through jax.jit we can compile the function for faster execution. For example, jax.jit(jax.grad(jnp.tanh)) returns a compiled function that would evaluate the gradient of the tanh function much faster than with standard python code. The first time the jitted function is called will be slow as jax has to compile the function, but subsequent calls will be very fast. Jax can also perform computations in CPU or GPU. Finally, JAX functions can be automatically vectorized to efficiently map them over arrays representing batches of inputs without having to use for loops. For example, if we have a python function test_func that operates over scalars, we can obtain a corresponding vectorized version of the function that operates on vectors by using jax.vmap(test_func). In this case, when evalauted over a vector, jax.vmap(test_func) will return a new vector of the same shape as the input vector and with each entry given by the evaluation of test_func on the corresponding entry of the input vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "542722eab86c4629a7b79bbba282f83d",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### Task 2.2\n",
    "\n",
    "In this task you will write the code for fitting your non-linear models in jax, doing gradient-based hyper-parameter optimization. For this, write a function that receives as input the hyper-paramteer values, fits the linear model on the training data, and returns the performance metric of the fitted model on validation data. For example, the mean squared error (or the negative log-likelihood if you are also learning the variance of Gaussian noise variables). Obtain the gradient of that function usin jax and call the optimizer scipy.optimize.minimize to find the optimal hyper-parameter values with the method \"L-BFGS-B\". Use reasonable initial values for each hyper-parameter together with sensible maximum and minimum thresholds for the possible values of each parameter. Report the resulting performance metrics on the validation data before and after the optimization. What are your optimal lengthscale values? Why do you think you obtained those values? Verify using scatterplots that the optimized model indeed fits the data better. Do roll-outs to see how closely the optimized model matches the real dynamics for a wide range of sensible initial conditions. How long does your model show reasonable agreement with the real dynamics? Quantify this in units of time and also in the number of oscillation cycles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6d3579068fad466d80a5c51e03b5e068",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Improved feature representation\n",
    "\n",
    "Despite the careful tuning of hyper-parameters, the previous models may not perform great. One of the main reasons is the difficulty in making predictions when we use as input feature the angle variable $\\theta$ whose effect is invariant to adding multiples of $2\\pi$ to it. While using $\\sin^2$ inside of our kernel function may help slightly, the $\\sin$ function is not enough to fully identify an angle value. A much better choice is to use as input features both the sine and cosine of the angle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0b67ff37791c44bebcc3417dbf22c1d4",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### Task 2.3\n",
    "\n",
    "Change your code to use the sine and cosine of the angle as input features for the nonlinear model and remove the $\\sin^2$ part inside the kernel function. Treat these sine and cosine features in the same way as the other features in the model. The output variables would be the same as before. Remove any call to the remap function as that will no longer be necessary. Refit your model again and evaluate its predictions as you did in task 2.2. Do the same for the linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e9e45692d6134262afdd7a5bef863034",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Week 3\n",
    "\n",
    "### Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8b2a167d01fa4208854a170069df5db1",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Having developed a good model for the dynamics, now it is time to control the system. In this exercise we will create a controller to achieve a desired state by parametrising the actions of the controller, and optimising those parameters through evaluation of the resulting performance. This is called _reinforcement learning_ in general. Using the interaction of the controller with the system to improve it is \"direct policy search\". There are many other, more sophisticated strategies.  \n",
    "\n",
    "When you call the `performAction` routine, it takes a signed scalar which is interpreted as an external force on the cart. The value is passed through the `tanh` function before being interpreted as a force, this prevents the application of excessively large forces (the transformation is controlled by the `max_force` variable inside the `CartPole` class.) The first thing you will need do is to modify your models (both the linear and nonlinear) to take account of this new state variable (i.e. your system now has 5 inputs, including the force F, and 4 outputs after a call to `performAction`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "dd613d25c4204f07a08680c3dd7f3cd8",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### Task 3.1\n",
    "Change your code so that the input vector now includes the action taken. Collect new data, again using random initial conditions and one step, but this time include the action. Verify using scatter-plots, 1D and 2D scans and roll-outs that your models can predict the change in the state variables. You will need to choose reasonable max and min values for the forces applied as otherwise, the system will behave in an unpredictable way. What are maximum and minimum forces that you can apply while your model still makes accurate predictions? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6da6f05b1231486ba66decf967181f86",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Policies\n",
    "\n",
    "A _policy_ is a function $p(X)$ that defines what the action should be given the other state variables. The  goal is to find a policy function that when enacted, gives rise to the desired behaviour, in this case the pole being balanced around its unstable equilibrium position. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ea1f706c53784b06a6f91b398113a19d",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Objective\n",
    "\n",
    "In order to optimize a policy, we need to define, mathematically, what we want to achieve. That is captured in an _objective function_ (also called _loss function_), a measure of how close we are to the desired behaviour. In the present case, we want the pole to be upright, so we could use the _loss function_\n",
    "\n",
    "$$\n",
    "l(X) = -\\cos\\theta\n",
    "$$\n",
    "\n",
    "But it is better, and more general, to define a _target state_, $X_0$, which we want the system to achieve, and use a loss function that increases when the distance of the state from the target is larger. The following loss function achieves this, \n",
    "\n",
    "$$\n",
    "l(X) = 1- e^{-|X-X_0|^2/2\\sigma_l^2}\n",
    "$$\n",
    "where $\\sigma_l$ is a scaling factor (you could introduce a separate one for each component of the state variable). The target state for the cartpole system is $X_0 = [0,0,0,0]$. The advantage of this form is that for large departures from the target, the loss is independent of the state. This expresses the notion that if the pole is far away from being upright and stationary, we do not much care what it is doing. The above loss functions are for a given state. We wish to keep the pole upright continuously, so the total loss of a trajectory should be a time integral (sum, in practice) of the pointwise loss of the state over some interval,\n",
    "\n",
    "$$\n",
    "L = \\sum_{i=1}^N l(X_i)\n",
    "$$\n",
    "\n",
    "The `CartPole` class contains a function to evaluate the above pointwise loss $l(X)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0ce356a9d1e44307bb3d6dc51e943249",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Linear control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "427ae8d8c3064e27a08760ea2a55a570",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "We start with defining a linear policy, \n",
    "\n",
    "$$\n",
    "p(X) = \\bf{p} \\cdot X\n",
    "$$\n",
    "\n",
    "with unknown coefficent vector ${\\bf p}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d7c61ce4909345fc9ebcad990a2e498f",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### Task 3.2\n",
    "\n",
    "Write code to evaluate the loss function for the trajectory of a rollout - use a short time horizon, but enough to capture 1-2 oscillation periods. Before any optimisation, _visualise_ the loss function as you vary some parameters in ${\\bf p}$, using similar 1D and 2D scans that you did for Task 1, i.e. varying just one or two elements of  ${\\bf p}$ and plotting the loss as a function of those elements. \n",
    "\n",
    "Given a fixed initial state, optimise the unknowns in the policy to minimise the loss function under the evolution given by the true model dynamics. You can do this by using gradients given by jax and replacing calls to numpy in Cartpole.py with calls to jax.numpy. To speed up your code, you will need to use jax.scan instead of the for loop and jax.git. Use the `scipy.optimize` package for optimization as before. Find elements of ${\\bf p}$ that are able to stabilize the pole when started just slightly displaced from the upright unstable position. Then try for the case where the pole is in its downward position. For these experiments, you will need to tune the $\\sigma_l$ parameters in the loss to obtain good results. Which values of $\\sigma_l$ did you choose? You will also have to change the max_force varible in Cartpole.py. Which value did you choose? Now try to start from the downward stable position, what happens in this case?\n",
    "\n",
    "Plot the time evolution of the variables under the policy as predicted by the dynamics to demonstrate that the pole is kept upright."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "614476bba69242e9b6b9837c5c132c65",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Task 3.3\n",
    "\n",
    "In the previous task you used the real dynamics to optimize your policy. But we have a good _model_ of the dynamics (the nonlinear one from Task 2.3). Try to optimise the policy parameters by testing them on model-rollouts. You need to limit the time horizon (number of steps) to where you think your model is still accurate. (Using models to optimise a policy is called _model predictive control_).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7e413ff679e6448b8dfc1986045fa918",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Week 4: \n",
    "\n",
    "### Sensitivity and stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "3860b57f8122431494e757c9594cf637",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "We go back to the beginning of the project, and modify the problem, introducing noise in various forms, and observe its effect. \n",
    "\n",
    "#### Task 4.1\n",
    "\n",
    "Introduce noise in the _observed_ dynamics (but not in the real dynamics of the system). Refit the models (linear and nonlinear), and characterise the degradation in the prediction accuracy. Reoptimise the linear policy, and check its stability, contrasting it with the noise-free case.\n",
    "\n",
    "#### Task 4.2\n",
    "\n",
    "Introduce noise in the actual dynamics of the cartpole system, and repeat the tests of the previous task. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bc3e764875f74d29abf64ac304a510cb",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "325c27ca7bc34c388f17eba3c5fb94d2",
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
