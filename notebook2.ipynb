{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97516087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CartPole import CartPole, remap_angle, cartpole_step, remap_angle2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "matplotlib.use('TkAgg') \n",
    "import scipy\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c761453e",
   "metadata": {},
   "source": [
    "---\n",
    "# Task 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdf2f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important helper functions for all tasks\n",
    "\n",
    "def get_std(X):\n",
    "    return np.std(X, axis=0)\n",
    "\n",
    "def convert_dict_to_array(data):\n",
    "    # zip all the values in the dictionary together and convert it to a numpy array\n",
    "    # suppose the keys are not known beforehand\n",
    "    keys = list(data.keys())\n",
    "    values = [data[key] for key in keys]\n",
    "    return np.array(list(zip(*values)))\n",
    "\n",
    "\n",
    "def rollout(initial_state, initial_force, num_steps, visual=True, max_force=20):\n",
    "    \"\"\"\n",
    "    Simulate the CartPole environment for a given number of steps.\n",
    "    \n",
    "    Args:\n",
    "        initial_state (tuple): The initial state of the environment.\n",
    "        it should be a tuple of the form (cart_location, cart_velocity, \n",
    "                                        pole_angle, pole_velocity).\n",
    "\n",
    "        initial_force (float): The initial force applied to the cart.\n",
    "        num_steps (int): The number of steps to simulate.\n",
    "    \n",
    "    Returns:\n",
    "        data: A dictionary containing the cart location, cart velocity, \n",
    "              pole angle and pole angular velocity at each step.\n",
    "    \"\"\"\n",
    "    env = CartPole(visual=visual, max_force=max_force)\n",
    "    env.reset()\n",
    "\n",
    "    data = {'cart_location': [],\n",
    "            'cart_velocity': [],\n",
    "            'pole_angle': [],\n",
    "            'pole_velocity': []\n",
    "        }\n",
    "    \n",
    "    # Set the initial state\n",
    "    env.setState(initial_state)\n",
    "\n",
    "    # Perform the action for the specified number of steps\n",
    "    for step in range(num_steps + 1):\n",
    "        # Store the current state\n",
    "        data['cart_location'].append(env.cart_location)\n",
    "        data['cart_velocity'].append(env.cart_velocity)\n",
    "        data['pole_angle'].append(env.pole_angle)\n",
    "        data['pole_velocity'].append(env.pole_velocity)\n",
    "\n",
    "        # Perform the action\n",
    "        env.performAction(initial_force)\n",
    "\n",
    "        # remap the angle to be between -pi and pi\n",
    "        env.remap_angle()\n",
    "    \n",
    "    # close the plot\n",
    "    if visual:\n",
    "        env.close_plot()\n",
    "        plt.close()\n",
    "        \n",
    "    return data\n",
    "\n",
    "# Plotting functions --------------------------------------------------------\n",
    "def plot_policy(X, target, graph_title):\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15, 6))\n",
    "    titles = ['cart_location', 'cart_velocity', 'pole_angle', 'pole_velocity']\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            title = titles[i * 2 + j]\n",
    "            ax[i, j].plot(np.arange(0, len(X[:, i * 2 + j])), X[:, i * 2 + j], 'r-', label='policy')\n",
    "            ax[i, j].plot(np.arange(0, len(X[:, i * 2 + j])), [target[i * 2 + j]] * len(X[:, i * 2 + j]), 'b--', label='target')\n",
    "            # ax[i, j].set_title(title)\n",
    "            ax[i, j].set_xlabel('Iterations')\n",
    "            ax[i, j].set_ylabel(title)\n",
    "            ax[i, j].grid()\n",
    "            ax[i, j].legend()\n",
    "    \n",
    "    # center the title on top of the figure\n",
    "    fig.suptitle(graph_title)\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 1])  # Adjust the rect to make space for the title\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_fit(Y_actual, Y_pred, graph_title):\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15, 8))\n",
    "    titles = ['cart_location', 'cart_velocity', 'pole_angle', 'pole_velocity']\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            title = titles[i * 2 + j]\n",
    "            # make scatter plot dots smaller\n",
    "            # colour the scatter plot dots dark blue\n",
    "            ax[i, j].scatter(Y_actual[:, i * 2 + j], Y_pred[:, i * 2 + j], label='pred', s=2, color='darkblue')\n",
    "            ax[i, j].plot(Y_actual[:, i * 2 + j], Y_actual[:, i * 2 + j], 'r--', label='Y = X')\n",
    "            # ax[i, j].set_title(title)\n",
    "            ax[i, j].set_xlabel('actual change in state')\n",
    "            ax[i, j].set_ylabel(title)\n",
    "            ax[i, j].grid()\n",
    "            ax[i, j].legend()\n",
    "\n",
    "    # center the title on top of the figure\n",
    "    fig.suptitle(graph_title)\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 1])  # Adjust the rect to make space for the title\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_actual_pred_iterations(X_actual, X_forecast, graph_title):\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15, 6))\n",
    "    titles = ['cart_location', 'cart_velocity', 'pole_angle', 'pole_velocity']\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            title = titles[i * 2 + j]\n",
    "            ax[i, j].plot(np.arange(0, len(X_actual[:, i * 2 + j])), X_actual[:, i * 2 + j], 'r-', label='actual')\n",
    "            ax[i, j].plot(np.arange(0, len(X_forecast[:, i * 2 + j])), X_forecast[:, i * 2 + j], 'b--', label='forecast')\n",
    "            # ax[i, j].set_title(title)\n",
    "            ax[i, j].set_xlabel('Iterations')\n",
    "            ax[i, j].set_ylabel(title)\n",
    "            ax[i, j].grid()\n",
    "            ax[i, j].legend()\n",
    "    \n",
    "    # center the title on top of the figure\n",
    "    fig.suptitle(graph_title)\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 1])  # Adjust the rect to make space for the title\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.show()\n",
    "\n",
    "def plot_actual_pred_time(X_actual, X_forecast, graph_title):\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15, 6))\n",
    "    titles = ['cart_location', 'cart_velocity', 'pole_angle', 'pole_velocity']\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            title = titles[i * 2 + j]\n",
    "            ax[i, j].plot(0.1 * np.arange(0, len(X_actual[:, i * 2 + j])), X_actual[:, i * 2 + j], 'r-', label='actual')\n",
    "            ax[i, j].plot(0.1 * np.arange(0, len(X_forecast[:, i * 2 + j])), X_forecast[:, i * 2 + j], 'b--', label='forecast')\n",
    "            # ax[i, j].set_title(title)\n",
    "            ax[i, j].set_xlabel('time')\n",
    "            ax[i, j].set_ylabel(title)\n",
    "            ax[i, j].grid()\n",
    "            ax[i, j].legend()\n",
    "    \n",
    "    # center the title on top of the figure\n",
    "    fig.suptitle(graph_title)\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 1])  # Adjust the rect to make space for the title\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.show()\n",
    "\n",
    "def forecast_nonlinear_force(initial_state, num_steps, alpha, sigma, X_prime, kernel_fn, max_force=20):\n",
    "    x_state = initial_state[:-1]  # exclude the force from the state\n",
    "    initial_force = initial_state[-1]  # force is the last element of the state\n",
    "    # obtain the actual state\n",
    "    X_actual = convert_dict_to_array(rollout(x_state, initial_force, num_steps, visual=False, max_force=max_force))\n",
    "\n",
    "    current_state = np.array(initial_state)\n",
    "    current_x_state = np.array(x_state)\n",
    "    X_forecast = [current_x_state.copy()]\n",
    "    for i in range(num_steps):\n",
    "        # calculate the kernel for the current state\n",
    "        K = kernel_fn(np.expand_dims(current_state, axis=0), X_prime, sigma)\n",
    "\n",
    "        Y_pred = K @ alpha\n",
    "        current_x_state = (current_state[:-1] + Y_pred).flatten()\n",
    "        current_state = np.concatenate([current_x_state, current_state[-1:]]) # keep the force unchanged\n",
    "\n",
    "        # remap the angle to be between -pi and pi PURELY FOR PLOTTING\n",
    "        # The original state is still used for the forecast\n",
    "        remapped_state = current_x_state.copy()\n",
    "        remapped_state[2] = remap_angle(remapped_state[2])\n",
    "        X_forecast.append(remapped_state)\n",
    "\n",
    "    X_forecast = np.array(X_forecast)\n",
    "    \n",
    "    plot_actual_pred_iterations(X_actual, X_forecast, graph_title=f\"Forecast for initial state: {initial_state[0]:.2f}, {initial_state[1]:.2f}, {initial_state[2]:.2f}, {initial_state[3]:.2f} with force {initial_state[4]:.2f}\")\n",
    "    plot_actual_pred_time(X_actual, X_forecast, graph_title=f\"Forecast for initial state: {initial_state[0]:.2f}, {initial_state[1]:.2f}, {initial_state[2]:.2f}, {initial_state[3]:.2f} with force {initial_state[4]:.2f}\")\n",
    "\n",
    "\n",
    "# training functions --------------------------------------------------------\n",
    "def generate_data_random_force(num_steps, max_force=20):\n",
    "    env = CartPole(visual=False, max_force=max_force)\n",
    "    env.reset()\n",
    "    x_data = {\n",
    "        'cart_location': [],\n",
    "        'cart_velocity': [],\n",
    "        'pole_angle': [],\n",
    "        'pole_velocity': [],\n",
    "        'force': []\n",
    "    }\n",
    "\n",
    "    y_data = {\n",
    "        'cart_location': [],\n",
    "        'cart_velocity': [],\n",
    "        'pole_angle': [],\n",
    "        'pole_velocity': []\n",
    "    }\n",
    "    for i in range(num_steps):\n",
    "        initial_state = [np.random.uniform(-10, 10), np.random.uniform(-10, 10),\n",
    "                         np.random.uniform(-np.pi, np.pi), np.random.uniform(-15, 15)]\n",
    "        initial_force = np.random.uniform(-env.max_force, env.max_force)\n",
    "        env.reset()\n",
    "        env.setState(initial_state)\n",
    "        env.performAction(initial_force)\n",
    "\n",
    "        # remap the angle to be between -pi and pi\n",
    "        # env.remap_angle()\n",
    "        \n",
    "        next_state = env.getState()\n",
    "    \n",
    "        x_data['cart_location'].append(initial_state[0])\n",
    "        x_data['cart_velocity'].append(initial_state[1])\n",
    "        x_data['pole_angle'].append(initial_state[2])\n",
    "        x_data['pole_velocity'].append(initial_state[3])\n",
    "        x_data['force'].append(initial_force)\n",
    "\n",
    "        y_data['cart_location'].append(next_state[0] - initial_state[0])\n",
    "        y_data['cart_velocity'].append(next_state[1] - initial_state[1])\n",
    "        y_data['pole_angle'].append(next_state[2] - initial_state[2])\n",
    "        y_data['pole_velocity'].append(next_state[3] - initial_state[3])\n",
    "\n",
    "    X = convert_dict_to_array(x_data)\n",
    "    Y = convert_dict_to_array(y_data)\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def generate_data_random_force_observed_noise(num_steps, max_force, y_std, noise_factor):\n",
    "    env = CartPole(visual=False, max_force=max_force)\n",
    "    env.reset()\n",
    "    x_data = {\n",
    "        'cart_location': [],\n",
    "        'cart_velocity': [],\n",
    "        'pole_angle': [],\n",
    "        'pole_velocity': [],\n",
    "        'force': []\n",
    "    }\n",
    "\n",
    "    y_data = {\n",
    "        'cart_location': [],\n",
    "        'cart_velocity': [],\n",
    "        'pole_angle': [],\n",
    "        'pole_velocity': []\n",
    "    }\n",
    "    for i in range(num_steps):\n",
    "        initial_state = [np.random.uniform(-10, 10), np.random.uniform(-10, 10),\n",
    "                         np.random.uniform(-np.pi, np.pi), np.random.uniform(-15, 15)]\n",
    "        initial_force = np.random.uniform(-env.max_force, env.max_force)\n",
    "        env.reset()\n",
    "        env.setState(initial_state)\n",
    "        env.performAction(initial_force)\n",
    "\n",
    "        # remap the angle to be between -pi and pi\n",
    "        # env.remap_angle()\n",
    "        \n",
    "        next_state = env.getState()\n",
    "    \n",
    "        x_data['cart_location'].append(initial_state[0])\n",
    "        x_data['cart_velocity'].append(initial_state[1])\n",
    "        x_data['pole_angle'].append(initial_state[2])\n",
    "        x_data['pole_velocity'].append(initial_state[3])\n",
    "        x_data['force'].append(initial_force)\n",
    "\n",
    "        y_data['cart_location'].append(next_state[0] - initial_state[0])\n",
    "        y_data['cart_velocity'].append(next_state[1] - initial_state[1])\n",
    "        y_data['pole_angle'].append(next_state[2] - initial_state[2])\n",
    "        y_data['pole_velocity'].append(next_state[3] - initial_state[3])\n",
    "\n",
    "        # add noise to observations y\n",
    "        noise_std = noise_factor * y_std\n",
    "        noise = np.random.normal(0, noise_std, size=(4,))\n",
    "        y_data['cart_location'][-1] += noise[0]\n",
    "        y_data['cart_velocity'][-1] += noise[1]\n",
    "        y_data['pole_angle'][-1] += noise[2]\n",
    "        y_data['pole_velocity'][-1] += noise[3]\n",
    "\n",
    "\n",
    "    X = convert_dict_to_array(x_data)\n",
    "    Y = convert_dict_to_array(y_data)\n",
    "    \n",
    "    # print(\"shape of X:\", X.shape, \"\\nshape of Y:\", Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "def tikhonov_solve(K, regularisation_matrix, Y,lamb):\n",
    "    \"\"\"\n",
    "    Solve the Tikhonov regularization problem.\n",
    "    \n",
    "    Args:\n",
    "        K (numpy.ndarray): The kernel matrix. (N, M)\n",
    "        regularisation_matrix (numpy.ndarray): The regularization matrix. (M, M)\n",
    "        Y (numpy.ndarray): The output data. (N, D)\n",
    "        lamb (float): The regularization parameter.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: The weights of the model.\n",
    "    \"\"\"\n",
    "    Y_solve = (K.T) @ Y  # (N, D)\n",
    "\n",
    "    regularisation_term = lamb * regularisation_matrix # (M, M)\n",
    "\n",
    "    X_solve = ((K.T) @ K) + regularisation_term # (M, M)\n",
    "\n",
    "    alpha = np.linalg.lstsq(X_solve, Y_solve, rcond=None)[0]  # (M, D)\n",
    "    \n",
    "    return alpha\n",
    "\n",
    "def train_nonlinear_models(X, Y, M, lamb, sigma, kernel_fn):\n",
    "  \n",
    "\n",
    "    # choose M random points from X\n",
    "    # indices = np.random.choice(X.shape[0], M, replace=False)\n",
    "    # X_prime = X[indices]\n",
    "    X_prime = X[:M] # (M, D)\n",
    "\n",
    "    # Create the kernel matrix\n",
    "    K = kernel_fn(X, X_prime, sigma) # (N, M)\n",
    "\n",
    "    # Create the regularization matrix\n",
    "    regularisation_matrix = kernel_fn(X_prime, X_prime, sigma) # (M, M)\n",
    "\n",
    "    # solve the Tikhonov regularization problem\n",
    "    alpha = tikhonov_solve(K, regularisation_matrix, Y, lamb)\n",
    "\n",
    "    return alpha, X_prime, K\n",
    "\n",
    "def kernel_expanded(X, X_prime, sigma):\n",
    "    # create new X where 2 additional dimensions are added, replacing the angle with sin and cos\n",
    "    # angle dimension is removed\n",
    "    X_new = np.hstack((X[:,0:2], np.sin(X[:, 2:3]), np.cos(X[:, 2:3]), X[:, 3:]))  # (N, D+1)\n",
    "    X_prime_new = np.hstack((X_prime[:,0:2], np.sin(X_prime[:, 2:3]), np.cos(X_prime[:, 2:3]), X_prime[:, 3:]))  # (M, D+1)\n",
    "\n",
    "    X_e = np.expand_dims(X_new, axis=1)  # (N, 1, D+1)\n",
    "    X_prime_e = np.expand_dims(X_prime_new, axis=0)  # (1, M, D+1)\n",
    "\n",
    "    diff = X_e - X_prime_e  # (N, M, D+1)\n",
    "    scaled_squared_diff = (diff ** 2)/(2 * sigma ** 2) # (N, M, D+1)\n",
    "\n",
    "    K = np.exp(-np.sum(scaled_squared_diff, axis=-1))  # (N, M)\n",
    "    return K\n",
    "\n",
    "\n",
    "# jax helper functions ---------------------------------------------------\n",
    "\n",
    "def train_nonlinear_models_j(X, Y, M, lamb, sigma, kernel_fn):\n",
    "    # choose M points from X\n",
    "    X_prime = X[:M] # (M, D)\n",
    "\n",
    "    # Create the kernel matrix\n",
    "    K = kernel_fn(X, X_prime, sigma) # (N, M)\n",
    "\n",
    "    # Create the regularization matrix\n",
    "    regularisation_matrix = kernel_fn(X_prime, X_prime, sigma) # (M, M)\n",
    "\n",
    "    alpha = tikhonov_solve_j(K, regularisation_matrix, Y, lamb)\n",
    "    return alpha, X_prime, K\n",
    "\n",
    "\n",
    "\n",
    "def tikhonov_solve_j(K, regularisation_matrix, Y,lamb):\n",
    "    \"\"\"\n",
    "    Solve the Tikhonov regularization problem.\n",
    "    \n",
    "    Args:\n",
    "        K (numpy.ndarray): The kernel matrix. (N, M)\n",
    "        regularisation_matrix (numpy.ndarray): The regularization matrix. (M, M)\n",
    "        Y (numpy.ndarray): The output data. (N, D)\n",
    "        lamb (float): The regularization parameter.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: The weights of the model.\n",
    "    \"\"\"\n",
    "    Y_solve = (K.T) @ Y  # (N, D)\n",
    "\n",
    "    regularisation_term = lamb * regularisation_matrix # (M, M)\n",
    "    X_solve = ((K.T) @ K) + regularisation_term # (M, M)\n",
    "\n",
    "    alpha = jnp.linalg.lstsq(X_solve, Y_solve, rcond=None, numpy_resid=True)[0]  # (M, D)\n",
    "    return alpha\n",
    "\n",
    "@jax.jit\n",
    "def kernel_expanded_j(X, X_prime, sigma):\n",
    "    # create new X where 2 additional dimensions are added, replacing the angle with sin and cos\n",
    "    # angle dimension is removed\n",
    "    X_new = jnp.hstack((X[:,0:2], jnp.sin(X[:, 2:3]), jnp.cos(X[:, 2:3]), X[:, 3:]))  # (N, D+1)\n",
    "    X_prime_new = jnp.hstack((X_prime[:,0:2], jnp.sin(X_prime[:, 2:3]), jnp.cos(X_prime[:, 2:3]), X_prime[:, 3:]))  # (M, D+1)\n",
    "\n",
    "    X_e = jnp.expand_dims(X_new, axis=1)  # (N, 1, D+1)\n",
    "    X_prime_e = jnp.expand_dims(X_prime_new, axis=0)  # (1, M, D+1)\n",
    "\n",
    "    diff = X_e - X_prime_e  # (N, M, D+1)\n",
    "    scaled_squared_diff = (diff ** 2)/(2 * sigma ** 2) # (N, M, D+1)\n",
    "\n",
    "    K = jnp.exp(-jnp.sum(scaled_squared_diff, axis=-1))  # (N, M)\n",
    "    return K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe88aa22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of Y: [0.58454333 1.48055989 0.89009544 3.76791994]\n"
     ]
    }
   ],
   "source": [
    "N_train, N_test = 4096, 2048\n",
    "X_no_noise, Y_no_noise = generate_data_random_force(num_steps=N_train+N_test)\n",
    "Y_std = get_std(Y_no_noise)\n",
    "print(\"Standard deviation of Y:\", Y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdc7084b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fun: 0.10889331652703485\n",
      "   x: [ 4.934e-02  5.828e+00  5.797e+00  4.659e-01  4.849e-01  8.636e+00\n",
      "        8.668e+00]\n",
      " fun: 0.1000162303872198\n",
      "   x: [ 1.110e-02  5.852e+00  5.821e+00  5.912e-01  5.690e-01  8.631e+00\n",
      "        8.682e+00]\n",
      " fun: 0.09550732271147852\n",
      "   x: [ 3.304e-02  5.903e+00  5.875e+00  7.427e-01  6.270e-01  8.616e+00\n",
      "        8.716e+00]\n",
      " fun: 0.09323989907321284\n",
      "   x: [ 1.000e-06  5.971e+00  5.950e+00  8.931e-01  6.693e-01  8.594e+00\n",
      "        8.763e+00]\n",
      " fun: 0.09176179915921187\n",
      "   x: [ 2.687e-02  6.033e+00  6.017e+00  1.000e+00  6.862e-01  8.575e+00\n",
      "        8.805e+00]\n",
      " fun: 0.09129587816421625\n",
      "   x: [ 2.395e-02  6.043e+00  6.029e+00  1.000e+00  6.723e-01  8.571e+00\n",
      "        8.813e+00]\n",
      " fun: 0.08921904873569404\n",
      "   x: [ 2.122e-03  6.181e+00  6.185e+00  1.000e+00  5.508e-01  8.524e+00\n",
      "        8.911e+00]\n",
      " fun: 0.08601675388625508\n",
      "   x: [ 1.400e-02  6.327e+00  6.346e+00  1.000e+00  5.719e-01  8.476e+00\n",
      "        9.012e+00]\n",
      " fun: 0.07405275248815116\n",
      "   x: [ 4.281e-02  7.274e+00  7.389e+00  1.000e+00  5.942e-01  8.168e+00\n",
      "        9.671e+00]\n",
      " fun: 0.0656888045265592\n",
      "   x: [ 6.435e-02  8.461e+00  8.695e+00  9.660e-01  5.878e-01  7.782e+00\n",
      "        1.050e+01]\n",
      " fun: 0.05991563927978481\n",
      "   x: [ 7.123e-02  9.933e+00  1.027e+01  7.924e-01  6.019e-01  7.446e+00\n",
      "        1.147e+01]\n",
      " fun: 0.056095397545232684\n",
      "   x: [ 8.955e-02  1.169e+01  1.215e+01  7.654e-01  5.903e-01  7.052e+00\n",
      "        1.264e+01]\n",
      " fun: 0.053941038218828154\n",
      "   x: [ 1.561e-02  1.380e+01  1.451e+01  1.000e+00  7.815e-01  6.644e+00\n",
      "        1.436e+01]\n",
      " fun: 0.052071220865611056\n",
      "   x: [ 6.470e-02  1.555e+01  1.636e+01  1.000e+00  7.184e-01  6.219e+00\n",
      "        1.547e+01]\n",
      " fun: 0.05143437445195173\n",
      "   x: [ 6.464e-02  1.692e+01  1.785e+01  1.000e+00  7.262e-01  5.917e+00\n",
      "        1.644e+01]\n",
      " fun: 0.05051374095673828\n",
      "   x: [ 4.614e-02  1.758e+01  1.888e+01  1.000e+00  5.021e-01  5.974e+00\n",
      "        1.776e+01]\n",
      " fun: 0.049910926327087976\n",
      "   x: [ 4.302e-02  2.005e+01  2.150e+01  1.000e+00  5.773e-01  5.414e+00\n",
      "        1.938e+01]\n",
      " fun: 0.04971727559980503\n",
      "   x: [ 3.157e-02  2.149e+01  2.318e+01  1.000e+00  5.738e-01  5.219e+00\n",
      "        2.072e+01]\n",
      " fun: 0.049623910407160916\n",
      "   x: [ 2.917e-02  2.256e+01  2.439e+01  1.000e+00  5.935e-01  5.060e+00\n",
      "        2.163e+01]\n",
      " fun: 0.04945428927053646\n",
      "   x: [ 2.664e-02  2.393e+01  2.602e+01  1.000e+00  6.302e-01  4.959e+00\n",
      "        2.301e+01]\n",
      " fun: 0.049211541157602776\n",
      "   x: [ 2.227e-02  2.538e+01  2.791e+01  1.000e+00  6.744e-01  5.052e+00\n",
      "        2.493e+01]\n",
      " fun: 0.048934078573546064\n",
      "   x: [ 1.694e-02  2.646e+01  2.958e+01  1.000e+00  7.100e-01  5.444e+00\n",
      "        2.709e+01]\n",
      " fun: 0.04871648377750138\n",
      "   x: [ 1.039e-02  2.701e+01  3.082e+01  1.000e+00  7.218e-01  6.096e+00\n",
      "        2.926e+01]\n",
      " fun: 0.0486642517780662\n",
      "   x: [ 1.253e-02  2.701e+01  3.104e+01  1.000e+00  7.182e-01  6.367e+00\n",
      "        2.987e+01]\n",
      " fun: 0.048599107876692166\n",
      "   x: [ 9.279e-03  2.710e+01  3.153e+01  1.000e+00  6.958e-01  6.801e+00\n",
      "        3.102e+01]\n",
      " fun: 0.04858622960007128\n",
      "   x: [ 8.597e-03  2.713e+01  3.169e+01  1.000e+00  6.737e-01  6.934e+00\n",
      "        3.140e+01]\n",
      " fun: 0.04858353746654097\n",
      "   x: [ 9.367e-03  2.701e+01  3.156e+01  1.000e+00  6.546e-01  6.949e+00\n",
      "        3.131e+01]\n",
      " fun: 0.04858294086117976\n",
      "   x: [ 9.752e-03  2.692e+01  3.141e+01  1.000e+00  6.427e-01  6.898e+00\n",
      "        3.110e+01]\n",
      " fun: 0.04858225386300233\n",
      "   x: [ 1.002e-02  2.687e+01  3.131e+01  1.000e+00  6.431e-01  6.851e+00\n",
      "        3.093e+01]\n",
      " fun: 0.048547496304823225\n",
      "   x: [ 1.097e-02  2.679e+01  3.099e+01  1.000e+00  6.317e-01  6.822e+00\n",
      "        3.020e+01]\n",
      " fun: 0.04838710869735901\n",
      "   x: [ 1.763e-02  2.701e+01  2.937e+01  1.000e+00  5.791e-01  7.040e+00\n",
      "        2.465e+01]\n",
      " fun: 0.04831150982719262\n",
      "   x: [ 1.392e-02  2.809e+01  3.101e+01  1.000e+00  6.139e-01  7.473e+00\n",
      "        2.667e+01]\n",
      " fun: 0.04824449616427033\n",
      "   x: [ 1.365e-02  2.923e+01  3.205e+01  1.000e+00  6.146e-01  7.653e+00\n",
      "        2.681e+01]\n",
      " fun: 0.04809187755638285\n",
      "   x: [ 1.437e-02  3.000e+01  3.946e+01  1.000e+00  6.044e-01  8.372e+00\n",
      "        2.663e+01]\n",
      " fun: 0.04805895882010418\n",
      "   x: [ 1.783e-02  3.000e+01  4.000e+01  1.000e+00  5.763e-01  8.398e+00\n",
      "        2.571e+01]\n",
      " fun: 0.0479922374712851\n",
      "   x: [ 2.560e-02  3.000e+01  4.000e+01  9.997e-01  5.304e-01  8.007e+00\n",
      "        2.370e+01]\n",
      " fun: 0.04790227633433623\n",
      "   x: [ 4.031e-02  3.000e+01  4.000e+01  9.987e-01  5.078e-01  6.500e+00\n",
      "        2.285e+01]\n",
      " fun: 0.04788285272877675\n",
      "   x: [ 3.142e-02  3.000e+01  4.000e+01  1.000e+00  5.638e-01  6.904e+00\n",
      "        2.375e+01]\n",
      " fun: 0.047875153904313794\n",
      "   x: [ 3.208e-02  3.000e+01  4.000e+01  9.993e-01  5.520e-01  6.765e+00\n",
      "        2.374e+01]\n",
      " fun: 0.047873989624319074\n",
      "   x: [ 3.158e-02  3.000e+01  4.000e+01  9.990e-01  5.453e-01  6.740e+00\n",
      "        2.367e+01]\n",
      " fun: 0.04787383506630044\n",
      "   x: [ 3.111e-02  3.000e+01  4.000e+01  9.990e-01  5.475e-01  6.734e+00\n",
      "        2.376e+01]\n",
      " fun: 0.047873810085010425\n",
      "   x: [ 3.062e-02  3.000e+01  4.000e+01  9.991e-01  5.476e-01  6.756e+00\n",
      "        2.382e+01]\n"
     ]
    }
   ],
   "source": [
    "# train sine cosine model\n",
    "\n",
    "N_train, N_test, M = 4096, 2048, 1024\n",
    "max_force = 15\n",
    "\n",
    "X, Y = generate_data_random_force_observed_noise(num_steps=N_train+N_test, max_force=max_force, y_std=Y_std, noise_factor=0.1)\n",
    "X = jnp.array(X)\n",
    "Y = jnp.array(Y)\n",
    "X_prime = X[:M]\n",
    "\n",
    "X_train = X[:N_train]\n",
    "Y_train = Y[:N_train]\n",
    "\n",
    "X_val = X[-N_test:]\n",
    "Y_val = Y[-N_test:]\n",
    "\n",
    "def loss(parameters):\n",
    "    lamb = parameters[0]\n",
    "    sigma = parameters[1:]\n",
    "    # train model\n",
    "    alpha, X_prime, _= train_nonlinear_models_j(X_train, Y_train, M=M, lamb=lamb, sigma=sigma, kernel_fn=kernel_expanded_j)\n",
    "\n",
    "    # predict using validation set\n",
    "    K_val = kernel_expanded_j(X_val, X_prime, sigma)\n",
    "    Y_pred = K_val @ alpha\n",
    "\n",
    "    mse = jnp.mean((Y_val - Y_pred) ** 2)\n",
    "    return mse\n",
    "\n",
    "# create a function that calculates the gradient of the loss function using jax.grad\n",
    "grad_loss = jax.grad(loss)\n",
    "\n",
    "initial_lamb = 1E-4\n",
    "std_force = max_force / (3**0.5)  # standard deviation for force\n",
    "x_sigma = get_std(X)\n",
    "# initial_sigma = jnp.array([6, 6, 0.5, 0.5, 6])\n",
    "std_sine, std_cos = (0.125)**0.5, (0.125)**0.5  # standard deviation for sine and cosine\n",
    "initial_sigma = jnp.array([x_sigma[0], x_sigma[1], std_sine, std_cos, x_sigma[-1], std_force])\n",
    "initial_hyperparameters = jnp.array([initial_lamb] + initial_sigma.tolist())\n",
    "\n",
    "losses = [loss(initial_hyperparameters)]\n",
    "\n",
    "def callback(intermediate_result):\n",
    "    print(intermediate_result)\n",
    "    losses.append(intermediate_result.fun)\n",
    "\n",
    "\n",
    "\n",
    "bounds = [(1E-6, 1E-1)] + [(0, 30)] + [(0, 40)] + [(0, 1)] * 2 +[(0, 10)] + [(0, max_force*3)]  # bounds for lamb and sigma\n",
    "res = scipy.optimize.minimize(loss, x0=initial_hyperparameters, method='L-BFGS-B', jac=grad_loss, bounds=bounds, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "079c31a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal lambda: 0.030620290457778494\n",
      "optimal sigma: [30.         40.          0.99912816  0.54763817  6.75635011 23.82006105]\n",
      "initial loss 0.130074461398551\n",
      "Final loss: 0.047873810085010425\n",
      "number of iterations: 42\n"
     ]
    }
   ],
   "source": [
    "print(\"optimal lambda:\", res.x[0])\n",
    "print(\"optimal sigma:\", res.x[1:])\n",
    "print(\"initial loss\", losses[0])\n",
    "print(\"Final loss:\", res.fun)\n",
    "print(\"number of iterations:\", len(losses) - 1)\n",
    "\n",
    "def plot_loss(losses):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.plot(losses, label='Loss')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss over iterations')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a878ca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, M, lamb = 4096, 1024, res.x[0]\n",
    "# N, M, lamb = 4096, 1024, 4.543e-03 # mine\n",
    "# N, M, lamb = 4096, 1024, 4.918e-04 # andrew\n",
    "max_force=15\n",
    "# generate training data\n",
    "X, Y = generate_data_random_force_observed_noise(num_steps=N, max_force=max_force, y_std=Y_std, noise_factor=0.1)\n",
    "\n",
    "# Get the standard deviation of X\n",
    "sigma = res.x[1:]\n",
    "# sigma = np.array([1.000e+01,  1.000e+01,  9.916e-01,  6.063e-01, 7.005e+00,  2.000e+01]) # mine\n",
    "# sigma = np.array([15.41,  1.413e+01,  5.24,  0.97, 7.356,  13.52])    # andrew\n",
    "\n",
    "# train model\n",
    "alpha, X_prime, K = train_nonlinear_models(X, Y, M=M, lamb=lamb, sigma=sigma, kernel_fn=kernel_expanded)\n",
    "\n",
    "# predict using training set\n",
    "Y_pred = K @ alpha\n",
    "\n",
    "# plot_fit(X, Y, Y_pred, graph_title=\"Fit of the model\")\n",
    "plot_fit(Y, Y_pred, graph_title=\"Change in state\")\n",
    "\n",
    "\n",
    "# Example initial states for testing\n",
    "initial_states = [[0, -2, np.pi, 4, 1], [0, 0, np.pi, 5, 2], [0, 0, np.pi, 0, 10], [0, 0, 0.1, 0, 8]]\n",
    "# initial_states = [[0, 0, np.pi, 0, 15]]\n",
    "for initial_state in initial_states:\n",
    "    forecast_nonlinear_force(initial_state, num_steps=100, alpha=alpha, sigma=sigma, X_prime=X_prime, kernel_fn=kernel_expanded)\n",
    "\n",
    "non_linear_model_sin_force = {\n",
    "    'lambda': res.x[0],\n",
    "    'sigma': res.x[1:],\n",
    "    'alpha': alpha,\n",
    "    'X_prime': X_prime,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b784478b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 19.528658634983024\n",
      "Iteration: 1\n",
      "P: [0.97506613 1.01115828 1.28523116 1.56189376]\n",
      "Loss: 18.83115554589682\n",
      "\n",
      "Iteration: 2\n",
      "P: [0.57986872 1.00135361 4.90201646 5.93005205]\n",
      "Loss: 3.918634816138515\n",
      "\n",
      "Iteration: 3\n",
      "P: [0.55040736 1.01073538 5.08736642 6.13331937]\n",
      "Loss: 3.879024059019882\n",
      "\n",
      "Iteration: 4\n",
      "P: [0.19011987 1.23546483 5.9786596  6.63033225]\n",
      "Loss: 2.933194875772463\n",
      "\n",
      "Iteration: 5\n",
      "P: [-0.63193355  2.67166093  7.76179612  6.61447473]\n",
      "Loss: 0.3364584207041035\n",
      "\n",
      "Iteration: 6\n",
      "P: [-0.68914849  2.7907202   7.91562828  6.60263461]\n",
      "Loss: 0.30417956478597286\n",
      "\n",
      "Iteration: 7\n",
      "P: [-2.58757275  6.24789333 10.80704093  6.03599088]\n",
      "Loss: 0.050585858167582876\n",
      "\n",
      "Iteration: 8\n",
      "P: [-2.7219648   6.5260379  11.12776837  5.99288938]\n",
      "Loss: 0.04536069380650409\n",
      "\n",
      "Iteration: 9\n",
      "P: [-3.07075065  7.39837315 12.43094171  5.88743894]\n",
      "Loss: 0.03779289700024635\n",
      "\n",
      "Iteration: 10\n",
      "P: [-2.97789129  7.42384976 12.86220751  5.94681027]\n",
      "Loss: 0.034589726077199234\n",
      "\n",
      "Iteration: 11\n",
      "P: [-2.71441343  7.90745287 15.33520523  6.15701947]\n",
      "Loss: 0.02513063205220012\n",
      "\n",
      "Iteration: 12\n",
      "P: [-2.49348084  8.59509091 18.28905607  6.34904135]\n",
      "Loss: 0.019412490368551083\n",
      "\n",
      "Iteration: 13\n",
      "P: [-2.23604969  9.22174259 21.3948097   6.44322348]\n",
      "Loss: 0.01641239168026376\n",
      "\n",
      "Iteration: 14\n",
      "P: [-1.45195598  8.65966463 23.41691771  5.88804106]\n",
      "Loss: 0.015259384527851583\n",
      "\n",
      "Iteration: 15\n",
      "P: [-0.80907864  8.38130129 24.03039185  5.73137769]\n",
      "Loss: 0.014839743244299819\n",
      "\n",
      "Iteration: 16\n",
      "P: [ 1.86923285  7.47279741 25.36788393  5.45732674]\n",
      "Loss: 0.013456804110391074\n",
      "\n",
      "Iteration: 17\n",
      "P: [ 5.79276219  5.94466807 23.76124264  5.19195594]\n",
      "Loss: 0.012817140466742427\n",
      "\n",
      "Iteration: 18\n",
      "P: [ 4.90672936  6.40216219 25.23842757  5.26421739]\n",
      "Loss: 0.012590921674658806\n",
      "\n",
      "Iteration: 19\n",
      "P: [ 5.52144572  6.15449107 25.57881711  5.18963273]\n",
      "Loss: 0.012524070627982442\n",
      "\n",
      "Iteration: 20\n",
      "P: [ 5.27291565  6.1003317  26.25277661  5.45580769]\n",
      "Loss: 0.012299016057317536\n",
      "\n",
      "Iteration: 21\n",
      "P: [ 5.73101793  5.78416041 26.54052373  5.33545051]\n",
      "Loss: 0.012263845448503341\n",
      "\n",
      "Iteration: 22\n",
      "P: [ 5.38739926  4.51256938 26.27118641  4.71494224]\n",
      "Loss: 0.012071934880200641\n",
      "\n",
      "Iteration: 23\n",
      "P: [ 4.20162983  2.1497537  24.89208485  3.58447818]\n",
      "Loss: 0.011900276862312098\n",
      "\n",
      "Iteration: 24\n",
      "P: [ 4.64270766  1.87800217 24.79132027  3.44070981]\n",
      "Loss: 0.011813485763135567\n",
      "\n",
      "Iteration: 25\n",
      "P: [ 4.57883435  1.45895812 24.30862724  3.16643677]\n",
      "Loss: 0.011801800399801943\n",
      "\n",
      "Iteration: 26\n",
      "P: [ 4.49847594  1.52281349 24.02814234  3.11647251]\n",
      "Loss: 0.01178810321792989\n",
      "\n",
      "Iteration: 27\n",
      "P: [ 4.30590997  1.59013202 23.71659745  3.12431787]\n",
      "Loss: 0.011778442850932436\n",
      "\n",
      "Iteration: 28\n",
      "P: [ 4.15444045  1.57946994 23.30745872  3.08688295]\n",
      "Loss: 0.011775783544648588\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train policy\n",
    "initial_state = jnp.array([0, 0, 0.1, 0])\n",
    "sigma = jnp.array([10, 10, 7, 10])\n",
    "# sigma = jnp.array([5.8, 5.8, 1.5, 8.5])  # Example sigma values\n",
    "num_steps = 30\n",
    "target = jnp.array([0, 0, 0, 0])\n",
    "max_force = 8\n",
    "\n",
    "initial_p = jnp.array([1, 1, 1, 1])  # initial policy parameters for upright initial starting position\n",
    "\n",
    "model_x_prime = jnp.array(non_linear_model_sin_force['X_prime'])\n",
    "model_sigma = jnp.array(non_linear_model_sin_force['sigma'])\n",
    "model_alpha = jnp.array(non_linear_model_sin_force['alpha'])\n",
    "\n",
    "@jax.jit\n",
    "def kernel_expanded_jax(X, X_prime, sigma):\n",
    "    # create new X where 2 additional dimensions are added, replacing the angle with sin and cos\n",
    "    # angle dimension is removed\n",
    "    X_new = jnp.hstack((X[:,0:2], jnp.sin(X[:, 2:3]), jnp.cos(X[:, 2:3]), X[:, 3:]))  # (N, D+1)\n",
    "    X_prime_new = jnp.hstack((X_prime[:,0:2], jnp.sin(X_prime[:, 2:3]), jnp.cos(X_prime[:, 2:3]), X_prime[:, 3:]))  # (M, D+1)\n",
    "\n",
    "    X_e = jnp.expand_dims(X_new, axis=1)  # (N, 1, D+1)\n",
    "    X_prime_e = jnp.expand_dims(X_prime_new, axis=0)  # (1, M, D+1)\n",
    "\n",
    "    diff = X_e - X_prime_e  # (N, M, D+1)\n",
    "    scaled_squared_diff = (diff ** 2)/(2 * sigma ** 2) # (N, M, D+1)\n",
    "\n",
    "    K = jnp.exp(-jnp.sum(scaled_squared_diff, axis=-1))  # (N, M)\n",
    "    return K\n",
    "\n",
    "@jax.jit\n",
    "def loss_policy_jax(state, target, sigma):\n",
    "    delta = (state - target) / sigma\n",
    "    exponent = 0.5 * jnp.dot(delta, delta)\n",
    "    return 1 - jnp.exp(-exponent)\n",
    "\n",
    "@jax.jit\n",
    "def loss_rollout_linear_jax(P):\n",
    "    def scan_step_jax(state, _):\n",
    "        force = P @ state\n",
    "        force = max_force * jnp.tanh(force/max_force)\n",
    "\n",
    "        # add force as the last element to the state\n",
    "        current_state = jnp.concatenate([state, jnp.array([force])])\n",
    "        K = kernel_expanded_jax(jnp.expand_dims(current_state, axis=0), model_x_prime, model_sigma)\n",
    "        Y_pred = K @ model_alpha\n",
    "        next_state = jnp.ravel(current_state[:-1] + Y_pred)\n",
    "\n",
    "        loss = loss_policy_jax(next_state, target, sigma)\n",
    "        return next_state, loss\n",
    "\n",
    "    init_loss = loss_policy_jax(initial_state, target, sigma)\n",
    "    _, losses = jax.lax.scan(scan_step_jax, initial_state, None, length=num_steps)\n",
    "    return init_loss + losses.sum()\n",
    "\n",
    "grad_loss_linear_jax = jax.grad(loss_rollout_linear_jax)\n",
    "\n",
    "losses = [loss_rollout_linear_jax(initial_p)]\n",
    "print(\"Initial loss:\", losses[0])\n",
    "\n",
    "def callback(intermediate_result):\n",
    "    print(\"Iteration:\", len(losses))\n",
    "    print(\"P:\", intermediate_result.x)\n",
    "    print(\"Loss:\", intermediate_result.fun)\n",
    "    print()\n",
    "    losses.append(intermediate_result.fun)\n",
    "\n",
    "res = scipy.optimize.minimize(loss_rollout_linear_jax, x0=initial_p, method='L-BFGS-B', jac=grad_loss_linear_jax, callback=callback, bounds=[(-30, 30)] * 4) \n",
    "\n",
    "def rollout_linear_force(initial_state, num_steps, P, max_force):\n",
    "    X_forecast = [initial_state.copy()]\n",
    "    \n",
    "    state = initial_state.copy()\n",
    "    for step in range(num_steps):\n",
    "        force = P @ state\n",
    "        force = max_force * np.tanh(force/max_force)\n",
    "        # add force as the last element to the state\n",
    "        current_state = jnp.concatenate([state, jnp.array([force])])\n",
    "        K = kernel_expanded_jax(jnp.expand_dims(current_state, axis=0), model_x_prime, model_sigma)\n",
    "\n",
    "        Y_pred = K @ model_alpha\n",
    "        state = jnp.ravel(current_state[:-1] + Y_pred)\n",
    "\n",
    "        remapped_state = state.copy()\n",
    "        # remap jax angle to be between -pi and pi PURELY FOR PLOTTING\n",
    "        remapped_state = np.array([remapped_state[0], remapped_state[1], remap_angle2(remapped_state[2]), remapped_state[3]])\n",
    "        X_forecast.append(remapped_state)\n",
    "\n",
    "    return np.array(X_forecast)\n",
    "\n",
    "P = res.x  # optimised policy matrix\n",
    "X = rollout_linear_force(initial_state=initial_state, num_steps=50, P=P, max_force=max_force)\n",
    "plot_policy(X, target, f\"Rollout Policy, initial_state: {initial_state}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79d20f1",
   "metadata": {},
   "source": [
    "---\n",
    "# upside down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df1a7700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of Y: [0.57952153 1.47412334 0.88962311 3.76359956]\n"
     ]
    }
   ],
   "source": [
    "N_train, N_test = 4096, 2048\n",
    "X_no_noise, Y_no_noise = generate_data_random_force(num_steps=N_train+N_test)\n",
    "Y_std = get_std(Y_no_noise)\n",
    "print(\"Standard deviation of Y:\", Y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a558a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fun: 0.10061255048589059\n",
      "   x: [ 4.900e-02  5.773e+00  5.753e+00  4.686e-01  4.844e-01  8.635e+00\n",
      "        8.668e+00]\n",
      " fun: 0.09246887923451691\n",
      "   x: [ 3.389e-02  5.799e+00  5.777e+00  5.814e-01  5.649e-01  8.631e+00\n",
      "        8.681e+00]\n",
      " fun: 0.08727051953842183\n",
      "   x: [ 7.715e-02  5.865e+00  5.842e+00  7.622e-01  6.374e-01  8.613e+00\n",
      "        8.716e+00]\n",
      " fun: 0.08512919120443677\n",
      "   x: [ 1.113e-02  5.932e+00  5.909e+00  8.925e-01  6.877e-01  8.593e+00\n",
      "        8.753e+00]\n",
      " fun: 0.08420456941272703\n",
      "   x: [ 4.776e-02  5.960e+00  5.937e+00  9.457e-01  6.976e-01  8.585e+00\n",
      "        8.768e+00]\n",
      " fun: 0.08359739901289251\n",
      "   x: [ 4.179e-02  5.996e+00  5.974e+00  1.000e+00  7.109e-01  8.574e+00\n",
      "        8.788e+00]\n",
      " fun: 0.08072155076042313\n",
      "   x: [ 1.716e-02  6.190e+00  6.169e+00  1.000e+00  7.313e-01  8.518e+00\n",
      "        8.896e+00]\n",
      " fun: 0.07576589888809497\n",
      "   x: [ 1.118e-02  6.628e+00  6.613e+00  1.000e+00  7.707e-01  8.390e+00\n",
      "        9.142e+00]\n",
      " fun: 0.06518580547139785\n",
      "   x: [ 5.053e-02  7.971e+00  7.970e+00  1.000e+00  8.757e-01  8.001e+00\n",
      "        9.892e+00]\n",
      " fun: 0.061641762105825795\n",
      "   x: [ 5.854e-02  8.828e+00  8.837e+00  9.217e-01  9.176e-01  7.754e+00\n",
      "        1.037e+01]\n",
      " fun: 0.06133965077256302\n",
      "   x: [ 3.855e-02  8.829e+00  8.838e+00  9.204e-01  9.067e-01  7.753e+00\n",
      "        1.037e+01]\n",
      " fun: 0.060907997369185084\n",
      "   x: [ 4.163e-02  8.837e+00  8.847e+00  9.191e-01  8.603e-01  7.753e+00\n",
      "        1.038e+01]\n",
      " fun: 0.05980330022524197\n",
      "   x: [ 5.217e-02  8.888e+00  8.902e+00  9.245e-01  6.642e-01  7.750e+00\n",
      "        1.040e+01]\n",
      " fun: 0.05963638696923298\n",
      "   x: [ 5.841e-02  8.934e+00  8.950e+00  9.144e-01  6.393e-01  7.746e+00\n",
      "        1.043e+01]\n",
      " fun: 0.058956100258641675\n",
      "   x: [ 8.204e-02  9.177e+00  9.200e+00  8.539e-01  6.006e-01  7.727e+00\n",
      "        1.057e+01]\n",
      " fun: 0.05768374724171852\n",
      "   x: [ 1.000e-01  9.703e+00  9.744e+00  7.227e-01  5.723e-01  7.685e+00\n",
      "        1.087e+01]\n",
      " fun: 0.054332997085665136\n",
      "   x: [ 1.000e-01  1.150e+01  1.160e+01  7.534e-01  5.177e-01  7.522e+00\n",
      "        1.193e+01]\n",
      " fun: 0.05226746466386518\n",
      "   x: [ 8.033e-02  1.329e+01  1.348e+01  6.466e-01  5.999e-01  7.397e+00\n",
      "        1.301e+01]\n",
      " fun: 0.050895130174417824\n",
      "   x: [ 5.104e-02  1.515e+01  1.543e+01  7.613e-01  6.345e-01  7.259e+00\n",
      "        1.413e+01]\n",
      " fun: 0.04981119818692813\n",
      "   x: [ 4.146e-02  1.773e+01  1.813e+01  8.400e-01  6.698e-01  7.062e+00\n",
      "        1.568e+01]\n",
      " fun: 0.04860940999561362\n",
      "   x: [ 4.760e-02  2.243e+01  2.304e+01  9.508e-01  7.090e-01  6.685e+00\n",
      "        1.851e+01]\n",
      " fun: 0.04814896697680093\n",
      "   x: [ 1.467e-02  2.947e+01  3.040e+01  1.000e+00  6.776e-01  6.127e+00\n",
      "        2.275e+01]\n",
      " fun: 0.047585393809710094\n",
      "   x: [ 4.122e-02  3.000e+01  3.508e+01  1.000e+00  6.567e-01  5.763e+00\n",
      "        2.545e+01]\n",
      " fun: 0.047551992671947436\n",
      "   x: [ 3.985e-02  3.000e+01  3.466e+01  9.704e-01  6.474e-01  5.797e+00\n",
      "        2.520e+01]\n",
      " fun: 0.04751449308613064\n",
      "   x: [ 3.887e-02  3.000e+01  3.399e+01  8.879e-01  6.216e-01  5.851e+00\n",
      "        2.482e+01]\n",
      " fun: 0.047506148640775736\n",
      "   x: [ 4.033e-02  3.000e+01  3.403e+01  8.582e-01  6.129e-01  5.850e+00\n",
      "        2.484e+01]\n",
      " fun: 0.04748548739747577\n",
      "   x: [ 4.431e-02  3.000e+01  3.426e+01  8.143e-01  5.998e-01  5.883e+00\n",
      "        2.496e+01]\n",
      " fun: 0.04746818100243903\n",
      "   x: [ 4.866e-02  3.000e+01  3.446e+01  7.862e-01  5.920e-01  5.950e+00\n",
      "        2.506e+01]\n",
      " fun: 0.047454042736400075\n",
      "   x: [ 5.192e-02  3.000e+01  3.446e+01  7.782e-01  5.905e-01  6.049e+00\n",
      "        2.504e+01]\n",
      " fun: 0.04744336361051194\n",
      "   x: [ 5.379e-02  3.000e+01  3.422e+01  7.797e-01  5.917e-01  6.176e+00\n",
      "        2.488e+01]\n",
      " fun: 0.047438289428852434\n",
      "   x: [ 5.353e-02  3.000e+01  3.394e+01  7.856e-01  5.923e-01  6.261e+00\n",
      "        2.471e+01]\n",
      " fun: 0.0474359889127054\n",
      "   x: [ 5.348e-02  3.000e+01  3.393e+01  8.024e-01  5.781e-01  6.291e+00\n",
      "        2.469e+01]\n",
      " fun: 0.047431885361170836\n",
      "   x: [ 5.166e-02  3.000e+01  3.375e+01  8.039e-01  5.799e-01  6.340e+00\n",
      "        2.458e+01]\n",
      " fun: 0.04741422288234876\n",
      "   x: [ 4.582e-02  3.000e+01  3.434e+01  7.981e-01  5.784e-01  6.530e+00\n",
      "        2.486e+01]\n",
      " fun: 0.04740118872954896\n",
      "   x: [ 3.658e-02  3.000e+01  3.553e+01  8.168e-01  5.847e-01  6.691e+00\n",
      "        2.549e+01]\n",
      " fun: 0.047396258663956796\n",
      "   x: [ 3.608e-02  3.000e+01  3.625e+01  8.225e-01  5.854e-01  6.700e+00\n",
      "        2.589e+01]\n",
      " fun: 0.04739471689774544\n",
      "   x: [ 3.418e-02  3.000e+01  3.671e+01  8.454e-01  5.928e-01  6.696e+00\n",
      "        2.614e+01]\n",
      " fun: 0.04739451366741728\n",
      "   x: [ 3.434e-02  3.000e+01  3.671e+01  8.473e-01  5.924e-01  6.692e+00\n",
      "        2.614e+01]\n",
      " fun: 0.04739328648477693\n",
      "   x: [ 3.470e-02  3.000e+01  3.679e+01  8.580e-01  5.899e-01  6.674e+00\n",
      "        2.615e+01]\n",
      " fun: 0.047391152942669844\n",
      "   x: [ 3.522e-02  3.000e+01  3.692e+01  8.686e-01  5.871e-01  6.656e+00\n",
      "        2.613e+01]\n",
      " fun: 0.047384687275751985\n",
      "   x: [ 3.637e-02  3.000e+01  3.733e+01  8.887e-01  5.814e-01  6.620e+00\n",
      "        2.607e+01]\n",
      " fun: 0.047370151850212996\n",
      "   x: [ 3.843e-02  3.000e+01  3.830e+01  9.150e-01  5.729e-01  6.567e+00\n",
      "        2.590e+01]\n",
      " fun: 0.047348490933599593\n",
      "   x: [ 4.212e-02  3.000e+01  4.000e+01  9.451e-01  5.567e-01  6.492e+00\n",
      "        2.549e+01]\n",
      " fun: 0.047328529763370514\n",
      "   x: [ 4.638e-02  3.000e+01  4.000e+01  9.188e-01  5.522e-01  6.466e+00\n",
      "        2.482e+01]\n",
      " fun: 0.04730803334505834\n",
      "   x: [ 5.744e-02  3.000e+01  4.000e+01  7.770e-01  5.458e-01  6.206e+00\n",
      "        2.314e+01]\n",
      " fun: 0.04729060699299441\n",
      "   x: [ 5.068e-02  3.000e+01  4.000e+01  8.204e-01  5.705e-01  6.350e+00\n",
      "        2.398e+01]\n",
      " fun: 0.047289761934152096\n",
      "   x: [ 5.215e-02  3.000e+01  4.000e+01  8.053e-01  5.737e-01  6.372e+00\n",
      "        2.394e+01]\n",
      " fun: 0.047288613580388175\n",
      "   x: [ 5.041e-02  3.000e+01  4.000e+01  8.010e-01  5.782e-01  6.367e+00\n",
      "        2.402e+01]\n",
      " fun: 0.047288206072590364\n",
      "   x: [ 4.927e-02  3.000e+01  4.000e+01  8.001e-01  5.805e-01  6.375e+00\n",
      "        2.404e+01]\n",
      " fun: 0.04728789796841611\n",
      "   x: [ 4.853e-02  3.000e+01  4.000e+01  8.005e-01  5.816e-01  6.392e+00\n",
      "        2.403e+01]\n",
      " fun: 0.04728766177716275\n",
      "   x: [ 4.817e-02  3.000e+01  4.000e+01  8.021e-01  5.811e-01  6.416e+00\n",
      "        2.399e+01]\n",
      " fun: 0.04728753150024133\n",
      "   x: [ 4.818e-02  3.000e+01  4.000e+01  8.021e-01  5.783e-01  6.433e+00\n",
      "        2.400e+01]\n",
      " fun: 0.04728751925497398\n",
      "   x: [ 4.810e-02  3.000e+01  4.000e+01  8.016e-01  5.775e-01  6.438e+00\n",
      "        2.402e+01]\n"
     ]
    }
   ],
   "source": [
    "# train sine cosine model\n",
    "\n",
    "N_train, N_test, M = 4096, 2048, 1024\n",
    "max_force = 15\n",
    "\n",
    "X, Y = generate_data_random_force_observed_noise(num_steps=N_train+N_test, max_force=max_force, y_std=Y_std, noise_factor=0.1)\n",
    "X = jnp.array(X)\n",
    "Y = jnp.array(Y)\n",
    "X_prime = X[:M]\n",
    "\n",
    "X_train = X[:N_train]\n",
    "Y_train = Y[:N_train]\n",
    "\n",
    "X_val = X[-N_test:]\n",
    "Y_val = Y[-N_test:]\n",
    "\n",
    "def loss(parameters):\n",
    "    lamb = parameters[0]\n",
    "    sigma = parameters[1:]\n",
    "    # train model\n",
    "    alpha, X_prime, _= train_nonlinear_models_j(X_train, Y_train, M=M, lamb=lamb, sigma=sigma, kernel_fn=kernel_expanded_j)\n",
    "\n",
    "    # predict using validation set\n",
    "    K_val = kernel_expanded_j(X_val, X_prime, sigma)\n",
    "    Y_pred = K_val @ alpha\n",
    "\n",
    "    mse = jnp.mean((Y_val - Y_pred) ** 2)\n",
    "    return mse\n",
    "\n",
    "# create a function that calculates the gradient of the loss function using jax.grad\n",
    "grad_loss = jax.grad(loss)\n",
    "\n",
    "initial_lamb = 1E-4\n",
    "std_force = max_force / (3**0.5)  # standard deviation for force\n",
    "x_sigma = get_std(X)\n",
    "# initial_sigma = jnp.array([6, 6, 0.5, 0.5, 6])\n",
    "std_sine, std_cos = (0.125)**0.5, (0.125)**0.5  # standard deviation for sine and cosine\n",
    "initial_sigma = jnp.array([x_sigma[0], x_sigma[1], std_sine, std_cos, x_sigma[-1], std_force])\n",
    "initial_hyperparameters = jnp.array([initial_lamb] + initial_sigma.tolist())\n",
    "\n",
    "losses = [loss(initial_hyperparameters)]\n",
    "\n",
    "def callback(intermediate_result):\n",
    "    print(intermediate_result)\n",
    "    losses.append(intermediate_result.fun)\n",
    "\n",
    "\n",
    "\n",
    "bounds = [(1E-6, 1E-1)] + [(0, 30)] + [(0, 40)] + [(0, 1)] * 2 +[(0, 10)] + [(0, max_force*3)]  # bounds for lamb and sigma\n",
    "res = scipy.optimize.minimize(loss, x0=initial_hyperparameters, method='L-BFGS-B', jac=grad_loss, bounds=bounds, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67785657",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, M, lamb = 4096, 1024, res.x[0]\n",
    "# N, M, lamb = 4096, 1024, 4.543e-03 # mine\n",
    "# N, M, lamb = 4096, 1024, 4.918e-04 # andrew\n",
    "max_force=15\n",
    "# generate training data\n",
    "X, Y = generate_data_random_force_observed_noise(num_steps=N, max_force=max_force, y_std=Y_std, noise_factor=0.1)\n",
    "\n",
    "# Get the standard deviation of X\n",
    "sigma = res.x[1:]\n",
    "# sigma = np.array([1.000e+01,  1.000e+01,  9.916e-01,  6.063e-01, 7.005e+00,  2.000e+01]) # mine\n",
    "# sigma = np.array([15.41,  1.413e+01,  5.24,  0.97, 7.356,  13.52])    # andrew\n",
    "\n",
    "# train model\n",
    "alpha, X_prime, K = train_nonlinear_models(X, Y, M=M, lamb=lamb, sigma=sigma, kernel_fn=kernel_expanded)\n",
    "\n",
    "# predict using training set\n",
    "Y_pred = K @ alpha\n",
    "\n",
    "# plot_fit(X, Y, Y_pred, graph_title=\"Fit of the model\")\n",
    "plot_fit(Y, Y_pred, graph_title=\"Change in state\")\n",
    "\n",
    "\n",
    "# Example initial states for testing\n",
    "initial_states = [[0, -2, np.pi, 4, 1], [0, 0, np.pi, 5, 2], [0, 0, np.pi, 0, 10], [0, 0, 0.1, 0, 8]]\n",
    "# initial_states = [[0, 0, np.pi, 0, 15]]\n",
    "for initial_state in initial_states:\n",
    "    forecast_nonlinear_force(initial_state, num_steps=100, alpha=alpha, sigma=sigma, X_prime=X_prime, kernel_fn=kernel_expanded)\n",
    "\n",
    "non_linear_model_sin_force_down = {\n",
    "    'lambda': res.x[0],\n",
    "    'sigma': res.x[1:],\n",
    "    'alpha': alpha,\n",
    "    'X_prime': X_prime,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0ba6aa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 44.73514973977988\n",
      "Iteration: 1\n",
      "P: [4.99979854 4.99934721 4.96191524 5.00002948]\n",
      "Loss: 44.73368200338194\n",
      "\n",
      "Iteration: 2\n",
      "P: [ 4.92894554  4.76962384 -8.32715493  5.01011429]\n",
      "Loss: 42.757886731917004\n",
      "\n",
      "Iteration: 3\n",
      "P: [ 3.89503935  1.62755109 -0.02973801  6.73723119]\n",
      "Loss: 33.902541640525826\n",
      "\n",
      "Iteration: 4\n",
      "P: [ 3.89823588  1.63726419 -0.05702683  6.73187845]\n",
      "Loss: 32.898943905470304\n",
      "\n",
      "Iteration: 5\n",
      "P: [ 3.46609999  1.24601196 -0.06442387  6.97179706]\n",
      "Loss: 30.66591333522328\n",
      "\n",
      "Iteration: 6\n",
      "P: [ 4.55362085 -0.69799225 -0.01469503  8.16387402]\n",
      "Loss: 29.006304247064907\n",
      "\n",
      "Iteration: 7\n",
      "P: [ 5.12638719 -1.47038746  0.00904864  8.63751215]\n",
      "Loss: 27.019404438762255\n",
      "\n",
      "Iteration: 8\n",
      "P: [ 4.88676845e+00 -1.59578100e+00  6.76968099e-03  8.66404382e+00]\n",
      "Loss: 23.829526068438884\n",
      "\n",
      "Iteration: 9\n",
      "P: [ 4.88276325e+00 -1.59732656e+00  6.69700724e-03  8.66400947e+00]\n",
      "Loss: 23.82840118468955\n",
      "\n",
      "Iteration: 10\n",
      "P: [ 4.85619387e+00 -1.60391652e+00  6.02260134e-03  8.66098125e+00]\n",
      "Loss: 23.810326841978256\n",
      "\n",
      "Iteration: 11\n",
      "P: [ 5.01617588e+00 -1.81275640e+00  2.40927811e-03  8.70953976e+00]\n",
      "Loss: 23.645932324544916\n",
      "\n",
      "Iteration: 12\n",
      "P: [ 5.10280170e+00 -1.92198281e+00  5.58519585e-04  8.73513222e+00]\n",
      "Loss: 23.570572420068324\n",
      "\n",
      "Iteration: 13\n",
      "P: [ 5.45206496e+00 -2.35855302e+00 -6.30592677e-03  8.82837899e+00]\n",
      "Loss: 23.35092956331096\n",
      "\n",
      "Iteration: 14\n",
      "P: [ 5.45783034e+00 -2.36556834e+00 -6.42311786e-03  8.83038558e+00]\n",
      "Loss: 23.345794567546918\n",
      "\n",
      "Iteration: 15\n",
      "P: [ 5.30251226e+00 -2.04763698e+00 -4.08908323e-03  9.01724331e+00]\n",
      "Loss: 18.16382652040654\n",
      "\n",
      "Iteration: 16\n",
      "P: [ 4.38240566 -1.24589145  0.02044327  9.4166229 ]\n",
      "Loss: 17.10776371099453\n",
      "\n",
      "Iteration: 17\n",
      "P: [ 4.36988096 -1.21964503  0.02062526  9.43236482]\n",
      "Loss: 16.86958131650712\n",
      "\n",
      "Iteration: 18\n",
      "P: [ 4.36948421 -1.2184024   0.02063024  9.43340418]\n",
      "Loss: 16.868660520216405\n",
      "\n",
      "Iteration: 19\n",
      "P: [ 4.37341426 -1.20770618  0.02043543  9.44403968]\n",
      "Loss: 16.852856403727944\n",
      "\n",
      "Iteration: 20\n",
      "P: [ 4.37595994 -1.20023666  0.02030651  9.45138353]\n",
      "Loss: 16.843733370045424\n",
      "\n",
      "Iteration: 21\n",
      "P: [ 4.37974201 -1.1877743   0.02010755  9.46373833]\n",
      "Loss: 16.832874835150015\n",
      "\n",
      "Iteration: 22\n",
      "P: [ 4.38217843 -1.17935985  0.01998075  9.47312967]\n",
      "Loss: 16.828741514498233\n",
      "\n",
      "Iteration: 23\n",
      "P: [ 4.3910117  -1.17268733  0.01973942  9.49757676]\n",
      "Loss: 16.82111871546271\n",
      "\n",
      "Iteration: 24\n",
      "P: [ 5.46363359e+00 -1.04914122e+00 -2.31241702e-03  1.17416065e+01]\n",
      "Loss: 14.40496398854805\n",
      "\n",
      "Iteration: 25\n",
      "P: [ 5.46330100e+00 -1.04918149e+00 -2.30555870e-03  1.17409110e+01]\n",
      "Loss: 13.886014033265353\n",
      "\n",
      "Iteration: 26\n",
      "P: [ 5.46228522e+00 -1.04882516e+00 -2.28963348e-03  1.17392091e+01]\n",
      "Loss: 13.881234102861116\n",
      "\n",
      "Iteration: 27\n",
      "P: [ 5.45198872e+00 -1.03977227e+00 -2.17845587e-03  1.17371177e+01]\n",
      "Loss: 13.822125415972373\n",
      "\n",
      "Iteration: 28\n",
      "P: [ 5.36112822e+00 -9.63846803e-01 -1.31526052e-03  1.17364724e+01]\n",
      "Loss: 10.45523739122053\n",
      "\n",
      "Iteration: 29\n",
      "P: [ 5.35999664e+00 -9.62979826e-01 -1.30379160e-03  1.17362479e+01]\n",
      "Loss: 10.386085869349964\n",
      "\n",
      "Iteration: 30\n",
      "P: [ 5.35720593e+00 -9.60954827e-01 -1.27355383e-03  1.17352110e+01]\n",
      "Loss: 10.245805551869308\n",
      "\n",
      "Iteration: 31\n",
      "P: [ 5.35693786e+00 -9.60857459e-01 -1.27045010e-03  1.17349724e+01]\n",
      "Loss: 10.237203337441153\n",
      "\n",
      "Iteration: 32\n",
      "P: [ 5.35533230e+00 -9.61178585e-01 -1.25151267e-03  1.17325310e+01]\n",
      "Loss: 10.210963002875891\n",
      "\n",
      "Iteration: 33\n",
      "P: [ 5.35389917e+00 -9.62496435e-01 -1.23553361e-03  1.17294439e+01]\n",
      "Loss: 10.194697056371455\n",
      "\n",
      "Iteration: 34\n",
      "P: [ 5.34278462e+00 -9.74835361e-01 -1.11336841e-03  1.17036108e+01]\n",
      "Loss: 10.081742028286943\n",
      "\n",
      "Iteration: 35\n",
      "P: [ 5.33458829e+00 -9.85142907e-01 -1.02050460e-03  1.16827760e+01]\n",
      "Loss: 10.01875479359205\n",
      "\n",
      "Iteration: 36\n",
      "P: [ 5.31774984e+00 -1.00336851e+00 -8.39449333e-04  1.16448808e+01]\n",
      "Loss: 9.951309074769997\n",
      "\n",
      "Iteration: 37\n",
      "P: [ 5.30738790e+00 -1.01281980e+00 -7.38362623e-04  1.16253399e+01]\n",
      "Loss: 9.887065793129757\n",
      "\n",
      "Iteration: 38\n",
      "P: [ 5.30321285e+00 -1.01673555e+00 -6.97154458e-04  1.16172650e+01]\n",
      "Loss: 9.875971263337716\n",
      "\n",
      "Iteration: 39\n",
      "P: [ 5.30003143e+00 -1.01940406e+00 -6.67702969e-04  1.16118068e+01]\n",
      "Loss: 9.862145663127423\n",
      "\n",
      "Iteration: 40\n",
      "P: [ 5.29626244e+00 -1.02257584e+00 -6.32802407e-04  1.16053280e+01]\n",
      "Loss: 9.8504874941862\n",
      "\n",
      "Iteration: 41\n",
      "P: [ 5.28363989e+00 -1.03223359e+00 -5.21898667e-04  1.15857616e+01]\n",
      "Loss: 9.817545548486036\n",
      "\n",
      "Iteration: 42\n",
      "P: [ 5.28231773e+00 -1.03286746e+00 -5.12663088e-04  1.15845538e+01]\n",
      "Loss: 9.807677118465328\n",
      "\n",
      "Iteration: 43\n",
      "P: [ 5.27831510e+00 -1.03564733e+00 -4.79310006e-04  1.15789851e+01]\n",
      "Loss: 9.797428119047588\n",
      "\n",
      "Iteration: 44\n",
      "P: [ 5.27784126e+00 -1.03596762e+00 -4.75418227e-04  1.15783457e+01]\n",
      "Loss: 9.796486486674342\n",
      "\n",
      "Iteration: 45\n",
      "P: [ 5.27485181e+00 -1.03791953e+00 -4.51320403e-04  1.15744690e+01]\n",
      "Loss: 9.791746383067784\n",
      "\n",
      "Iteration: 46\n",
      "P: [ 5.27270225e+00 -1.03922200e+00 -4.34633862e-04  1.15719076e+01]\n",
      "Loss: 9.787508064438493\n",
      "\n",
      "Iteration: 47\n",
      "P: [ 5.26876274e+00 -1.04135549e+00 -4.05644694e-04  1.15677781e+01]\n",
      "Loss: 9.77510246119615\n",
      "\n",
      "Iteration: 48\n",
      "P: [ 5.26495227e+00 -1.04335932e+00 -3.77979444e-04  1.15639170e+01]\n",
      "Loss: 9.767458047168416\n",
      "\n",
      "Iteration: 49\n",
      "P: [ 5.25835896e+00 -1.04624463e+00 -3.33766896e-04  1.15585335e+01]\n",
      "Loss: 9.751293836281985\n",
      "\n",
      "Iteration: 50\n",
      "P: [ 5.21528344e+00 -1.06658533e+00 -3.55476878e-05  1.15200387e+01]\n",
      "Loss: 9.20663091667229\n",
      "\n",
      "Iteration: 51\n",
      "P: [ 5.21394894e+00 -1.06652857e+00 -3.05884791e-05  1.15203778e+01]\n",
      "Loss: 9.199337827213823\n",
      "\n",
      "Iteration: 52\n",
      "P: [ 5.20726050e+00 -1.06043780e+00 -4.19171417e-05  1.15350235e+01]\n",
      "Loss: 9.104343296883085\n",
      "\n",
      "Iteration: 53\n",
      "P: [ 5.19223336e+00 -1.05252952e+00 -3.08769507e-05  1.15548273e+01]\n",
      "Loss: 8.9898604709587\n",
      "\n",
      "Iteration: 54\n",
      "P: [ 5.18871616e+00 -1.05953374e+00  2.86209487e-05  1.15389815e+01]\n",
      "Loss: 8.873272158248321\n",
      "\n",
      "Iteration: 55\n",
      "P: [ 5.18228223e+00 -1.06025316e+00  5.94841507e-05  1.15380668e+01]\n",
      "Loss: 8.787379334012437\n",
      "\n",
      "Iteration: 56\n",
      "P: [ 5.17968539e+00 -1.06136390e+00  7.72179344e-05  1.15357987e+01]\n",
      "Loss: 8.775709893104448\n",
      "\n",
      "Iteration: 57\n",
      "P: [ 5.17819589e+00 -1.06512684e+00  1.07208358e-04  1.15273729e+01]\n",
      "Loss: 8.757109996588982\n",
      "\n",
      "Iteration: 58\n",
      "P: [ 5.17519221e+00 -1.07767808e+00  1.99449946e-04  1.14989933e+01]\n",
      "Loss: 8.70696444846679\n",
      "\n",
      "Iteration: 59\n",
      "P: [ 5.17433287e+00 -1.07667654e+00  1.97291118e-04  1.15012282e+01]\n",
      "Loss: 8.70317134095304\n",
      "\n",
      "Iteration: 60\n",
      "P: [ 5.17076785e+00 -1.08232154e+00  2.50736033e-04  1.14880923e+01]\n",
      "Loss: 8.672660841774631\n",
      "\n",
      "Iteration: 61\n",
      "P: [ 5.16868702e+00 -1.08510332e+00  2.78151310e-04  1.14817066e+01]\n",
      "Loss: 8.656601465949462\n",
      "\n",
      "Iteration: 62\n",
      "P: [ 5.16794865e+00 -1.08623968e+00  2.88885200e-04  1.14790877e+01]\n",
      "Loss: 8.65289781470047\n",
      "\n",
      "Iteration: 63\n",
      "P: [ 5.16693501e+00 -1.08861834e+00  3.08871886e-04  1.14736118e+01]\n",
      "Loss: 8.648569059562066\n",
      "\n",
      "Iteration: 64\n",
      "P: [ 5.16604412e+00 -1.09142866e+00  3.31132789e-04  1.14671288e+01]\n",
      "Loss: 8.644365752327362\n",
      "\n",
      "Iteration: 65\n",
      "P: [ 5.16492039e+00 -1.09414689e+00  3.54187836e-04  1.14607883e+01]\n",
      "Loss: 8.635516125939724\n",
      "\n",
      "Iteration: 66\n",
      "P: [ 5.16317171e+00 -1.09817385e+00  3.88023892e-04  1.14514935e+01]\n",
      "Loss: 8.618667595757053\n",
      "\n",
      "Iteration: 67\n",
      "P: [ 5.16223991e+00 -1.10023162e+00  4.05588063e-04  1.14467340e+01]\n",
      "Loss: 8.614197915642228\n",
      "\n",
      "Iteration: 68\n",
      "P: [ 5.16102553e+00 -1.10302691e+00  4.29082571e-04  1.14402846e+01]\n",
      "Loss: 8.609647583709735\n",
      "\n",
      "Iteration: 69\n",
      "P: [ 5.15989855e+00 -1.10581363e+00  4.51866590e-04  1.14338887e+01]\n",
      "Loss: 8.602671050714797\n",
      "\n",
      "Iteration: 70\n",
      "P: [ 5.15695893e+00 -1.10396267e+00  4.43651002e-04  1.14397163e+01]\n",
      "Loss: 8.586374691634203\n",
      "\n",
      "Iteration: 71\n",
      "P: [ 5.15648062e+00 -1.10683670e+00  4.57164978e-04  1.14342696e+01]\n",
      "Loss: 8.583244041703022\n",
      "\n",
      "Iteration: 72\n",
      "P: [ 5.15455110e+00 -1.11068610e+00  4.82643548e-04  1.14267090e+01]\n",
      "Loss: 8.559995730259631\n",
      "\n",
      "Iteration: 73\n",
      "P: [ 5.15441249e+00 -1.11096904e+00  4.84362064e-04  1.14261765e+01]\n",
      "Loss: 8.559328434554725\n",
      "\n",
      "Iteration: 74\n",
      "P: [ 5.15388431e+00 -1.11148655e+00  4.85530352e-04  1.14257362e+01]\n",
      "Loss: 8.55630681253462\n",
      "\n",
      "Iteration: 75\n",
      "P: [ 5.15326852e+00 -1.11217609e+00  4.84593249e-04  1.14255023e+01]\n",
      "Loss: 8.551550042883672\n",
      "\n",
      "Iteration: 76\n",
      "P: [ 5.15283627e+00 -1.11377715e+00  4.83792945e-04  1.14239919e+01]\n",
      "Loss: 8.540076722988347\n",
      "\n",
      "Iteration: 77\n",
      "P: [ 5.15291661e+00 -1.11808455e+00  4.69298642e-04  1.14210949e+01]\n",
      "Loss: 8.5045984611949\n",
      "\n",
      "Iteration: 78\n",
      "P: [ 5.15287253e+00 -1.11865062e+00  4.68117073e-04  1.14206329e+01]\n",
      "Loss: 8.50117661365818\n",
      "\n",
      "Iteration: 79\n",
      "P: [ 5.15282400e+00 -1.12238928e+00  4.50963184e-04  1.14189749e+01]\n",
      "Loss: 8.489598273562397\n",
      "\n",
      "Iteration: 80\n",
      "P: [ 5.15323159e+00 -1.12269853e+00  4.48517709e-04  1.14187101e+01]\n",
      "Loss: 8.473299172610977\n",
      "\n",
      "Iteration: 81\n",
      "P: [ 5.15398163e+00 -1.12666673e+00  4.25243315e-04  1.14172173e+01]\n",
      "Loss: 8.44721374350566\n",
      "\n",
      "Iteration: 82\n",
      "P: [ 5.15429565e+00 -1.12850333e+00  4.14830577e-04  1.14164901e+01]\n",
      "Loss: 8.436083507100927\n",
      "\n",
      "Iteration: 83\n",
      "P: [ 5.15444257e+00 -1.12921579e+00  4.10412502e-04  1.14162535e+01]\n",
      "Loss: 8.432192038219414\n",
      "\n",
      "Iteration: 84\n",
      "P: [ 5.15505336e+00 -1.13181238e+00  3.93367897e-04  1.14154955e+01]\n",
      "Loss: 8.419876254869436\n",
      "\n",
      "Iteration: 85\n",
      "P: [ 5.15577228e+00 -1.13437493e+00  3.75304766e-04  1.14148733e+01]\n",
      "Loss: 8.40914349302094\n",
      "\n",
      "Iteration: 86\n",
      "P: [ 5.15782238e+00 -1.14038278e+00  3.28846562e-04  1.14138474e+01]\n",
      "Loss: 8.376399791418697\n",
      "\n",
      "Iteration: 87\n",
      "P: [ 5.16347685e+00 -1.15373354e+00  2.06485671e-04  1.14140175e+01]\n",
      "Loss: 8.293420780542133\n",
      "\n",
      "Iteration: 88\n",
      "P: [ 5.16402890e+00 -1.15509220e+00  1.94402562e-04  1.14139891e+01]\n",
      "Loss: 8.284570464381222\n",
      "\n",
      "Iteration: 89\n",
      "P: [ 5.16463729e+00 -1.15649845e+00  1.81242381e-04  1.14140440e+01]\n",
      "Loss: 8.278465930785943\n",
      "\n",
      "Iteration: 90\n",
      "P: [ 5.16557810e+00 -1.15860326e+00  1.61014752e-04  1.14141944e+01]\n",
      "Loss: 8.271822508582305\n",
      "\n",
      "Iteration: 91\n",
      "P: [ 5.16686840e+00 -1.16133801e+00  1.33487159e-04  1.14145529e+01]\n",
      "Loss: 8.262910680547625\n",
      "\n",
      "Iteration: 92\n",
      "P: [ 5.16870117e+00 -1.16494601e+00  9.48088435e-05  1.14153343e+01]\n",
      "Loss: 8.239657261028446\n",
      "\n",
      "Iteration: 93\n",
      "P: [ 5.17096556e+00 -1.16911767e+00  4.77767836e-05  1.14165295e+01]\n",
      "Loss: 8.21875551324088\n",
      "\n",
      "Iteration: 94\n",
      "P: [ 5.18427446e+00 -1.19470325e+00 -2.30960458e-04  1.14226150e+01]\n",
      "Loss: 7.7425995581946605\n",
      "\n",
      "Iteration: 95\n",
      "P: [ 5.18423106e+00 -1.19461663e+00 -2.30018897e-04  1.14225938e+01]\n",
      "Loss: 7.742532892310853\n",
      "\n",
      "Iteration: 96\n",
      "P: [ 5.18893313e+00 -1.20042265e+00 -3.11529840e-04  1.14260204e+01]\n",
      "Loss: 7.689396857924502\n",
      "\n",
      "Iteration: 97\n",
      "P: [ 5.20294376e+00 -1.21869404e+00 -5.59949209e-04  1.14359213e+01]\n",
      "Loss: 7.684753187677728\n",
      "\n",
      "Iteration: 98\n",
      "P: [ 5.20928441e+00 -1.22698455e+00 -6.72496430e-04  1.14403950e+01]\n",
      "Loss: 7.529679416374801\n",
      "\n",
      "Iteration: 99\n",
      "P: [ 5.20935797e+00 -1.22708046e+00 -6.73800457e-04  1.14404470e+01]\n",
      "Loss: 7.52955269432487\n",
      "\n",
      "Iteration: 100\n",
      "P: [ 5.20968355e+00 -1.22750266e+00 -6.79422600e-04  1.14406555e+01]\n",
      "Loss: 7.528620349664568\n",
      "\n",
      "Iteration: 101\n",
      "P: [ 5.21037789e+00 -1.22840112e+00 -6.91270749e-04  1.14410797e+01]\n",
      "Loss: 7.526286479514756\n",
      "\n",
      "Iteration: 102\n",
      "P: [ 5.21192720e+00 -1.23040303e+00 -7.17480828e-04  1.14419927e+01]\n",
      "Loss: 7.521554340786775\n",
      "\n",
      "Iteration: 103\n",
      "P: [ 5.21292967e+00 -1.23169569e+00 -7.34113149e-04  1.14425336e+01]\n",
      "Loss: 7.513248957239386\n",
      "\n",
      "Iteration: 104\n",
      "P: [ 5.21527266e+00 -1.23467456e+00 -7.72836069e-04  1.14438306e+01]\n",
      "Loss: 7.497424298619498\n",
      "\n",
      "Iteration: 105\n",
      "P: [ 5.21565752e+00 -1.23516654e+00 -7.79249507e-04  1.14440487e+01]\n",
      "Loss: 7.495668193834474\n",
      "\n",
      "Iteration: 106\n",
      "P: [ 5.21632558e+00 -1.23601678e+00 -7.90323505e-04  1.14444228e+01]\n",
      "Loss: 7.492739355181099\n",
      "\n",
      "Iteration: 107\n",
      "P: [ 5.21729418e+00 -1.23724518e+00 -8.06330909e-04  1.14449634e+01]\n",
      "Loss: 7.489111821160472\n",
      "\n",
      "Iteration: 108\n",
      "P: [ 5.21821464e+00 -1.23840615e+00 -8.21457599e-04  1.14454725e+01]\n",
      "Loss: 7.48594774320221\n",
      "\n",
      "Iteration: 109\n",
      "P: [ 5.22023043e+00 -1.24093533e+00 -8.54187712e-04  1.14465460e+01]\n",
      "Loss: 7.478749823275405\n",
      "\n",
      "Iteration: 110\n",
      "P: [ 5.22217096e+00 -1.24335415e+00 -8.84727122e-04  1.14474598e+01]\n",
      "Loss: 7.465127512739793\n",
      "\n",
      "Iteration: 111\n",
      "P: [ 5.22298277e+00 -1.24436911e+00 -8.97658273e-04  1.14478607e+01]\n",
      "Loss: 7.4620451627239905\n",
      "\n",
      "Iteration: 112\n",
      "P: [ 5.22387342e+00 -1.24548094e+00 -9.11725292e-04  1.14482855e+01]\n",
      "Loss: 7.458521711499735\n",
      "\n",
      "Iteration: 113\n",
      "P: [ 5.22577656e+00 -1.24785496e+00 -9.41543432e-04  1.14491613e+01]\n",
      "Loss: 7.4517021968535735\n",
      "\n",
      "Iteration: 114\n",
      "P: [ 5.22781691e+00 -1.25039275e+00 -9.73149972e-04  1.14500594e+01]\n",
      "Loss: 7.443692981400789\n",
      "\n",
      "Iteration: 115\n",
      "P: [ 5.23540332e+00 -1.25964926e+00 -1.08837713e-03  1.14533636e+01]\n",
      "Loss: 7.411330065040872\n",
      "\n",
      "Iteration: 116\n",
      "P: [ 5.23594339e+00 -1.26030995e+00 -1.09661380e-03  1.14536009e+01]\n",
      "Loss: 7.4098062191798855\n",
      "\n",
      "Iteration: 117\n",
      "P: [ 5.23776999e+00 -1.26252529e+00 -1.12421623e-03  1.14543984e+01]\n",
      "Loss: 7.403951360701215\n",
      "\n",
      "Iteration: 118\n",
      "P: [ 5.23930247e+00 -1.26437776e+00 -1.14729799e-03  1.14550671e+01]\n",
      "Loss: 7.399156190875269\n",
      "\n",
      "Iteration: 119\n",
      "P: [ 5.24228325e+00 -1.26797155e+00 -1.19199876e-03  1.14563574e+01]\n",
      "Loss: 7.3897696681261795\n",
      "\n",
      "Iteration: 120\n",
      "P: [ 5.24842431e+00 -1.27538224e+00 -1.28324349e-03  1.14589025e+01]\n",
      "Loss: 7.373368337605164\n",
      "\n",
      "Iteration: 121\n",
      "P: [ 5.25041657e+00 -1.27779860e+00 -1.31227310e-03  1.14596410e+01]\n",
      "Loss: 7.360015487676845\n",
      "\n",
      "Iteration: 122\n",
      "P: [ 5.25290290e+00 -1.28080291e+00 -1.34894428e-03  1.14606330e+01]\n",
      "Loss: 7.3519102366336755\n",
      "\n",
      "Iteration: 123\n",
      "P: [ 5.25313334e+00 -1.28108159e+00 -1.35233324e-03  1.14607235e+01]\n",
      "Loss: 7.351432137330278\n",
      "\n",
      "Iteration: 124\n",
      "P: [ 5.25580925e+00 -1.28431978e+00 -1.39154612e-03  1.14617551e+01]\n",
      "Loss: 7.348468192152024\n",
      "\n",
      "Iteration: 125\n",
      "P: [ 5.25571998e+00 -1.28421085e+00 -1.39010630e-03  1.14617088e+01]\n",
      "Loss: 7.343009525636559\n",
      "\n",
      "Iteration: 126\n",
      "P: [ 5.25797257e+00 -1.28693553e+00 -1.42286506e-03  1.14625538e+01]\n",
      "Loss: 7.335634245974186\n",
      "\n",
      "Iteration: 127\n",
      "P: [ 5.27424898e+00 -1.30662268e+00 -1.65980999e-03  1.14686853e+01]\n",
      "Loss: 7.301366777969208\n",
      "\n",
      "Iteration: 128\n",
      "P: [ 5.27737617e+00 -1.31037571e+00 -1.70464548e-03  1.14698740e+01]\n",
      "Loss: 7.296590527788349\n",
      "\n",
      "Iteration: 129\n",
      "P: [ 5.30485158e+00 -1.34315733e+00 -2.09407889e-03  1.14803882e+01]\n",
      "Loss: 7.205491165235168\n",
      "\n",
      "Iteration: 130\n",
      "P: [ 5.30570442e+00 -1.34416033e+00 -2.10580882e-03  1.14807188e+01]\n",
      "Loss: 7.1720444643239185\n",
      "\n",
      "Iteration: 131\n",
      "P: [ 5.31347434e+00 -1.35340044e+00 -2.21520081e-03  1.14837017e+01]\n",
      "Loss: 7.1420481503024345\n",
      "\n",
      "Iteration: 132\n",
      "P: [ 5.31488156e+00 -1.35507519e+00 -2.23504465e-03  1.14842416e+01]\n",
      "Loss: 7.139051302217766\n",
      "\n",
      "Iteration: 133\n",
      "P: [ 5.31989732e+00 -1.36103698e+00 -2.30558865e-03  1.14861684e+01]\n",
      "Loss: 7.133732042479243\n",
      "\n",
      "Iteration: 134\n",
      "P: [ 5.31925575e+00 -1.36027090e+00 -2.29648435e-03  1.14859234e+01]\n",
      "Loss: 7.124525387608334\n",
      "\n",
      "Iteration: 135\n",
      "P: [ 5.32213718e+00 -1.36369001e+00 -2.33687539e-03  1.14870328e+01]\n",
      "Loss: 7.115428944693211\n",
      "\n",
      "Iteration: 136\n",
      "P: [ 5.32592671e+00 -1.36818843e+00 -2.39003640e-03  1.14884911e+01]\n",
      "Loss: 7.108168214057137\n",
      "\n",
      "Iteration: 137\n",
      "P: [ 5.32628361e+00 -1.36861079e+00 -2.39501179e-03  1.14886290e+01]\n",
      "Loss: 7.10481035490905\n",
      "\n",
      "Iteration: 138\n",
      "P: [ 5.32892892e+00 -1.37174680e+00 -2.43202158e-03  1.14896488e+01]\n",
      "Loss: 7.0975632240619575\n",
      "\n",
      "Iteration: 139\n",
      "P: [ 5.33288097e+00 -1.37642979e+00 -2.48722054e-03  1.14911736e+01]\n",
      "Loss: 7.085197422605531\n",
      "\n",
      "Iteration: 140\n",
      "P: [ 5.33643425e+00 -1.38063958e+00 -2.53681560e-03  1.14925449e+01]\n",
      "Loss: 7.078760083670215\n",
      "\n",
      "Iteration: 141\n",
      "P: [ 5.34091043e+00 -1.38593862e+00 -2.59914486e-03  1.14942746e+01]\n",
      "Loss: 7.0648859814154\n",
      "\n",
      "Iteration: 142\n",
      "P: [ 5.34093366e+00 -1.38596589e+00 -2.59945897e-03  1.14942837e+01]\n",
      "Loss: 7.063902241866785\n",
      "\n",
      "Iteration: 143\n",
      "P: [ 5.34473439e+00 -1.39046438e+00 -2.65233531e-03  1.14957529e+01]\n",
      "Loss: 7.05808852071321\n",
      "\n",
      "Iteration: 144\n",
      "P: [ 5.34476254e+00 -1.39049695e+00 -2.65269366e-03  1.14957642e+01]\n",
      "Loss: 7.053887937208615\n",
      "\n",
      "Iteration: 145\n",
      "P: [ 5.34771437e+00 -1.39398956e+00 -2.69370941e-03  1.14969059e+01]\n",
      "Loss: 7.04880318574444\n",
      "\n",
      "Iteration: 146\n",
      "P: [ 5.34880258e+00 -1.39527661e+00 -2.70880627e-03  1.14973271e+01]\n",
      "Loss: 7.045496764097673\n",
      "\n",
      "Iteration: 147\n",
      "P: [ 5.34926082e+00 -1.39581822e+00 -2.71514509e-03  1.14975047e+01]\n",
      "Loss: 7.042951628191785\n",
      "\n",
      "Iteration: 148\n",
      "P: [ 5.35118327e+00 -1.39809199e+00 -2.74181534e-03  1.14982488e+01]\n",
      "Loss: 7.038987417738969\n",
      "\n",
      "Iteration: 149\n",
      "P: [ 5.35212275e+00 -1.39920303e+00 -2.75484298e-03  1.14986124e+01]\n",
      "Loss: 7.037932066661245\n",
      "\n",
      "Iteration: 150\n",
      "P: [ 5.35306469e+00 -1.40031672e+00 -2.76789150e-03  1.14989772e+01]\n",
      "Loss: 7.035493278486703\n",
      "\n",
      "Iteration: 151\n",
      "P: [ 5.35505004e+00 -1.40266388e+00 -2.79536958e-03  1.14997462e+01]\n",
      "Loss: 7.0293811023696415\n",
      "\n",
      "Iteration: 152\n",
      "P: [ 5.35584074e+00 -1.40359876e+00 -2.80631935e-03  1.15000524e+01]\n",
      "Loss: 7.028202543520487\n",
      "\n",
      "Iteration: 153\n",
      "P: [ 5.35713785e+00 -1.40513221e+00 -2.82426890e-03  1.15005549e+01]\n",
      "Loss: 7.026136702749981\n",
      "\n",
      "Iteration: 154\n",
      "P: [ 5.35857821e+00 -1.40683479e+00 -2.84418393e-03  1.15011129e+01]\n",
      "Loss: 7.022695405900677\n",
      "\n",
      "Iteration: 155\n",
      "P: [ 5.36010236e+00 -1.40863760e+00 -2.86523039e-03  1.15017028e+01]\n",
      "Loss: 7.0181838664829765\n",
      "\n",
      "Iteration: 156\n",
      "P: [ 5.36100051e+00 -1.40969969e+00 -2.87764303e-03  1.15020505e+01]\n",
      "Loss: 7.015907913903925\n",
      "\n",
      "Iteration: 157\n",
      "P: [ 5.36163902e+00 -1.41045480e+00 -2.88646546e-03  1.15022977e+01]\n",
      "Loss: 7.0148057939504005\n",
      "\n",
      "Iteration: 158\n",
      "P: [ 5.36295811e+00 -1.41201490e+00 -2.90468720e-03  1.15028083e+01]\n",
      "Loss: 7.014309788821048\n",
      "\n",
      "Iteration: 159\n",
      "P: [ 5.36256348e+00 -1.41154826e+00 -2.89923258e-03  1.15026555e+01]\n",
      "Loss: 7.013349812557656\n",
      "\n",
      "Iteration: 160\n",
      "P: [ 5.36274925e+00 -1.41176816e+00 -2.90179120e-03  1.15027273e+01]\n",
      "Loss: 7.012191132168223\n",
      "\n",
      "Iteration: 161\n",
      "P: [ 5.36397118e+00 -1.41321389e+00 -2.91865127e-03  1.15032000e+01]\n",
      "Loss: 7.009390642872724\n",
      "\n",
      "Iteration: 162\n",
      "P: [ 5.36471873e+00 -1.41409832e+00 -2.92896740e-03  1.15034892e+01]\n",
      "Loss: 7.007958691680853\n",
      "\n",
      "Iteration: 163\n",
      "P: [ 5.36565206e+00 -1.41520261e+00 -2.94184411e-03  1.15038503e+01]\n",
      "Loss: 7.006712582515549\n",
      "\n",
      "Iteration: 164\n",
      "P: [ 5.36657929e+00 -1.41629986e+00 -2.95463073e-03  1.15042088e+01]\n",
      "Loss: 7.005462677215451\n",
      "\n",
      "Iteration: 165\n",
      "P: [ 5.36754800e+00 -1.41744650e+00 -2.96797892e-03  1.15045833e+01]\n",
      "Loss: 7.002716167248121\n",
      "\n",
      "Iteration: 166\n",
      "P: [ 5.36886577e+00 -1.41900671e+00 -2.98612372e-03  1.15050925e+01]\n",
      "Loss: 6.998969424582608\n",
      "\n",
      "Iteration: 167\n",
      "P: [ 5.36956718e+00 -1.41983699e+00 -2.99578750e-03  1.15053636e+01]\n",
      "Loss: 6.997519023484173\n",
      "\n",
      "Iteration: 168\n",
      "P: [ 5.37031711e+00 -1.42072479e+00 -3.00611730e-03  1.15056534e+01]\n",
      "Loss: 6.996481329215829\n",
      "\n",
      "Iteration: 169\n",
      "P: [ 5.37128080e+00 -1.42186576e+00 -3.01938698e-03  1.15060258e+01]\n",
      "Loss: 6.995630710213264\n",
      "\n",
      "Iteration: 170\n",
      "P: [ 5.37160619e+00 -1.42225117e+00 -3.02386203e-03  1.15061515e+01]\n",
      "Loss: 6.99419672525425\n",
      "\n",
      "Iteration: 171\n",
      "P: [ 5.37324718e+00 -1.42419477e+00 -3.04643341e-03  1.15067851e+01]\n",
      "Loss: 6.990031702705869\n",
      "\n",
      "Iteration: 172\n",
      "P: [ 5.37422633e+00 -1.42535450e+00 -3.05990142e-03  1.15071632e+01]\n",
      "Loss: 6.988625643036412\n",
      "\n",
      "Iteration: 173\n",
      "P: [ 5.37622297e+00 -1.42771990e+00 -3.08734533e-03  1.15079340e+01]\n",
      "Loss: 6.984865264175552\n",
      "\n",
      "Iteration: 174\n",
      "P: [ 5.37667106e+00 -1.42825110e+00 -3.09349364e-03  1.15081067e+01]\n",
      "Loss: 6.982875343147418\n",
      "\n",
      "Iteration: 175\n",
      "P: [ 5.37792647e+00 -1.42973861e+00 -3.11074191e-03  1.15085912e+01]\n",
      "Loss: 6.980735535704865\n",
      "\n",
      "Iteration: 176\n",
      "P: [ 5.37859486e+00 -1.43053066e+00 -3.11992257e-03  1.15088491e+01]\n",
      "Loss: 6.980118043073075\n",
      "\n",
      "Iteration: 177\n",
      "P: [ 5.37919078e+00 -1.43123699e+00 -3.12810258e-03  1.15090789e+01]\n",
      "Loss: 6.97870965182797\n",
      "\n",
      "Iteration: 178\n",
      "P: [ 5.38049066e+00 -1.43277800e+00 -3.14593675e-03  1.15095801e+01]\n",
      "Loss: 6.975276135042206\n",
      "\n",
      "Iteration: 179\n",
      "P: [ 5.38104974e+00 -1.43344070e+00 -3.15361015e-03  1.15097958e+01]\n",
      "Loss: 6.974490612360631\n",
      "\n",
      "Iteration: 180\n",
      "P: [ 5.38181968e+00 -1.43435346e+00 -3.16417360e-03  1.15100926e+01]\n",
      "Loss: 6.973489303500478\n",
      "\n",
      "Iteration: 181\n",
      "P: [ 5.38283501e+00 -1.43555731e+00 -3.17809802e-03  1.15104840e+01]\n",
      "Loss: 6.971894239060673\n",
      "\n",
      "Iteration: 182\n",
      "P: [ 5.38377295e+00 -1.43666972e+00 -3.19095165e-03  1.15108454e+01]\n",
      "Loss: 6.969033339134965\n",
      "\n",
      "Iteration: 183\n",
      "P: [ 5.38471573e+00 -1.43778774e+00 -3.20387549e-03  1.15112087e+01]\n",
      "Loss: 6.967945449325958\n",
      "\n",
      "Iteration: 184\n",
      "P: [ 5.38620008e+00 -1.43954838e+00 -3.22421114e-03  1.15117805e+01]\n",
      "Loss: 6.965416523095338\n",
      "\n",
      "Iteration: 185\n",
      "P: [ 5.38695653e+00 -1.44044614e+00 -3.23455925e-03  1.15120717e+01]\n",
      "Loss: 6.9639746553301975\n",
      "\n",
      "Iteration: 186\n",
      "P: [ 5.38813131e+00 -1.44183977e+00 -3.25064876e-03  1.15125241e+01]\n",
      "Loss: 6.960610546898668\n",
      "\n",
      "Iteration: 187\n",
      "P: [ 5.38847615e+00 -1.44224888e+00 -3.25537080e-03  1.15126569e+01]\n",
      "Loss: 6.960265553111947\n",
      "\n",
      "Iteration: 188\n",
      "P: [ 5.38879472e+00 -1.44262685e+00 -3.25973167e-03  1.15127796e+01]\n",
      "Loss: 6.959930457265437\n",
      "\n",
      "Iteration: 189\n",
      "P: [ 5.38949699e+00 -1.44346018e+00 -3.26934302e-03  1.15130499e+01]\n",
      "Loss: 6.959122664917243\n",
      "\n",
      "Iteration: 190\n",
      "P: [ 5.39006784e+00 -1.44413767e+00 -3.27715219e-03  1.15132696e+01]\n",
      "Loss: 6.957839631074898\n",
      "\n",
      "Iteration: 191\n",
      "P: [ 5.39107878e+00 -1.44533771e+00 -3.29097457e-03  1.15136586e+01]\n",
      "Loss: 6.9550666068757145\n",
      "\n",
      "Iteration: 192\n",
      "P: [ 5.39168332e+00 -1.44605523e+00 -3.29924371e-03  1.15138912e+01]\n",
      "Loss: 6.954183761896333\n",
      "\n",
      "Iteration: 193\n",
      "P: [ 5.39243730e+00 -1.44695020e+00 -3.30955403e-03  1.15141813e+01]\n",
      "Loss: 6.953450215209635\n",
      "\n",
      "Iteration: 194\n",
      "P: [ 5.39292300e+00 -1.44752685e+00 -3.31619253e-03  1.15143681e+01]\n",
      "Loss: 6.952369633732722\n",
      "\n",
      "Iteration: 195\n",
      "P: [ 5.39396204e+00 -1.44876066e+00 -3.33038712e-03  1.15147677e+01]\n",
      "Loss: 6.949781343827835\n",
      "\n",
      "Iteration: 196\n",
      "P: [ 5.39446920e+00 -1.44936282e+00 -3.33731823e-03  1.15149627e+01]\n",
      "Loss: 6.948942597223543\n",
      "\n",
      "Iteration: 197\n",
      "P: [ 5.39510592e+00 -1.45011884e+00 -3.34601800e-03  1.15152076e+01]\n",
      "Loss: 6.948274230706394\n",
      "\n",
      "Iteration: 198\n",
      "P: [ 5.39563022e+00 -1.45074147e+00 -3.35317954e-03  1.15154091e+01]\n",
      "Loss: 6.947582259692016\n",
      "\n",
      "Iteration: 199\n",
      "P: [ 5.39652250e+00 -1.45180125e+00 -3.36536271e-03  1.15157521e+01]\n",
      "Loss: 6.945726870935806\n",
      "\n",
      "Iteration: 200\n",
      "P: [ 5.39737067e+00 -1.45280886e+00 -3.37693767e-03  1.15160780e+01]\n",
      "Loss: 6.943614556423233\n",
      "\n",
      "Iteration: 201\n",
      "P: [ 5.39787505e+00 -1.45340796e+00 -3.38382330e-03  1.15162718e+01]\n",
      "Loss: 6.942815885753904\n",
      "\n",
      "Iteration: 202\n",
      "P: [ 5.39848709e+00 -1.45413500e+00 -3.39217725e-03  1.15165070e+01]\n",
      "Loss: 6.942173757234432\n",
      "\n",
      "Iteration: 203\n",
      "P: [ 5.39905082e+00 -1.45480472e+00 -3.39986949e-03  1.15167236e+01]\n",
      "Loss: 6.941472092773251\n",
      "\n",
      "Iteration: 204\n",
      "P: [ 5.39982519e+00 -1.45572485e+00 -3.41043181e-03  1.15170211e+01]\n",
      "Loss: 6.9397696838140295\n",
      "\n",
      "Iteration: 205\n",
      "P: [ 5.40065230e+00 -1.45670782e+00 -3.42170840e-03  1.15173387e+01]\n",
      "Loss: 6.937792129971887\n",
      "\n",
      "Iteration: 206\n",
      "P: [ 5.40111285e+00 -1.45725509e+00 -3.42798963e-03  1.15175155e+01]\n",
      "Loss: 6.937058948786504\n",
      "\n",
      "Iteration: 207\n",
      "P: [ 5.40170868e+00 -1.45796315e+00 -3.43611438e-03  1.15177444e+01]\n",
      "Loss: 6.936429535366516\n",
      "\n",
      "Iteration: 208\n",
      "P: [ 5.40224846e+00 -1.45860467e+00 -3.44347293e-03  1.15179516e+01]\n",
      "Loss: 6.93580682066552\n",
      "\n",
      "Iteration: 209\n",
      "P: [ 5.40294171e+00 -1.45942872e+00 -3.45291999e-03  1.15182177e+01]\n",
      "Loss: 6.934333498539635\n",
      "\n",
      "Iteration: 210\n",
      "P: [ 5.40374932e+00 -1.46038889e+00 -3.46392072e-03  1.15185276e+01]\n",
      "Loss: 6.932386523181856\n",
      "\n",
      "Iteration: 211\n",
      "P: [ 5.40423296e+00 -1.46096380e+00 -3.47051070e-03  1.15187133e+01]\n",
      "Loss: 6.93164537706914\n",
      "\n",
      "Iteration: 212\n",
      "P: [ 5.40480022e+00 -1.46163817e+00 -3.47823873e-03  1.15189310e+01]\n",
      "Loss: 6.9310818816211786\n",
      "\n",
      "Iteration: 213\n",
      "P: [ 5.40528950e+00 -1.46221990e+00 -3.48490258e-03  1.15191187e+01]\n",
      "Loss: 6.930451367216887\n",
      "\n",
      "Iteration: 214\n",
      "P: [ 5.40609608e+00 -1.46317902e+00 -3.49588423e-03  1.15194281e+01]\n",
      "Loss: 6.9288032890528575\n",
      "\n",
      "Iteration: 215\n",
      "P: [ 5.40685391e+00 -1.46408033e+00 -3.50619766e-03  1.15197187e+01]\n",
      "Loss: 6.9270524349126985\n",
      "\n",
      "Iteration: 216\n",
      "P: [ 5.40728067e+00 -1.46458784e+00 -3.51200743e-03  1.15198824e+01]\n",
      "Loss: 6.926400855119175\n",
      "\n",
      "Iteration: 217\n",
      "P: [ 5.40783206e+00 -1.46524357e+00 -3.51951244e-03  1.15200939e+01]\n",
      "Loss: 6.925833468685679\n",
      "\n",
      "Iteration: 218\n",
      "P: [ 5.40837078e+00 -1.46588431e+00 -3.52684339e-03  1.15203005e+01]\n",
      "Loss: 6.92526426622078\n",
      "\n",
      "Iteration: 219\n",
      "P: [ 5.40894473e+00 -1.46656706e+00 -3.53465082e-03  1.15205206e+01]\n",
      "Loss: 6.923999356967856\n",
      "\n",
      "Iteration: 220\n",
      "P: [ 5.40970350e+00 -1.46746981e+00 -3.54496854e-03  1.15208114e+01]\n",
      "Loss: 6.922235639054809\n",
      "\n",
      "Iteration: 221\n",
      "P: [ 5.41015059e+00 -1.46800165e+00 -3.55104981e-03  1.15209828e+01]\n",
      "Loss: 6.921556457589347\n",
      "\n",
      "Iteration: 222\n",
      "P: [ 5.41067839e+00 -1.46862956e+00 -3.55822794e-03  1.15211851e+01]\n",
      "Loss: 6.921039538631095\n",
      "\n",
      "Iteration: 223\n",
      "P: [ 5.41113537e+00 -1.46917327e+00 -3.56444135e-03  1.15213602e+01]\n",
      "Loss: 6.920499693614803\n",
      "\n",
      "Iteration: 224\n",
      "P: [ 5.41184433e+00 -1.47001690e+00 -3.57407794e-03  1.15216319e+01]\n",
      "Loss: 6.919132204978354\n",
      "\n",
      "Iteration: 225\n",
      "P: [ 5.41256403e+00 -1.47087344e+00 -3.58385634e-03  1.15219076e+01]\n",
      "Loss: 6.917459855304246\n",
      "\n",
      "Iteration: 226\n",
      "P: [ 5.41300954e+00 -1.47140360e+00 -3.58991125e-03  1.15220783e+01]\n",
      "Loss: 6.916829138091314\n",
      "\n",
      "Iteration: 227\n",
      "P: [ 5.41357332e+00 -1.47207454e+00 -3.59757219e-03  1.15222942e+01]\n",
      "Loss: 6.9163150329834835\n",
      "\n",
      "Iteration: 228\n",
      "P: [ 5.41399766e+00 -1.47257960e+00 -3.60333674e-03  1.15224568e+01]\n",
      "Loss: 6.915707232994446\n",
      "\n",
      "Iteration: 229\n",
      "P: [ 5.41481998e+00 -1.47355849e+00 -3.61450414e-03  1.15227717e+01]\n",
      "Loss: 6.913931452842853\n",
      "\n",
      "Iteration: 230\n",
      "P: [ 5.41571024e+00 -1.47461828e+00 -3.62659313e-03  1.15231126e+01]\n",
      "Loss: 6.912660925156192\n",
      "\n",
      "Iteration: 231\n",
      "P: [ 5.41715913e+00 -1.47634343e+00 -3.64625822e-03  1.15236672e+01]\n",
      "Loss: 6.909943857749218\n",
      "\n",
      "Iteration: 232\n",
      "P: [ 5.41742920e+00 -1.47666497e+00 -3.64992450e-03  1.15237705e+01]\n",
      "Loss: 6.909599767086687\n",
      "\n",
      "Iteration: 233\n",
      "P: [ 5.41823634e+00 -1.47762605e+00 -3.66087846e-03  1.15240795e+01]\n",
      "Loss: 6.9090814106021305\n",
      "\n",
      "Iteration: 234\n",
      "P: [ 5.41826746e+00 -1.47766315e+00 -3.66129917e-03  1.15240914e+01]\n",
      "Loss: 6.908427453530041\n",
      "\n",
      "Iteration: 235\n",
      "P: [ 5.41921472e+00 -1.47879131e+00 -3.67414821e-03  1.15244538e+01]\n",
      "Loss: 6.9067165417113605\n",
      "\n",
      "Iteration: 236\n",
      "P: [ 5.41969894e+00 -1.47936801e+00 -3.68071637e-03  1.15246391e+01]\n",
      "Loss: 6.906167291064295\n",
      "\n",
      "Iteration: 237\n",
      "P: [ 5.42048165e+00 -1.48030030e+00 -3.69133022e-03  1.15249385e+01]\n",
      "Loss: 6.90505330575607\n",
      "\n",
      "Iteration: 238\n",
      "P: [ 5.42124947e+00 -1.48121503e+00 -3.70173813e-03  1.15252321e+01]\n",
      "Loss: 6.903399637821767\n",
      "\n",
      "Iteration: 239\n",
      "P: [ 5.42160478e+00 -1.48163828e+00 -3.70655529e-03  1.15253680e+01]\n",
      "Loss: 6.903042305561026\n",
      "\n",
      "Iteration: 240\n",
      "P: [ 5.42264893e+00 -1.48288222e+00 -3.72070828e-03  1.15257673e+01]\n",
      "Loss: 6.902492434547438\n",
      "\n",
      "Iteration: 241\n",
      "P: [ 5.42251355e+00 -1.48272103e+00 -3.71887090e-03  1.15257155e+01]\n",
      "Loss: 6.901454531260569\n",
      "\n",
      "Iteration: 242\n",
      "P: [ 5.42310478e+00 -1.48342553e+00 -3.72688154e-03  1.15259415e+01]\n",
      "Loss: 6.900456282397355\n",
      "\n",
      "Iteration: 243\n",
      "P: [ 5.42350272e+00 -1.48389967e+00 -3.73227349e-03  1.15260937e+01]\n",
      "Loss: 6.899954516924495\n",
      "\n",
      "Iteration: 244\n",
      "P: [ 5.42408774e+00 -1.48459679e+00 -3.74019941e-03  1.15263173e+01]\n",
      "Loss: 6.899434650582654\n",
      "\n",
      "Iteration: 245\n",
      "P: [ 5.42448152e+00 -1.48506607e+00 -3.74553270e-03  1.15264678e+01]\n",
      "Loss: 6.898759444560748\n",
      "\n",
      "Iteration: 246\n",
      "P: [ 5.42521138e+00 -1.48593603e+00 -3.75541454e-03  1.15267467e+01]\n",
      "Loss: 6.897157108521455\n",
      "\n",
      "Iteration: 247\n",
      "P: [ 5.42561101e+00 -1.48641232e+00 -3.76082649e-03  1.15268994e+01]\n",
      "Loss: 6.89662247575791\n",
      "\n",
      "Iteration: 248\n",
      "P: [ 5.42609415e+00 -1.48698818e+00 -3.76736859e-03  1.15270840e+01]\n",
      "Loss: 6.896221937027303\n",
      "\n",
      "Iteration: 249\n",
      "P: [ 5.42645712e+00 -1.48742085e+00 -3.77228224e-03  1.15272227e+01]\n",
      "Loss: 6.895740289755775\n",
      "\n",
      "Iteration: 250\n",
      "P: [ 5.42717562e+00 -1.48827743e+00 -3.78200617e-03  1.15274971e+01]\n",
      "Loss: 6.894294578591303\n",
      "\n",
      "Iteration: 251\n",
      "P: [ 5.42790746e+00 -1.48914997e+00 -3.79190951e-03  1.15277766e+01]\n",
      "Loss: 6.89313060062403\n",
      "\n",
      "Iteration: 252\n",
      "P: [ 5.42886885e+00 -1.49029637e+00 -3.80491465e-03  1.15281437e+01]\n",
      "Loss: 6.89156647904326\n",
      "\n",
      "Iteration: 253\n",
      "P: [ 5.42948723e+00 -1.49103370e+00 -3.81328083e-03  1.15283798e+01]\n",
      "Loss: 6.890806360854757\n",
      "\n",
      "Iteration: 254\n",
      "P: [ 5.42988990e+00 -1.49151388e+00 -3.81872733e-03  1.15285336e+01]\n",
      "Loss: 6.890496519063826\n",
      "\n",
      "Iteration: 255\n",
      "P: [ 5.43031585e+00 -1.49202189e+00 -3.82448688e-03  1.15286962e+01]\n",
      "Loss: 6.8896703570369064\n",
      "\n",
      "Iteration: 256\n",
      "P: [ 5.43095543e+00 -1.49278480e+00 -3.83313285e-03  1.15289402e+01]\n",
      "Loss: 6.888331193630661\n",
      "\n",
      "Iteration: 257\n",
      "P: [ 5.43132349e+00 -1.49322378e+00 -3.83810945e-03  1.15290807e+01]\n",
      "Loss: 6.887837554576161\n",
      "\n",
      "Iteration: 258\n",
      "P: [ 5.43176503e+00 -1.49375043e+00 -3.84407881e-03  1.15292492e+01]\n",
      "Loss: 6.887461439612585\n",
      "\n",
      "Iteration: 259\n",
      "P: [ 5.43212815e+00 -1.49418359e+00 -3.84898708e-03  1.15293878e+01]\n",
      "Loss: 6.887050874516092\n",
      "\n",
      "Iteration: 260\n",
      "P: [ 5.43274123e+00 -1.49491499e+00 -3.85727187e-03  1.15296217e+01]\n",
      "Loss: 6.885939095902385\n",
      "\n",
      "Iteration: 261\n",
      "P: [ 5.43333032e+00 -1.49561787e+00 -3.86523030e-03  1.15298464e+01]\n",
      "Loss: 6.884746327253297\n",
      "\n",
      "Iteration: 262\n",
      "P: [ 5.43366518e+00 -1.49601738e+00 -3.86975504e-03  1.15299741e+01]\n",
      "Loss: 6.884316324258926\n",
      "\n",
      "Iteration: 263\n",
      "P: [ 5.43414416e+00 -1.49658886e+00 -3.87622644e-03  1.15301568e+01]\n",
      "Loss: 6.8839112415085655\n",
      "\n",
      "Iteration: 264\n",
      "P: [ 5.43449363e+00 -1.49700586e+00 -3.88094708e-03  1.15302901e+01]\n",
      "Loss: 6.8834720848020075\n",
      "\n",
      "Iteration: 265\n",
      "P: [ 5.43516306e+00 -1.49780474e+00 -3.88998733e-03  1.15305454e+01]\n",
      "Loss: 6.882182233942316\n",
      "\n",
      "Iteration: 266\n",
      "P: [ 5.43583518e+00 -1.49860688e+00 -3.89906283e-03  1.15308017e+01]\n",
      "Loss: 6.881114683118356\n",
      "\n",
      "Iteration: 267\n",
      "P: [ 5.43675507e+00 -1.49970483e+00 -3.91148145e-03  1.15311523e+01]\n",
      "Loss: 6.879724821907468\n",
      "\n",
      "Iteration: 268\n",
      "P: [ 5.43778153e+00 -1.50093015e+00 -3.92533310e-03  1.15315435e+01]\n",
      "Loss: 6.878698394984663\n",
      "\n",
      "Iteration: 269\n",
      "P: [ 5.43838915e+00 -1.50165547e+00 -3.93353337e-03  1.15317751e+01]\n",
      "Loss: 6.877267862849547\n",
      "\n",
      "Iteration: 270\n",
      "P: [ 5.43874895e+00 -1.50208496e+00 -3.93838894e-03  1.15319123e+01]\n",
      "Loss: 6.876879465950815\n",
      "\n",
      "Iteration: 271\n",
      "P: [ 5.43889563e+00 -1.50226008e+00 -3.94036813e-03  1.15319682e+01]\n",
      "Loss: 6.87675105783447\n",
      "\n",
      "Iteration: 272\n",
      "P: [ 5.43943386e+00 -1.50290265e+00 -3.94762934e-03  1.15321733e+01]\n",
      "Loss: 6.876290488922458\n",
      "\n",
      "Iteration: 273\n",
      "P: [ 5.43968724e+00 -1.50320519e+00 -3.95104662e-03  1.15322698e+01]\n",
      "Loss: 6.875706997519041\n",
      "\n",
      "Iteration: 274\n",
      "P: [ 5.44028811e+00 -1.50392272e+00 -3.95914891e-03  1.15324987e+01]\n",
      "Loss: 6.874487619545111\n",
      "\n",
      "Iteration: 275\n",
      "P: [ 5.44061607e+00 -1.50431430e+00 -3.96357201e-03  1.15326236e+01]\n",
      "Loss: 6.874030958498969\n",
      "\n",
      "Iteration: 276\n",
      "P: [ 5.44101629e+00 -1.50479219e+00 -3.96896941e-03  1.15327761e+01]\n",
      "Loss: 6.873684482757891\n",
      "\n",
      "Iteration: 277\n",
      "P: [ 5.44133732e+00 -1.50517555e+00 -3.97329809e-03  1.15328983e+01]\n",
      "Loss: 6.873388060074171\n",
      "\n",
      "Iteration: 278\n",
      "P: [ 5.44180551e+00 -1.50573469e+00 -3.97960971e-03  1.15330767e+01]\n",
      "Loss: 6.872656156438713\n",
      "\n",
      "Iteration: 279\n",
      "P: [ 5.44238828e+00 -1.50643074e+00 -3.98746385e-03  1.15332986e+01]\n",
      "Loss: 6.871450374649293\n",
      "\n",
      "Iteration: 280\n",
      "P: [ 5.44278132e+00 -1.50690015e+00 -3.99276192e-03  1.15334482e+01]\n",
      "Loss: 6.871093327054563\n",
      "\n",
      "Iteration: 281\n",
      "P: [ 5.44363259e+00 -1.50791691e+00 -4.00423449e-03  1.15337724e+01]\n",
      "Loss: 6.870707990272079\n",
      "\n",
      "Iteration: 282\n",
      "P: [ 5.44353628e+00 -1.50780194e+00 -4.00293481e-03  1.15337357e+01]\n",
      "Loss: 6.8698435903610235\n",
      "\n",
      "Iteration: 283\n",
      "P: [ 5.44409813e+00 -1.50847311e+00 -4.01050444e-03  1.15339495e+01]\n",
      "Loss: 6.868994625873524\n",
      "\n",
      "Iteration: 284\n",
      "P: [ 5.44446432e+00 -1.50891053e+00 -4.01543814e-03  1.15340889e+01]\n",
      "Loss: 6.868620660148657\n",
      "\n",
      "Iteration: 285\n",
      "P: [ 5.44491702e+00 -1.50945134e+00 -4.02153665e-03  1.15342613e+01]\n",
      "Loss: 6.868196402474444\n",
      "\n",
      "Iteration: 286\n",
      "P: [ 5.44540718e+00 -1.51003694e+00 -4.02813818e-03  1.15344478e+01]\n",
      "Loss: 6.867472999606931\n",
      "\n",
      "Iteration: 287\n",
      "P: [ 5.44597317e+00 -1.51071332e+00 -4.03575886e-03  1.15346631e+01]\n",
      "Loss: 6.866319960384956\n",
      "\n",
      "Iteration: 288\n",
      "P: [ 5.44636937e+00 -1.51118672e+00 -4.04109437e-03  1.15348139e+01]\n",
      "Loss: 6.865856626906484\n",
      "\n",
      "Iteration: 289\n",
      "P: [ 5.44676018e+00 -1.51165373e+00 -4.04635680e-03  1.15349626e+01]\n",
      "Loss: 6.865584228906273\n",
      "\n",
      "Iteration: 290\n",
      "P: [ 5.44702193e+00 -1.51196656e+00 -4.04988059e-03  1.15350621e+01]\n",
      "Loss: 6.865185887808327\n",
      "\n",
      "Iteration: 291\n",
      "P: [ 5.44768956e+00 -1.51276459e+00 -4.05886655e-03  1.15353160e+01]\n",
      "Loss: 6.863915865412961\n",
      "\n",
      "Iteration: 292\n",
      "P: [ 5.44805517e+00 -1.51320157e+00 -4.06378807e-03  1.15354551e+01]\n",
      "Loss: 6.863622978465005\n",
      "\n",
      "Iteration: 293\n",
      "P: [ 5.44877158e+00 -1.51405797e+00 -4.07342970e-03  1.15357275e+01]\n",
      "Loss: 6.862971819182425\n",
      "\n",
      "Iteration: 294\n",
      "P: [ 5.44905879e+00 -1.51440144e+00 -4.07729296e-03  1.15358366e+01]\n",
      "Loss: 6.861997938616682\n",
      "\n",
      "Iteration: 295\n",
      "P: [ 5.44951997e+00 -1.51495282e+00 -4.08349835e-03  1.15360119e+01]\n",
      "Loss: 6.861479636937743\n",
      "\n",
      "Iteration: 296\n",
      "P: [ 5.45010270e+00 -1.51564959e+00 -4.09133831e-03  1.15362334e+01]\n",
      "Loss: 6.860986958654733\n",
      "\n",
      "Iteration: 297\n",
      "P: [ 5.45046182e+00 -1.51607909e+00 -4.09616824e-03  1.15363698e+01]\n",
      "Loss: 6.860172415016566\n",
      "\n",
      "Iteration: 298\n",
      "P: [ 5.45117453e+00 -1.51693146e+00 -4.10575374e-03  1.15366406e+01]\n",
      "Loss: 6.859237656182063\n",
      "\n",
      "Iteration: 299\n",
      "P: [ 5.45197815e+00 -1.51789285e+00 -4.11655758e-03  1.15369457e+01]\n",
      "Loss: 6.858664949268963\n",
      "\n",
      "Iteration: 300\n",
      "P: [ 5.45272862e+00 -1.51879055e+00 -4.12664847e-03  1.15372308e+01]\n",
      "Loss: 6.8568852768480575\n",
      "\n",
      "Iteration: 301\n",
      "P: [ 5.45284611e+00 -1.51893109e+00 -4.12822812e-03  1.15372754e+01]\n",
      "Loss: 6.856783632363401\n",
      "\n",
      "Iteration: 302\n",
      "P: [ 5.45300026e+00 -1.51911550e+00 -4.13030068e-03  1.15373339e+01]\n",
      "Loss: 6.856699545571351\n",
      "\n",
      "Iteration: 303\n",
      "P: [ 5.45313187e+00 -1.51927295e+00 -4.13206995e-03  1.15373839e+01]\n",
      "Loss: 6.856614112189844\n",
      "\n",
      "Iteration: 304\n",
      "P: [ 5.45339991e+00 -1.51959365e+00 -4.13567292e-03  1.15374857e+01]\n",
      "Loss: 6.856376110882802\n",
      "\n",
      "Iteration: 305\n",
      "P: [ 5.45378829e+00 -1.52005838e+00 -4.14089289e-03  1.15376331e+01]\n",
      "Loss: 6.855906490023868\n",
      "\n",
      "Iteration: 306\n",
      "P: [ 5.45424742e+00 -1.52060784e+00 -4.14706242e-03  1.15378073e+01]\n",
      "Loss: 6.855000248804849\n",
      "\n",
      "Iteration: 307\n",
      "P: [ 5.45480926e+00 -1.52128030e+00 -4.15461117e-03  1.15380205e+01]\n",
      "Loss: 6.854036628274312\n",
      "\n",
      "Iteration: 308\n",
      "P: [ 5.45511239e+00 -1.52164308e+00 -4.15868444e-03  1.15381355e+01]\n",
      "Loss: 6.853789127860878\n",
      "\n",
      "Iteration: 309\n",
      "P: [ 5.45578485e+00 -1.52244796e+00 -4.16771884e-03  1.15383907e+01]\n",
      "Loss: 6.853265578371226\n",
      "\n",
      "Iteration: 310\n",
      "P: [ 5.45599766e+00 -1.52270279e+00 -4.17057651e-03  1.15384713e+01]\n",
      "Loss: 6.852507591807987\n",
      "\n",
      "Iteration: 311\n",
      "P: [ 5.45654319e+00 -1.52335587e+00 -4.17790399e-03  1.15386783e+01]\n",
      "Loss: 6.851912079609838\n",
      "\n",
      "Iteration: 312\n",
      "P: [ 5.45735220e+00 -1.52432453e+00 -4.18876827e-03  1.15389850e+01]\n",
      "Loss: 6.8508580536540595\n",
      "\n",
      "Iteration: 313\n",
      "P: [ 5.45758248e+00 -1.52460038e+00 -4.19185908e-03  1.15390723e+01]\n",
      "Loss: 6.850276073560237\n",
      "\n",
      "Iteration: 314\n",
      "P: [ 5.45815402e+00 -1.52528479e+00 -4.19953336e-03  1.15392889e+01]\n",
      "Loss: 6.8496026095413045\n",
      "\n",
      "Iteration: 315\n",
      "P: [ 5.45844703e+00 -1.52563569e+00 -4.20346742e-03  1.15394000e+01]\n",
      "Loss: 6.849437822686993\n",
      "\n",
      "Iteration: 316\n",
      "P: [ 5.45866146e+00 -1.52589253e+00 -4.20634583e-03  1.15394813e+01]\n",
      "Loss: 6.849118475458246\n",
      "\n",
      "Iteration: 317\n",
      "P: [ 5.45931557e+00 -1.52667614e+00 -4.21512490e-03  1.15397291e+01]\n",
      "Loss: 6.8479711706455175\n",
      "\n",
      "Iteration: 318\n",
      "P: [ 5.45972791e+00 -1.52717008e+00 -4.22065947e-03  1.15398853e+01]\n",
      "Loss: 6.847673433942945\n",
      "\n",
      "Iteration: 319\n",
      "P: [ 5.46046014e+00 -1.52804740e+00 -4.23048537e-03  1.15401626e+01]\n",
      "Loss: 6.846833894573963\n",
      "\n",
      "Iteration: 320\n",
      "P: [ 5.46083108e+00 -1.52849206e+00 -4.23546066e-03  1.15403030e+01]\n",
      "Loss: 6.84604506534795\n",
      "\n",
      "Iteration: 321\n",
      "P: [ 5.46141707e+00 -1.52919425e+00 -4.24332305e-03  1.15405249e+01]\n",
      "Loss: 6.845205394054392\n",
      "\n",
      "Iteration: 322\n",
      "P: [ 5.46165524e+00 -1.52947967e+00 -4.24651836e-03  1.15406150e+01]\n",
      "Loss: 6.8450929635502336\n",
      "\n",
      "Iteration: 323\n",
      "P: [ 5.46182105e+00 -1.52967841e+00 -4.24874258e-03  1.15406778e+01]\n",
      "Loss: 6.84490440602326\n",
      "\n",
      "Iteration: 324\n",
      "P: [ 5.46245674e+00 -1.53044042e+00 -4.25726864e-03  1.15409184e+01]\n",
      "Loss: 6.844036863931602\n",
      "\n",
      "Iteration: 325\n",
      "P: [ 5.46290866e+00 -1.53098235e+00 -4.26332852e-03  1.15410893e+01]\n",
      "Loss: 6.843158883449986\n",
      "\n",
      "Iteration: 326\n",
      "P: [ 5.46330451e+00 -1.53145695e+00 -4.26863733e-03  1.15412390e+01]\n",
      "Loss: 6.842835601257189\n",
      "\n",
      "Iteration: 327\n",
      "P: [ 5.46400845e+00 -1.53230111e+00 -4.27807672e-03  1.15415053e+01]\n",
      "Loss: 6.842481495026108\n",
      "\n",
      "Iteration: 328\n",
      "P: [ 5.46400264e+00 -1.53229429e+00 -4.27799764e-03  1.15415030e+01]\n",
      "Loss: 6.841776153340629\n",
      "\n",
      "Iteration: 329\n",
      "P: [ 5.46460036e+00 -1.53301132e+00 -4.28601036e-03  1.15417289e+01]\n",
      "Loss: 6.840931667260321\n",
      "\n",
      "Iteration: 330\n",
      "P: [ 5.46494039e+00 -1.53341921e+00 -4.29056893e-03  1.15418574e+01]\n",
      "Loss: 6.840652464148497\n",
      "\n",
      "Iteration: 331\n",
      "P: [ 5.46561436e+00 -1.53422784e+00 -4.29960309e-03  1.15421121e+01]\n",
      "Loss: 6.840215794001874\n",
      "\n",
      "Iteration: 332\n",
      "P: [ 5.46570999e+00 -1.53434272e+00 -4.30088375e-03  1.15421481e+01]\n",
      "Loss: 6.83954807223393\n",
      "\n",
      "Iteration: 333\n",
      "P: [ 5.46643731e+00 -1.53521566e+00 -4.31063057e-03  1.15424228e+01]\n",
      "Loss: 6.83863282780127\n",
      "\n",
      "Iteration: 334\n",
      "P: [ 5.46729252e+00 -1.53624229e+00 -4.32208985e-03  1.15427456e+01]\n",
      "Loss: 6.837876866240592\n",
      "\n",
      "Iteration: 335\n",
      "P: [ 5.46787452e+00 -1.53694138e+00 -4.32988498e-03  1.15429651e+01]\n",
      "Loss: 6.836873460770519\n",
      "\n",
      "Iteration: 336\n",
      "P: [ 5.46850332e+00 -1.53769644e+00 -4.33830858e-03  1.15432024e+01]\n",
      "Loss: 6.835947893288855\n",
      "\n",
      "Iteration: 337\n",
      "P: [ 5.46869818e+00 -1.53793046e+00 -4.34091889e-03  1.15432759e+01]\n",
      "Loss: 6.835876894151279\n",
      "\n",
      "Iteration: 338\n",
      "P: [ 5.46880715e+00 -1.53806137e+00 -4.34237830e-03  1.15433170e+01]\n",
      "Loss: 6.835715690114136\n",
      "\n",
      "Iteration: 339\n",
      "P: [ 5.46953279e+00 -1.53893320e+00 -4.35209562e-03  1.15435905e+01]\n",
      "Loss: 6.834605080203486\n",
      "\n",
      "Iteration: 340\n",
      "P: [ 5.47014003e+00 -1.53966288e+00 -4.36022686e-03  1.15438193e+01]\n",
      "Loss: 6.833893350158176\n",
      "\n",
      "Iteration: 341\n",
      "P: [ 5.47117599e+00 -1.54090821e+00 -4.37409511e-03  1.15442095e+01]\n",
      "Loss: 6.832453203131183\n",
      "\n",
      "Iteration: 342\n",
      "P: [ 5.47151365e+00 -1.54131405e+00 -4.37861558e-03  1.15443367e+01]\n",
      "Loss: 6.832055295981271\n",
      "\n",
      "Iteration: 343\n",
      "P: [ 5.47179406e+00 -1.54165116e+00 -4.38236930e-03  1.15444423e+01]\n",
      "Loss: 6.831900307712652\n",
      "\n",
      "Iteration: 344\n",
      "P: [ 5.47202716e+00 -1.54193143e+00 -4.38548929e-03  1.15445300e+01]\n",
      "Loss: 6.831681796037366\n",
      "\n",
      "Iteration: 345\n",
      "P: [ 5.47250659e+00 -1.54250801e+00 -4.39190536e-03  1.15447104e+01]\n",
      "Loss: 6.830991148917803\n",
      "\n",
      "Iteration: 346\n",
      "P: [ 5.47301195e+00 -1.54311597e+00 -4.39866723e-03  1.15449005e+01]\n",
      "Loss: 6.830064928155591\n",
      "\n",
      "Iteration: 347\n",
      "P: [ 5.47337777e+00 -1.54355596e+00 -4.40356261e-03  1.15450382e+01]\n",
      "Loss: 6.829753743772548\n",
      "\n",
      "Iteration: 348\n",
      "P: [ 5.47408002e+00 -1.54440076e+00 -4.41295907e-03  1.15453023e+01]\n",
      "Loss: 6.8294901297947375\n",
      "\n",
      "Iteration: 349\n",
      "P: [ 5.47398352e+00 -1.54428478e+00 -4.41166700e-03  1.15452659e+01]\n",
      "Loss: 6.828961890493623\n",
      "\n",
      "Iteration: 350\n",
      "P: [ 5.47437509e+00 -1.54475611e+00 -4.41690453e-03  1.15454131e+01]\n",
      "Loss: 6.828433763615956\n",
      "\n",
      "Iteration: 351\n",
      "P: [ 5.47497048e+00 -1.54547258e+00 -4.42486936e-03  1.15456369e+01]\n",
      "Loss: 6.82764969085086\n",
      "\n",
      "Iteration: 352\n",
      "P: [ 5.47523792e+00 -1.54579444e+00 -4.42844698e-03  1.15457374e+01]\n",
      "Loss: 6.8275380932604515\n",
      "\n",
      "Iteration: 353\n",
      "P: [ 5.47533833e+00 -1.54591532e+00 -4.42978992e-03  1.15457751e+01]\n",
      "Loss: 6.827406897972365\n",
      "\n",
      "Iteration: 354\n",
      "P: [ 5.47606141e+00 -1.54678602e+00 -4.43946004e-03  1.15460467e+01]\n",
      "Loss: 6.826343728715165\n",
      "\n",
      "Iteration: 355\n",
      "P: [ 5.47658296e+00 -1.54741424e+00 -4.44643395e-03  1.15462424e+01]\n",
      "Loss: 6.8255709186957905\n",
      "\n",
      "Iteration: 356\n",
      "P: [ 5.47676470e+00 -1.54763311e+00 -4.44886429e-03  1.15463106e+01]\n",
      "Loss: 6.8254253829179445\n",
      "\n",
      "Iteration: 357\n",
      "P: [ 5.47766644e+00 -1.54871937e+00 -4.46092157e-03  1.15466490e+01]\n",
      "Loss: 6.82498573564331\n",
      "\n",
      "Iteration: 358\n",
      "P: [ 5.47752482e+00 -1.54854893e+00 -4.45902720e-03  1.15465958e+01]\n",
      "Loss: 6.824450074851875\n",
      "\n",
      "Iteration: 359\n",
      "P: [ 5.47791945e+00 -1.54902460e+00 -4.46430226e-03  1.15467437e+01]\n",
      "Loss: 6.823911123156548\n",
      "\n",
      "Iteration: 360\n",
      "P: [ 5.47825631e+00 -1.54943056e+00 -4.46880555e-03  1.15468700e+01]\n",
      "Loss: 6.82347205477619\n",
      "\n",
      "Iteration: 361\n",
      "P: [ 5.47839705e+00 -1.54960018e+00 -4.47068701e-03  1.15469228e+01]\n",
      "Loss: 6.823327100729192\n",
      "\n",
      "Iteration: 362\n",
      "P: [ 5.47880129e+00 -1.55008740e+00 -4.47609083e-03  1.15470743e+01]\n",
      "Loss: 6.82309537229082\n",
      "\n",
      "Iteration: 363\n",
      "P: [ 5.47907270e+00 -1.55041468e+00 -4.47971820e-03  1.15471760e+01]\n",
      "Loss: 6.822656274851845\n",
      "\n",
      "Iteration: 364\n",
      "P: [ 5.47970559e+00 -1.55117810e+00 -4.48817573e-03  1.15474129e+01]\n",
      "Loss: 6.821686393776123\n",
      "\n",
      "Iteration: 365\n",
      "P: [ 5.48015079e+00 -1.55171499e+00 -4.49412567e-03  1.15475797e+01]\n",
      "Loss: 6.821251625202036\n",
      "\n",
      "Iteration: 366\n",
      "P: [ 5.48059662e+00 -1.55225277e+00 -4.50008341e-03  1.15477466e+01]\n",
      "Loss: 6.821033006617663\n",
      "\n",
      "Iteration: 367\n",
      "P: [ 5.48071319e+00 -1.55239348e+00 -4.50164069e-03  1.15477902e+01]\n",
      "Loss: 6.820704587148676\n",
      "\n",
      "Iteration: 368\n",
      "P: [ 5.48136890e+00 -1.55318506e+00 -4.51040003e-03  1.15480353e+01]\n",
      "Loss: 6.819772563097115\n",
      "\n",
      "Iteration: 369\n",
      "P: [ 5.48182594e+00 -1.55373665e+00 -4.51650625e-03  1.15482063e+01]\n",
      "Loss: 6.819062347629914\n",
      "\n",
      "Iteration: 370\n",
      "P: [ 5.48210972e+00 -1.55407918e+00 -4.52029745e-03  1.15483124e+01]\n",
      "Loss: 6.818884980539676\n",
      "\n",
      "Iteration: 371\n",
      "P: [ 5.48225686e+00 -1.55425680e+00 -4.52226299e-03  1.15483674e+01]\n",
      "Loss: 6.818790347170836\n",
      "\n",
      "Iteration: 372\n",
      "P: [ 5.48261488e+00 -1.55468909e+00 -4.52704536e-03  1.15485012e+01]\n",
      "Loss: 6.818510508741444\n",
      "\n",
      "Iteration: 373\n",
      "P: [ 5.48294835e+00 -1.55509185e+00 -4.53149912e-03  1.15486258e+01]\n",
      "Loss: 6.818062792450338\n",
      "\n",
      "Iteration: 374\n",
      "P: [ 5.48353743e+00 -1.55580370e+00 -4.53936567e-03  1.15488456e+01]\n",
      "Loss: 6.816965719991343\n",
      "\n",
      "Iteration: 375\n",
      "P: [ 5.48400787e+00 -1.55637204e+00 -4.54564846e-03  1.15490213e+01]\n",
      "Loss: 6.816655977327224\n",
      "\n",
      "Iteration: 376\n",
      "P: [ 5.48462192e+00 -1.55711423e+00 -4.55384788e-03  1.15492504e+01]\n",
      "Loss: 6.815991254068715\n",
      "\n",
      "Iteration: 377\n",
      "P: [ 5.48509596e+00 -1.55768771e+00 -4.56017619e-03  1.15494269e+01]\n",
      "Loss: 6.815077609539243\n",
      "\n",
      "Iteration: 378\n",
      "P: [ 5.48537170e+00 -1.55802111e+00 -4.56385779e-03  1.15495297e+01]\n",
      "Loss: 6.81471676808725\n",
      "\n",
      "Iteration: 379\n",
      "P: [ 5.48570656e+00 -1.55842604e+00 -4.56832854e-03  1.15496546e+01]\n",
      "Loss: 6.814426434374316\n",
      "\n",
      "Iteration: 380\n",
      "P: [ 5.48618496e+00 -1.55900463e+00 -4.57471556e-03  1.15498328e+01]\n",
      "Loss: 6.814283584003498\n",
      "\n",
      "Iteration: 381\n",
      "P: [ 5.48610169e+00 -1.55890398e+00 -4.57360361e-03  1.15498018e+01]\n",
      "Loss: 6.814138494263064\n",
      "\n",
      "Iteration: 382\n",
      "P: [ 5.48611328e+00 -1.55891815e+00 -4.57375780e-03  1.15498060e+01]\n",
      "Loss: 6.81385730812177\n",
      "\n",
      "Iteration: 383\n",
      "P: [ 5.48640118e+00 -1.55926669e+00 -4.57760045e-03  1.15499131e+01]\n",
      "Loss: 6.813534657749928\n",
      "\n",
      "Iteration: 384\n",
      "P: [ 5.48721632e+00 -1.56025306e+00 -4.58848141e-03  1.15502166e+01]\n",
      "Loss: 6.812757796989999\n",
      "\n",
      "Iteration: 385\n",
      "P: [ 5.48741194e+00 -1.56048984e+00 -4.59109254e-03  1.15502894e+01]\n",
      "Loss: 6.812694066818408\n",
      "\n",
      "Iteration: 386\n",
      "P: [ 5.48755344e+00 -1.56066122e+00 -4.59298088e-03  1.15503420e+01]\n",
      "Loss: 6.8124308607748105\n",
      "\n",
      "Iteration: 387\n",
      "P: [ 5.48828128e+00 -1.56154316e+00 -4.60269298e-03  1.15506123e+01]\n",
      "Loss: 6.8113242865627965\n",
      "\n",
      "Iteration: 388\n",
      "P: [ 5.48881567e+00 -1.56219043e+00 -4.60982440e-03  1.15508110e+01]\n",
      "Loss: 6.810622019397389\n",
      "\n",
      "Iteration: 389\n",
      "P: [ 5.48913009e+00 -1.56257135e+00 -4.61402013e-03  1.15509278e+01]\n",
      "Loss: 6.810475344282054\n",
      "\n",
      "Iteration: 390\n",
      "P: [ 5.48924681e+00 -1.56271281e+00 -4.61557763e-03  1.15509711e+01]\n",
      "Loss: 6.810369006071695\n",
      "\n",
      "Iteration: 391\n",
      "P: [ 5.48992756e+00 -1.56353809e+00 -4.62466024e-03  1.15512237e+01]\n",
      "Loss: 6.809652815337821\n",
      "\n",
      "Iteration: 392\n",
      "P: [ 5.49038744e+00 -1.56409612e+00 -4.63079516e-03  1.15513941e+01]\n",
      "Loss: 6.808808451236295\n",
      "\n",
      "Iteration: 393\n",
      "P: [ 5.49108886e+00 -1.56494752e+00 -4.64015162e-03  1.15516539e+01]\n",
      "Loss: 6.807855430460352\n",
      "\n",
      "Iteration: 394\n",
      "P: [ 5.49150964e+00 -1.56545812e+00 -4.64576490e-03  1.15518098e+01]\n",
      "Loss: 6.807420227994995\n",
      "\n",
      "Iteration: 395\n",
      "P: [ 5.49217529e+00 -1.56626609e+00 -4.65464425e-03  1.15520562e+01]\n",
      "Loss: 6.807210784530986\n",
      "\n",
      "Iteration: 396\n",
      "P: [ 5.49197886e+00 -1.56602778e+00 -4.65202383e-03  1.15519834e+01]\n",
      "Loss: 6.807009049473064\n",
      "\n",
      "Iteration: 397\n",
      "P: [ 5.49207567e+00 -1.56614553e+00 -4.65331475e-03  1.15520192e+01]\n",
      "Loss: 6.806716340700444\n",
      "\n",
      "Iteration: 398\n",
      "P: [ 5.49278489e+00 -1.56700738e+00 -4.66277343e-03  1.15522813e+01]\n",
      "Loss: 6.805854305379533\n",
      "\n",
      "Iteration: 399\n",
      "P: [ 5.49333737e+00 -1.56767864e+00 -4.67014189e-03  1.15524855e+01]\n",
      "Loss: 6.805271762322259\n",
      "\n",
      "Iteration: 400\n",
      "P: [ 5.49360439e+00 -1.56800313e+00 -4.67370296e-03  1.15525841e+01]\n",
      "Loss: 6.805125668585512\n",
      "\n",
      "Iteration: 401\n",
      "P: [ 5.49388217e+00 -1.56834079e+00 -4.67740759e-03  1.15526868e+01]\n",
      "Loss: 6.805004272398121\n",
      "\n",
      "Iteration: 402\n",
      "P: [ 5.49403841e+00 -1.56853086e+00 -4.67949086e-03  1.15527444e+01]\n",
      "Loss: 6.804762908274413\n",
      "\n",
      "Iteration: 403\n",
      "P: [ 5.49476412e+00 -1.56941408e+00 -4.68916728e-03  1.15530118e+01]\n",
      "Loss: 6.803629271310569\n",
      "\n",
      "Iteration: 404\n",
      "P: [ 5.49546727e+00 -1.57027020e+00 -4.69854234e-03  1.15532708e+01]\n",
      "Loss: 6.802704864490891\n",
      "\n",
      "Iteration: 405\n",
      "P: [ 5.49657366e+00 -1.57161782e+00 -4.71329295e-03  1.15536780e+01]\n",
      "Loss: 6.801605674674599\n",
      "\n",
      "Iteration: 406\n",
      "P: [ 5.49679417e+00 -1.57188688e+00 -4.71623217e-03  1.15537589e+01]\n",
      "Loss: 6.801137774693605\n",
      "\n",
      "Iteration: 407\n",
      "P: [ 5.49721622e+00 -1.57240134e+00 -4.72185856e-03  1.15539140e+01]\n",
      "Loss: 6.800723967969144\n",
      "\n",
      "Iteration: 408\n",
      "P: [ 5.49801778e+00 -1.57337897e+00 -4.73254340e-03  1.15542083e+01]\n",
      "Loss: 6.799888518084155\n",
      "\n",
      "Iteration: 409\n",
      "P: [ 5.49917260e+00 -1.57478827e+00 -4.74793456e-03  1.15546318e+01]\n",
      "Loss: 6.798576824066681\n",
      "\n",
      "Iteration: 410\n",
      "P: [ 5.49934338e+00 -1.57499659e+00 -4.75020904e-03  1.15546945e+01]\n",
      "Loss: 6.798168709491898\n",
      "\n",
      "Iteration: 411\n",
      "P: [ 5.49976147e+00 -1.57550660e+00 -4.75577983e-03  1.15548480e+01]\n",
      "Loss: 6.797733068642636\n",
      "\n",
      "Iteration: 412\n",
      "P: [ 5.50009381e+00 -1.57591192e+00 -4.76020759e-03  1.15549700e+01]\n",
      "Loss: 6.7974040524527295\n",
      "\n",
      "Iteration: 413\n",
      "P: [ 5.50057730e+00 -1.57650153e+00 -4.76664817e-03  1.15551475e+01]\n",
      "Loss: 6.796904486764829\n",
      "\n",
      "Iteration: 414\n",
      "P: [ 5.50129224e+00 -1.57737329e+00 -4.77616989e-03  1.15554101e+01]\n",
      "Loss: 6.796095792382001\n",
      "\n",
      "Iteration: 415\n",
      "P: [ 5.50235942e+00 -1.57867437e+00 -4.79037894e-03  1.15558022e+01]\n",
      "Loss: 6.794748549876288\n",
      "\n",
      "Iteration: 416\n",
      "P: [ 5.50257410e+00 -1.57893610e+00 -4.79323733e-03  1.15558811e+01]\n",
      "Loss: 6.794579919270037\n",
      "\n",
      "Iteration: 417\n",
      "P: [ 5.50284221e+00 -1.57926294e+00 -4.79680633e-03  1.15559796e+01]\n",
      "Loss: 6.79425788959862\n",
      "\n",
      "Iteration: 418\n",
      "P: [ 5.50317550e+00 -1.57966921e+00 -4.80124264e-03  1.15561021e+01]\n",
      "Loss: 6.79387073990382\n",
      "\n",
      "Iteration: 419\n",
      "P: [ 5.50363963e+00 -1.58023497e+00 -4.80741993e-03  1.15562727e+01]\n",
      "Loss: 6.793316792531712\n",
      "\n",
      "Iteration: 420\n",
      "P: [ 5.50467233e+00 -1.58149375e+00 -4.82116282e-03  1.15566523e+01]\n",
      "Loss: 6.792529724700637\n",
      "\n",
      "Iteration: 421\n",
      "P: [ 5.50584790e+00 -1.58292644e+00 -4.83680005e-03  1.15570844e+01]\n",
      "Loss: 6.790652881684182\n",
      "\n",
      "Iteration: 422\n",
      "P: [ 5.50591283e+00 -1.58300559e+00 -4.83766400e-03  1.15571083e+01]\n",
      "Loss: 6.790592083715161\n",
      "\n",
      "Iteration: 423\n",
      "P: [ 5.50620808e+00 -1.58336541e+00 -4.84159139e-03  1.15572169e+01]\n",
      "Loss: 6.790369938905712\n",
      "\n",
      "Iteration: 424\n",
      "P: [ 5.50666554e+00 -1.58392290e+00 -4.84767568e-03  1.15573851e+01]\n",
      "Loss: 6.790102943284953\n",
      "\n",
      "Iteration: 425\n",
      "P: [ 5.50703416e+00 -1.58437207e+00 -4.85257704e-03  1.15575206e+01]\n",
      "Loss: 6.789437452307133\n",
      "\n",
      "Iteration: 426\n",
      "P: [ 5.50732184e+00 -1.58472261e+00 -4.85640176e-03  1.15576264e+01]\n",
      "Loss: 6.788967529479229\n",
      "\n",
      "Iteration: 427\n",
      "P: [ 5.50750801e+00 -1.58494946e+00 -4.85887713e-03  1.15576949e+01]\n",
      "Loss: 6.788792925731159\n",
      "\n",
      "Iteration: 428\n",
      "P: [ 5.50785628e+00 -1.58537382e+00 -4.86350761e-03  1.15578230e+01]\n",
      "Loss: 6.788493138770779\n",
      "\n",
      "Iteration: 429\n",
      "P: [ 5.50843059e+00 -1.58607358e+00 -4.87114240e-03  1.15580342e+01]\n",
      "Loss: 6.788113063886409\n",
      "\n",
      "Iteration: 430\n",
      "P: [ 5.50861946e+00 -1.58630366e+00 -4.87365184e-03  1.15581037e+01]\n",
      "Loss: 6.787447530195571\n",
      "\n",
      "Iteration: 431\n",
      "P: [ 5.50886778e+00 -1.58660620e+00 -4.87695235e-03  1.15581951e+01]\n",
      "Loss: 6.787180718902507\n",
      "\n",
      "Iteration: 432\n",
      "P: [ 5.50907924e+00 -1.58686382e+00 -4.87976288e-03  1.15582728e+01]\n",
      "Loss: 6.786980138511054\n",
      "\n",
      "Iteration: 433\n",
      "P: [ 5.50946216e+00 -1.58733034e+00 -4.88485197e-03  1.15584137e+01]\n",
      "Loss: 6.786699263949846\n",
      "\n",
      "Iteration: 434\n",
      "P: [ 5.50978301e+00 -1.58772121e+00 -4.88911546e-03  1.15585318e+01]\n",
      "Loss: 6.786311124031336\n",
      "\n",
      "Iteration: 435\n",
      "P: [ 5.51019153e+00 -1.58821882e+00 -4.89454251e-03  1.15586821e+01]\n",
      "Loss: 6.7856136700145075\n",
      "\n",
      "Iteration: 436\n",
      "P: [ 5.51038867e+00 -1.58845898e+00 -4.89716198e-03  1.15587546e+01]\n",
      "Loss: 6.785405937162675\n",
      "\n",
      "Iteration: 437\n",
      "P: [ 5.51052443e+00 -1.58862435e+00 -4.89896561e-03  1.15588046e+01]\n",
      "Loss: 6.785277379114368\n",
      "\n",
      "Iteration: 438\n",
      "P: [ 5.51080622e+00 -1.58896761e+00 -4.90270940e-03  1.15589083e+01]\n",
      "Loss: 6.785060524254698\n",
      "\n",
      "Iteration: 439\n",
      "P: [ 5.51123951e+00 -1.58949538e+00 -4.90846525e-03  1.15590677e+01]\n",
      "Loss: 6.784891070064055\n",
      "\n",
      "Iteration: 440\n",
      "P: [ 5.51124470e+00 -1.58950168e+00 -4.90853362e-03  1.15590696e+01]\n",
      "Loss: 6.7844792310164035\n",
      "\n",
      "Iteration: 441\n",
      "P: [ 5.51180954e+00 -1.59018964e+00 -4.91603559e-03  1.15592775e+01]\n",
      "Loss: 6.783883793330353\n",
      "\n",
      "Iteration: 442\n",
      "P: [ 5.51230455e+00 -1.59079251e+00 -4.92260932e-03  1.15594597e+01]\n",
      "Loss: 6.783492635248713\n",
      "\n",
      "Iteration: 443\n",
      "P: [ 5.51275515e+00 -1.59134123e+00 -4.92859160e-03  1.15596256e+01]\n",
      "Loss: 6.782658585663461\n",
      "\n",
      "Iteration: 444\n",
      "P: [ 5.51289855e+00 -1.59151587e+00 -4.93049575e-03  1.15596784e+01]\n",
      "Loss: 6.782523118124324\n",
      "\n",
      "Iteration: 445\n",
      "P: [ 5.51316403e+00 -1.59183917e+00 -4.93402056e-03  1.15597762e+01]\n",
      "Loss: 6.782312130295057\n",
      "\n",
      "Iteration: 446\n",
      "P: [ 5.51341193e+00 -1.59214105e+00 -4.93731170e-03  1.15598674e+01]\n",
      "Loss: 6.782128709417341\n",
      "\n",
      "Iteration: 447\n",
      "P: [ 5.51380202e+00 -1.59261605e+00 -4.94248981e-03  1.15600111e+01]\n",
      "Loss: 6.781705283575847\n",
      "\n",
      "Iteration: 448\n",
      "P: [ 5.51411929e+00 -1.59300233e+00 -4.94670022e-03  1.15601279e+01]\n",
      "Loss: 6.7810924469208596\n",
      "\n",
      "Iteration: 449\n",
      "P: [ 5.51443970e+00 -1.59339247e+00 -4.95095309e-03  1.15602459e+01]\n",
      "Loss: 6.780822330371139\n",
      "\n",
      "Iteration: 450\n",
      "P: [ 5.51493519e+00 -1.59399576e+00 -4.95752890e-03  1.15604284e+01]\n",
      "Loss: 6.780631528198687\n",
      "\n",
      "Iteration: 451\n",
      "P: [ 5.51502065e+00 -1.59409977e+00 -4.95866214e-03  1.15604599e+01]\n",
      "Loss: 6.78008955498934\n",
      "\n",
      "Iteration: 452\n",
      "P: [ 5.51568411e+00 -1.59490751e+00 -4.96746561e-03  1.15607043e+01]\n",
      "Loss: 6.779662660270897\n",
      "\n",
      "Iteration: 453\n",
      "P: [ 5.51579225e+00 -1.59503914e+00 -4.96889980e-03  1.15607441e+01]\n",
      "Loss: 6.779215201561597\n",
      "\n",
      "Iteration: 454\n",
      "P: [ 5.51637378e+00 -1.59574705e+00 -4.97661446e-03  1.15609583e+01]\n",
      "Loss: 6.7788004063380045\n",
      "\n",
      "Iteration: 455\n",
      "P: [ 5.51655844e+00 -1.59597182e+00 -4.97906344e-03  1.15610264e+01]\n",
      "Loss: 6.778336817247563\n",
      "\n",
      "Iteration: 456\n",
      "P: [ 5.51683249e+00 -1.59630540e+00 -4.98269844e-03  1.15611273e+01]\n",
      "Loss: 6.778115574552388\n",
      "\n",
      "Iteration: 457\n",
      "P: [ 5.51714343e+00 -1.59668388e+00 -4.98682238e-03  1.15612419e+01]\n",
      "Loss: 6.777833401345919\n",
      "\n",
      "Iteration: 458\n",
      "P: [ 5.51752858e+00 -1.59715266e+00 -4.99192969e-03  1.15613839e+01]\n",
      "Loss: 6.777246278718446\n",
      "\n",
      "Iteration: 459\n",
      "P: [ 5.51785708e+00 -1.59755248e+00 -4.99628583e-03  1.15615049e+01]\n",
      "Loss: 6.777017410767488\n",
      "\n",
      "Iteration: 460\n",
      "P: [ 5.51825414e+00 -1.59803572e+00 -5.00155036e-03  1.15616512e+01]\n",
      "Loss: 6.7765453792323544\n",
      "\n",
      "Iteration: 461\n",
      "P: [ 5.51853679e+00 -1.59837967e+00 -5.00529673e-03  1.15617554e+01]\n",
      "Loss: 6.776067245431084\n",
      "\n",
      "Iteration: 462\n",
      "P: [ 5.51887808e+00 -1.59879502e+00 -5.00982143e-03  1.15618812e+01]\n",
      "Loss: 6.775652291982045\n",
      "\n",
      "Iteration: 463\n",
      "P: [ 5.51904360e+00 -1.59899646e+00 -5.01201572e-03  1.15619422e+01]\n",
      "Loss: 6.775527112264201\n",
      "\n",
      "Iteration: 464\n",
      "P: [ 5.51906765e+00 -1.59902571e+00 -5.01233433e-03  1.15619511e+01]\n",
      "Loss: 6.775463233809087\n",
      "\n",
      "Iteration: 465\n",
      "P: [ 5.51935274e+00 -1.59937265e+00 -5.01611326e-03  1.15620562e+01]\n",
      "Loss: 6.775154411227714\n",
      "\n",
      "Iteration: 466\n",
      "P: [ 5.51965388e+00 -1.59973909e+00 -5.02010468e-03  1.15621672e+01]\n",
      "Loss: 6.774908799254508\n",
      "\n",
      "Iteration: 467\n",
      "P: [ 5.51999326e+00 -1.60015204e+00 -5.02460223e-03  1.15622923e+01]\n",
      "Loss: 6.774507589442168\n",
      "\n",
      "Iteration: 468\n",
      "P: [ 5.52038874e+00 -1.60063323e+00 -5.02984245e-03  1.15624382e+01]\n",
      "Loss: 6.773933738310375\n",
      "\n",
      "Iteration: 469\n",
      "P: [ 5.52048894e+00 -1.60075515e+00 -5.03117028e-03  1.15624751e+01]\n",
      "Loss: 6.773836613563835\n",
      "\n",
      "Iteration: 470\n",
      "P: [ 5.52075519e+00 -1.60107910e+00 -5.03469825e-03  1.15625733e+01]\n",
      "Loss: 6.773622395625515\n",
      "\n",
      "Iteration: 471\n",
      "P: [ 5.52102867e+00 -1.60141185e+00 -5.03832175e-03  1.15626741e+01]\n",
      "Loss: 6.773401641926802\n",
      "\n",
      "Iteration: 472\n",
      "P: [ 5.52136967e+00 -1.60182671e+00 -5.04283915e-03  1.15627999e+01]\n",
      "Loss: 6.772938172037216\n",
      "\n",
      "Iteration: 473\n",
      "P: [ 5.52169628e+00 -1.60222404e+00 -5.04716527e-03  1.15629204e+01]\n",
      "Loss: 6.7724618097756055\n",
      "\n",
      "Iteration: 474\n",
      "P: [ 5.52178865e+00 -1.60233643e+00 -5.04838903e-03  1.15629544e+01]\n",
      "Loss: 6.772377215552548\n",
      "\n",
      "Iteration: 475\n",
      "P: [ 5.52206042e+00 -1.60266704e+00 -5.05198883e-03  1.15630547e+01]\n",
      "Loss: 6.772152799376399\n",
      "\n",
      "Iteration: 476\n",
      "P: [ 5.52225752e+00 -1.60290682e+00 -5.05459948e-03  1.15631274e+01]\n",
      "Loss: 6.7720038349482365\n",
      "\n",
      "Iteration: 477\n",
      "P: [ 5.52256783e+00 -1.60328430e+00 -5.05870909e-03  1.15632418e+01]\n",
      "Loss: 6.771620891547623\n",
      "\n",
      "Iteration: 478\n",
      "P: [ 5.52289702e+00 -1.60368471e+00 -5.06306800e-03  1.15633633e+01]\n",
      "Loss: 6.771114310137675\n",
      "\n",
      "Iteration: 479\n",
      "P: [ 5.52306381e+00 -1.60388760e+00 -5.06527677e-03  1.15634248e+01]\n",
      "Loss: 6.770979680310501\n",
      "\n",
      "Iteration: 480\n",
      "P: [ 5.52332406e+00 -1.60420416e+00 -5.06872289e-03  1.15635208e+01]\n",
      "Loss: 6.770758753650497\n",
      "\n",
      "Iteration: 481\n",
      "P: [ 5.52387093e+00 -1.60486934e+00 -5.07596364e-03  1.15637226e+01]\n",
      "Loss: 6.770543818341269\n",
      "\n",
      "Iteration: 482\n",
      "P: [ 5.52384408e+00 -1.60483665e+00 -5.07560735e-03  1.15637127e+01]\n",
      "Loss: 6.770038166435461\n",
      "\n",
      "Iteration: 483\n",
      "P: [ 5.52427197e+00 -1.60535708e+00 -5.08127201e-03  1.15638705e+01]\n",
      "Loss: 6.7696197251517045\n",
      "\n",
      "Iteration: 484\n",
      "P: [ 5.52447380e+00 -1.60560256e+00 -5.08394385e-03  1.15639450e+01]\n",
      "Loss: 6.769478203249192\n",
      "\n",
      "Iteration: 485\n",
      "P: [ 5.52470991e+00 -1.60588971e+00 -5.08706891e-03  1.15640322e+01]\n",
      "Loss: 6.769132943908918\n",
      "\n",
      "Iteration: 486\n",
      "P: [ 5.52494197e+00 -1.60617192e+00 -5.09014032e-03  1.15641178e+01]\n",
      "Loss: 6.768920047452333\n",
      "\n",
      "Iteration: 487\n",
      "P: [ 5.52560783e+00 -1.60698168e+00 -5.09895241e-03  1.15643635e+01]\n",
      "Loss: 6.768300415833183\n",
      "\n",
      "Iteration: 488\n",
      "P: [ 5.52581578e+00 -1.60723451e+00 -5.10170288e-03  1.15644403e+01]\n",
      "Loss: 6.768019796418204\n",
      "\n",
      "Iteration: 489\n",
      "P: [ 5.52630438e+00 -1.60782867e+00 -5.10816847e-03  1.15646206e+01]\n",
      "Loss: 6.767347221397767\n",
      "\n",
      "Iteration: 490\n",
      "P: [ 5.52635051e+00 -1.60788477e+00 -5.10877891e-03  1.15646377e+01]\n",
      "Loss: 6.7673298811999345\n",
      "\n",
      "Iteration: 491\n",
      "P: [ 5.52653538e+00 -1.60810957e+00 -5.11122480e-03  1.15647059e+01]\n",
      "Loss: 6.7671580987594755\n",
      "\n",
      "Iteration: 492\n",
      "P: [ 5.52697724e+00 -1.60864684e+00 -5.11707026e-03  1.15648690e+01]\n",
      "Loss: 6.76682024248453\n",
      "\n",
      "Iteration: 493\n",
      "P: [ 5.52711696e+00 -1.60881670e+00 -5.11891791e-03  1.15649206e+01]\n",
      "Loss: 6.766393081974988\n",
      "\n",
      "Iteration: 494\n",
      "P: [ 5.52731964e+00 -1.60906313e+00 -5.12159893e-03  1.15649955e+01]\n",
      "Loss: 6.766190869553368\n",
      "\n",
      "Iteration: 495\n",
      "P: [ 5.52756240e+00 -1.60935829e+00 -5.12480990e-03  1.15650851e+01]\n",
      "Loss: 6.765997136412746\n",
      "\n",
      "Iteration: 496\n",
      "P: [ 5.52801396e+00 -1.60990730e+00 -5.13078228e-03  1.15652518e+01]\n",
      "Loss: 6.765846572342395\n",
      "\n",
      "Iteration: 497\n",
      "P: [ 5.52790520e+00 -1.60977505e+00 -5.12934334e-03  1.15652117e+01]\n",
      "Loss: 6.7655140733487675\n",
      "\n",
      "Iteration: 498\n",
      "P: [ 5.52842449e+00 -1.61040637e+00 -5.13621064e-03  1.15654034e+01]\n",
      "Loss: 6.765109624890038\n",
      "\n",
      "Iteration: 499\n",
      "P: [ 5.52849989e+00 -1.61049803e+00 -5.13720752e-03  1.15654313e+01]\n",
      "Loss: 6.764884747087725\n",
      "\n",
      "Iteration: 500\n",
      "P: [ 5.52885152e+00 -1.61092550e+00 -5.14185704e-03  1.15655611e+01]\n",
      "Loss: 6.764600661643501\n",
      "\n",
      "Iteration: 501\n",
      "P: [ 5.52919748e+00 -1.61134605e+00 -5.14643095e-03  1.15656889e+01]\n",
      "Loss: 6.7642519771206215\n",
      "\n",
      "Iteration: 502\n",
      "P: [ 5.52949531e+00 -1.61170807e+00 -5.15036762e-03  1.15657989e+01]\n",
      "Loss: 6.76377235155209\n",
      "\n",
      "Iteration: 503\n",
      "P: [ 5.52968530e+00 -1.61193902e+00 -5.15287937e-03  1.15658691e+01]\n",
      "Loss: 6.7635376461700325\n",
      "\n",
      "Iteration: 504\n",
      "P: [ 5.52989079e+00 -1.61218880e+00 -5.15559581e-03  1.15659450e+01]\n",
      "Loss: 6.763380417789348\n",
      "\n",
      "Iteration: 505\n",
      "P: [ 5.52998097e+00 -1.61229842e+00 -5.15678777e-03  1.15659783e+01]\n",
      "Loss: 6.763288314570173\n",
      "\n",
      "Iteration: 506\n",
      "P: [ 5.53059466e+00 -1.61304434e+00 -5.16489907e-03  1.15662050e+01]\n",
      "Loss: 6.762925277789261\n",
      "\n",
      "Iteration: 507\n",
      "P: [ 5.53062666e+00 -1.61308322e+00 -5.16532130e-03  1.15662168e+01]\n",
      "Loss: 6.762508915747315\n",
      "\n",
      "Iteration: 508\n",
      "P: [ 5.53115019e+00 -1.61371953e+00 -5.17224016e-03  1.15664102e+01]\n",
      "Loss: 6.762131814129027\n",
      "\n",
      "Iteration: 509\n",
      "P: [ 5.53111491e+00 -1.61367663e+00 -5.17177355e-03  1.15663972e+01]\n",
      "Loss: 6.761977682908765\n",
      "\n",
      "Iteration: 510\n",
      "P: [ 5.53133739e+00 -1.61394702e+00 -5.17471324e-03  1.15664794e+01]\n",
      "Loss: 6.761723368907208\n",
      "\n",
      "Iteration: 511\n",
      "P: [ 5.53144433e+00 -1.61407699e+00 -5.17612630e-03  1.15665189e+01]\n",
      "Loss: 6.7616172566570265\n",
      "\n",
      "Iteration: 512\n",
      "P: [ 5.53154881e+00 -1.61420398e+00 -5.17750685e-03  1.15665575e+01]\n",
      "Loss: 6.761516182744819\n",
      "\n",
      "Iteration: 513\n",
      "P: [ 5.53183518e+00 -1.61455199e+00 -5.18129041e-03  1.15666633e+01]\n",
      "Loss: 6.761301264729873\n",
      "\n",
      "Iteration: 514\n",
      "P: [ 5.53204712e+00 -1.61480956e+00 -5.18409039e-03  1.15667416e+01]\n",
      "Loss: 6.761094911735849\n",
      "\n",
      "Iteration: 515\n",
      "P: [ 5.53239583e+00 -1.61523331e+00 -5.18869672e-03  1.15668705e+01]\n",
      "Loss: 6.760580743777604\n",
      "\n",
      "Iteration: 516\n",
      "P: [ 5.53257081e+00 -1.61544595e+00 -5.19100821e-03  1.15669351e+01]\n",
      "Loss: 6.76046607232584\n",
      "\n",
      "Iteration: 517\n",
      "P: [ 5.53290813e+00 -1.61585585e+00 -5.19546370e-03  1.15670598e+01]\n",
      "Loss: 6.760110990222051\n",
      "\n",
      "Iteration: 518\n",
      "P: [ 5.53324484e+00 -1.61626498e+00 -5.19991042e-03  1.15671843e+01]\n",
      "Loss: 6.759635458443343\n",
      "\n",
      "Iteration: 519\n",
      "P: [ 5.53334362e+00 -1.61638501e+00 -5.20121508e-03  1.15672208e+01]\n",
      "Loss: 6.75955672683291\n",
      "\n",
      "Iteration: 520\n",
      "P: [ 5.53347511e+00 -1.61654477e+00 -5.20295141e-03  1.15672694e+01]\n",
      "Loss: 6.759392159748779\n",
      "\n",
      "Iteration: 521\n",
      "P: [ 5.53366616e+00 -1.61677691e+00 -5.20547441e-03  1.15673400e+01]\n",
      "Loss: 6.759225983249455\n",
      "\n",
      "Iteration: 522\n",
      "P: [ 5.53397896e+00 -1.61715697e+00 -5.20960502e-03  1.15674556e+01]\n",
      "Loss: 6.758989900393549\n",
      "\n",
      "Iteration: 523\n",
      "P: [ 5.53417047e+00 -1.61738964e+00 -5.21213339e-03  1.15675264e+01]\n",
      "Loss: 6.758650939399258\n",
      "\n",
      "Iteration: 524\n",
      "P: [ 5.53429937e+00 -1.61754625e+00 -5.21383541e-03  1.15675741e+01]\n",
      "Loss: 6.758550383196793\n",
      "\n",
      "Iteration: 525\n",
      "P: [ 5.53465557e+00 -1.61797901e+00 -5.21853813e-03  1.15677058e+01]\n",
      "Loss: 6.758210053170973\n",
      "\n",
      "Iteration: 526\n",
      "P: [ 5.53499680e+00 -1.61839355e+00 -5.22304266e-03  1.15678319e+01]\n",
      "Loss: 6.7577766526176\n",
      "\n",
      "Iteration: 527\n",
      "P: [ 5.53526641e+00 -1.61872108e+00 -5.22660134e-03  1.15679316e+01]\n",
      "Loss: 6.757424557209614\n",
      "\n",
      "Iteration: 528\n",
      "P: [ 5.53535519e+00 -1.61882893e+00 -5.22777325e-03  1.15679644e+01]\n",
      "Loss: 6.757338286709105\n",
      "\n",
      "Iteration: 529\n",
      "P: [ 5.53547915e+00 -1.61897951e+00 -5.22940945e-03  1.15680103e+01]\n",
      "Loss: 6.7572268157146675\n",
      "\n",
      "Iteration: 530\n",
      "P: [ 5.53569700e+00 -1.61924416e+00 -5.23228493e-03  1.15680908e+01]\n",
      "Loss: 6.75708097796482\n",
      "\n",
      "Iteration: 531\n",
      "P: [ 5.53597408e+00 -1.61958075e+00 -5.23594202e-03  1.15681933e+01]\n",
      "Loss: 6.756964430570403\n",
      "\n",
      "Iteration: 532\n",
      "P: [ 5.53608782e+00 -1.61971891e+00 -5.23744284e-03  1.15682353e+01]\n",
      "Loss: 6.756644452254942\n",
      "\n",
      "Iteration: 533\n",
      "P: [ 5.53620860e+00 -1.61986560e+00 -5.23903639e-03  1.15682800e+01]\n",
      "Loss: 6.756402630469288\n",
      "\n",
      "Iteration: 534\n",
      "P: [ 5.53620860e+00 -1.61986560e+00 -5.23903638e-03  1.15682800e+01]\n",
      "Loss: 6.756402366151355\n",
      "\n",
      "Iteration: 535\n",
      "P: [ 5.53620860e+00 -1.61986560e+00 -5.23903636e-03  1.15682800e+01]\n",
      "Loss: 6.75640196635104\n",
      "\n",
      "Iteration: 536\n",
      "P: [ 5.53620860e+00 -1.61986560e+00 -5.23903636e-03  1.15682800e+01]\n",
      "Loss: 6.756401965104201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train policy\n",
    "initial_state = jnp.array([0, 0, np.pi, 0])\n",
    "sigma = jnp.array([10, 8, 4, 10])\n",
    "# sigma = jnp.array([5.8, 5.8, 1.5, 8.5])  # Example sigma values\n",
    "num_steps = 50\n",
    "target = jnp.array([0, 0, 0, 0])\n",
    "max_force = 10\n",
    "\n",
    "initial_p = jnp.array([5, 5, 5, 5])  # initial policy parameters for upright initial starting position\n",
    "\n",
    "model_x_prime = jnp.array(non_linear_model_sin_force_down['X_prime'])\n",
    "model_sigma = jnp.array(non_linear_model_sin_force_down['sigma'])\n",
    "model_alpha = jnp.array(non_linear_model_sin_force_down['alpha'])\n",
    "\n",
    "@jax.jit\n",
    "def kernel_expanded_jax(X, X_prime, sigma):\n",
    "    # create new X where 2 additional dimensions are added, replacing the angle with sin and cos\n",
    "    # angle dimension is removed\n",
    "    X_new = jnp.hstack((X[:,0:2], jnp.sin(X[:, 2:3]), jnp.cos(X[:, 2:3]), X[:, 3:]))  # (N, D+1)\n",
    "    X_prime_new = jnp.hstack((X_prime[:,0:2], jnp.sin(X_prime[:, 2:3]), jnp.cos(X_prime[:, 2:3]), X_prime[:, 3:]))  # (M, D+1)\n",
    "\n",
    "    X_e = jnp.expand_dims(X_new, axis=1)  # (N, 1, D+1)\n",
    "    X_prime_e = jnp.expand_dims(X_prime_new, axis=0)  # (1, M, D+1)\n",
    "\n",
    "    diff = X_e - X_prime_e  # (N, M, D+1)\n",
    "    scaled_squared_diff = (diff ** 2)/(2 * sigma ** 2) # (N, M, D+1)\n",
    "\n",
    "    K = jnp.exp(-jnp.sum(scaled_squared_diff, axis=-1))  # (N, M)\n",
    "    return K\n",
    "\n",
    "@jax.jit\n",
    "def loss_policy_jax(state, target, sigma):\n",
    "    delta = (state - target) / sigma\n",
    "    exponent = 0.5 * jnp.dot(delta, delta)\n",
    "    return 1 - jnp.exp(-exponent)\n",
    "\n",
    "@jax.jit\n",
    "def loss_rollout_linear_jax(P):\n",
    "    def scan_step_jax(state, _):\n",
    "        force = P @ state\n",
    "        force = max_force * jnp.tanh(force/max_force)\n",
    "\n",
    "        # add force as the last element to the state\n",
    "        current_state = jnp.concatenate([state, jnp.array([force])])\n",
    "        K = kernel_expanded_jax(jnp.expand_dims(current_state, axis=0), model_x_prime, model_sigma)\n",
    "        Y_pred = K @ model_alpha\n",
    "        next_state = jnp.ravel(current_state[:-1] + Y_pred)\n",
    "\n",
    "        loss = loss_policy_jax(next_state, target, sigma)\n",
    "        return next_state, loss\n",
    "\n",
    "    init_loss = loss_policy_jax(initial_state, target, sigma)\n",
    "    _, losses = jax.lax.scan(scan_step_jax, initial_state, None, length=num_steps)\n",
    "    return init_loss + losses.sum()\n",
    "\n",
    "grad_loss_linear_jax = jax.grad(loss_rollout_linear_jax)\n",
    "\n",
    "losses = [loss_rollout_linear_jax(initial_p)]\n",
    "print(\"Initial loss:\", losses[0])\n",
    "\n",
    "def callback(intermediate_result):\n",
    "    print(\"Iteration:\", len(losses))\n",
    "    print(\"P:\", intermediate_result.x)\n",
    "    print(\"Loss:\", intermediate_result.fun)\n",
    "    print()\n",
    "    losses.append(intermediate_result.fun)\n",
    "\n",
    "res = scipy.optimize.minimize(loss_rollout_linear_jax, x0=initial_p, method='L-BFGS-B', jac=grad_loss_linear_jax, callback=callback, bounds=[(-20, 20)] * 2 + [(-30, 30)] + [(-20, 20)]) \n",
    "\n",
    "def rollout_linear_force(initial_state, num_steps, P, max_force):\n",
    "    X_forecast = [initial_state.copy()]\n",
    "    \n",
    "    state = initial_state.copy()\n",
    "    for step in range(num_steps):\n",
    "        force = P @ state\n",
    "        force = max_force * np.tanh(force/max_force)\n",
    "        # add force as the last element to the state\n",
    "        current_state = jnp.concatenate([state, jnp.array([force])])\n",
    "        K = kernel_expanded_jax(jnp.expand_dims(current_state, axis=0), model_x_prime, model_sigma)\n",
    "\n",
    "        Y_pred = K @ model_alpha\n",
    "        state = jnp.ravel(current_state[:-1] + Y_pred)\n",
    "\n",
    "        remapped_state = state.copy()\n",
    "        # remap jax angle to be between -pi and pi PURELY FOR PLOTTING\n",
    "        remapped_state = np.array([remapped_state[0], remapped_state[1], remap_angle2(remapped_state[2]), remapped_state[3]])\n",
    "        X_forecast.append(remapped_state)\n",
    "\n",
    "    return np.array(X_forecast)\n",
    "\n",
    "P = res.x  # optimised policy matrix\n",
    "X = rollout_linear_force(initial_state=initial_state, num_steps=25, P=P, max_force=max_force)\n",
    "plot_policy(X, target, f\"Rollout Policy, initial_state: {initial_state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a877255",
   "metadata": {},
   "source": [
    "---\n",
    "### Real dynamics noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4781dd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_random_force_real_noise(num_steps, max_force, std):\n",
    "    env = CartPole(visual=False, max_force=max_force)\n",
    "    env.reset()\n",
    "    x_data = {\n",
    "        'cart_location': [],\n",
    "        'cart_velocity': [],\n",
    "        'pole_angle': [],\n",
    "        'pole_velocity': [],\n",
    "        'force': []\n",
    "    }\n",
    "\n",
    "    y_data = {\n",
    "        'cart_location': [],\n",
    "        'cart_velocity': [],\n",
    "        'pole_angle': [],\n",
    "        'pole_velocity': []\n",
    "    }\n",
    "    for i in range(num_steps):\n",
    "        initial_state = [np.random.uniform(-10, 10), np.random.uniform(-10, 10),\n",
    "                         np.random.uniform(-np.pi, np.pi), np.random.uniform(-15, 15)]\n",
    "        initial_force = np.random.uniform(-env.max_force, env.max_force)\n",
    "        env.reset()\n",
    "        env.setState(initial_state)\n",
    "        env.performAction_noise(initial_force, std)\n",
    "\n",
    "        # remap the angle to be between -pi and pi\n",
    "        # env.remap_angle()\n",
    "        \n",
    "        next_state = env.getState()\n",
    "    \n",
    "        x_data['cart_location'].append(initial_state[0])\n",
    "        x_data['cart_velocity'].append(initial_state[1])\n",
    "        x_data['pole_angle'].append(initial_state[2])\n",
    "        x_data['pole_velocity'].append(initial_state[3])\n",
    "        x_data['force'].append(initial_force)\n",
    "\n",
    "        y_data['cart_location'].append(next_state[0] - initial_state[0])\n",
    "        y_data['cart_velocity'].append(next_state[1] - initial_state[1])\n",
    "        y_data['pole_angle'].append(next_state[2] - initial_state[2])\n",
    "        y_data['pole_velocity'].append(next_state[3] - initial_state[3])\n",
    "\n",
    "    X = convert_dict_to_array(x_data)\n",
    "    Y = convert_dict_to_array(y_data)\n",
    "    \n",
    "    # print(\"shape of X:\", X.shape, \"\\nshape of Y:\", Y.shape)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9f95b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fun: 0.05225262152158267\n",
      "   x: [ 1.000e-06  5.766e+00  5.742e+00  4.643e-01  4.930e-01  8.701e+00\n",
      "        8.668e+00]\n",
      " fun: 0.044636675365970754\n",
      "   x: [ 2.596e-02  5.790e+00  5.765e+00  5.894e-01  5.634e-01  8.693e+00\n",
      "        8.681e+00]\n",
      " fun: 0.04014535123748864\n",
      "   x: [ 1.000e-06  5.833e+00  5.807e+00  7.284e-01  6.277e-01  8.679e+00\n",
      "        8.705e+00]\n",
      " fun: 0.03846511784603547\n",
      "   x: [ 2.933e-02  5.896e+00  5.871e+00  8.956e-01  6.920e-01  8.658e+00\n",
      "        8.741e+00]\n",
      " fun: 0.037281931490235565\n",
      "   x: [ 9.323e-03  5.926e+00  5.903e+00  9.610e-01  7.071e-01  8.648e+00\n",
      "        8.758e+00]\n",
      " fun: 0.03661412873735718\n",
      "   x: [ 1.000e-06  5.974e+00  5.954e+00  1.000e+00  7.223e-01  8.632e+00\n",
      "        8.786e+00]\n",
      " fun: 0.030161137315313072\n",
      "   x: [ 1.000e-06  6.403e+00  6.411e+00  1.000e+00  7.517e-01  8.487e+00\n",
      "        9.032e+00]\n",
      " fun: 0.017336941592531643\n",
      "   x: [ 8.926e-03  7.635e+00  7.728e+00  1.000e+00  6.520e-01  8.077e+00\n",
      "        9.756e+00]\n",
      " fun: 0.012091395491499861\n",
      "   x: [ 1.084e-03  8.707e+00  8.873e+00  1.000e+00  5.800e-01  7.721e+00\n",
      "        1.039e+01]\n",
      " fun: 0.00977411665431563\n",
      "   x: [ 8.044e-04  9.665e+00  9.896e+00  1.000e+00  5.553e-01  7.403e+00\n",
      "        1.095e+01]\n",
      " fun: 0.007565817301486427\n",
      "   x: [ 9.610e-03  1.114e+01  1.147e+01  1.000e+00  5.450e-01  6.915e+00\n",
      "        1.181e+01]\n",
      " fun: 0.006130185672958712\n",
      "   x: [ 1.136e-02  1.288e+01  1.333e+01  1.000e+00  5.409e-01  6.339e+00\n",
      "        1.283e+01]\n",
      " fun: 0.00515131920858108\n",
      "   x: [ 9.832e-03  1.499e+01  1.558e+01  9.931e-01  5.346e-01  5.644e+00\n",
      "        1.407e+01]\n",
      " fun: 0.004631077013688027\n",
      "   x: [ 6.724e-03  1.720e+01  1.794e+01  8.538e-01  6.982e-01  4.952e+00\n",
      "        1.538e+01]\n",
      " fun: 0.004541076680855392\n",
      "   x: [ 3.416e-03  1.780e+01  1.858e+01  7.715e-01  6.616e-01  4.769e+00\n",
      "        1.573e+01]\n",
      " fun: 0.004380896234939835\n",
      "   x: [ 3.456e-03  1.951e+01  2.041e+01  8.493e-01  6.156e-01  4.189e+00\n",
      "        1.674e+01]\n",
      " fun: 0.004380860393943251\n",
      "   x: [ 3.418e-03  1.948e+01  2.037e+01  8.510e-01  6.194e-01  4.199e+00\n",
      "        1.672e+01]\n",
      " fun: 0.0043648455764389565\n",
      "   x: [ 2.341e-03  1.983e+01  2.075e+01  9.000e-01  6.249e-01  4.079e+00\n",
      "        1.692e+01]\n",
      " fun: 0.004347047087689885\n",
      "   x: [ 3.788e-03  2.030e+01  2.125e+01  9.680e-01  6.404e-01  3.916e+00\n",
      "        1.720e+01]\n",
      " fun: 0.004341940806436906\n",
      "   x: [ 3.421e-03  2.026e+01  2.121e+01  9.754e-01  6.388e-01  3.935e+00\n",
      "        1.718e+01]\n",
      " fun: 0.004329109018797474\n",
      "   x: [ 2.431e-03  2.026e+01  2.122e+01  1.000e+00  6.350e-01  3.970e+00\n",
      "        1.719e+01]\n",
      " fun: 0.004270177856022846\n",
      "   x: [ 1.618e-03  2.029e+01  2.130e+01  1.000e+00  6.172e-01  4.156e+00\n",
      "        1.726e+01]\n",
      " fun: 0.0041028909256601\n",
      "   x: [ 1.901e-03  2.087e+01  2.204e+01  1.000e+00  5.832e-01  4.512e+00\n",
      "        1.775e+01]\n",
      " fun: 0.003771917341649096\n",
      "   x: [ 2.154e-03  2.363e+01  2.534e+01  9.448e-01  5.508e-01  5.054e+00\n",
      "        1.978e+01]\n",
      " fun: 0.003570670754377039\n",
      "   x: [ 2.690e-03  2.723e+01  2.960e+01  8.953e-01  4.955e-01  5.584e+00\n",
      "        2.238e+01]\n",
      " fun: 0.0034997304944371053\n",
      "   x: [ 2.343e-03  3.000e+01  3.289e+01  9.069e-01  4.843e-01  5.890e+00\n",
      "        2.438e+01]\n",
      " fun: 0.0034912337546189353\n",
      "   x: [ 2.038e-03  3.000e+01  3.289e+01  9.277e-01  5.069e-01  5.862e+00\n",
      "        2.437e+01]\n",
      " fun: 0.003490472040227657\n",
      "   x: [ 1.994e-03  3.000e+01  3.288e+01  9.285e-01  5.110e-01  5.857e+00\n",
      "        2.437e+01]\n",
      " fun: 0.0034899516438820517\n",
      "   x: [ 1.972e-03  3.000e+01  3.288e+01  9.269e-01  5.141e-01  5.854e+00\n",
      "        2.437e+01]\n",
      " fun: 0.0034892856306091187\n",
      "   x: [ 1.935e-03  3.000e+01  3.288e+01  9.207e-01  5.175e-01  5.844e+00\n",
      "        2.437e+01]\n",
      " fun: 0.0034876916401608846\n",
      "   x: [ 1.870e-03  3.000e+01  3.287e+01  8.871e-01  5.315e-01  5.794e+00\n",
      "        2.436e+01]\n",
      " fun: 0.0034874104857013028\n",
      "   x: [ 1.884e-03  3.000e+01  3.287e+01  8.736e-01  5.340e-01  5.775e+00\n",
      "        2.435e+01]\n",
      " fun: 0.0034873806639592374\n",
      "   x: [ 1.851e-03  3.000e+01  3.286e+01  8.701e-01  5.336e-01  5.773e+00\n",
      "        2.435e+01]\n",
      " fun: 0.003487056621723338\n",
      "   x: [ 1.910e-03  3.000e+01  3.286e+01  8.480e-01  5.344e-01  5.744e+00\n",
      "        2.434e+01]\n",
      " fun: 0.003487018956932313\n",
      "   x: [ 1.921e-03  3.000e+01  3.285e+01  8.465e-01  5.337e-01  5.742e+00\n",
      "        2.434e+01]\n",
      " fun: 0.0034869962763734437\n",
      "   x: [ 1.929e-03  3.000e+01  3.285e+01  8.461e-01  5.330e-01  5.743e+00\n",
      "        2.434e+01]\n",
      " fun: 0.003486982334290925\n",
      "   x: [ 1.934e-03  3.000e+01  3.285e+01  8.460e-01  5.325e-01  5.743e+00\n",
      "        2.434e+01]\n",
      " fun: 0.0034869810747796153\n",
      "   x: [ 1.935e-03  3.000e+01  3.285e+01  8.459e-01  5.324e-01  5.743e+00\n",
      "        2.434e+01]\n"
     ]
    }
   ],
   "source": [
    "# train sine cosine model\n",
    "\n",
    "N_train, N_test, M = 4096, 2048, 1024\n",
    "max_force = 15\n",
    "state_std = 0.05\n",
    "\n",
    "X, Y = generate_data_random_force_real_noise(num_steps=N_train+N_test, max_force=max_force, std=state_std)\n",
    "X = jnp.array(X)\n",
    "Y = jnp.array(Y)\n",
    "X_prime = X[:M]\n",
    "\n",
    "X_train = X[:N_train]\n",
    "Y_train = Y[:N_train]\n",
    "\n",
    "X_val = X[-N_test:]\n",
    "Y_val = Y[-N_test:]\n",
    "\n",
    "def loss(parameters):\n",
    "    lamb = parameters[0]\n",
    "    sigma = parameters[1:]\n",
    "    # train model\n",
    "    alpha, X_prime, _= train_nonlinear_models_j(X_train, Y_train, M=M, lamb=lamb, sigma=sigma, kernel_fn=kernel_expanded_j)\n",
    "\n",
    "    # predict using validation set\n",
    "    K_val = kernel_expanded_j(X_val, X_prime, sigma)\n",
    "    Y_pred = K_val @ alpha\n",
    "\n",
    "    mse = jnp.mean((Y_val - Y_pred) ** 2)\n",
    "    return mse\n",
    "\n",
    "# create a function that calculates the gradient of the loss function using jax.grad\n",
    "grad_loss = jax.grad(loss)\n",
    "\n",
    "initial_lamb = 1E-4\n",
    "std_force = max_force / (3**0.5)  # standard deviation for force\n",
    "x_sigma = get_std(X)\n",
    "# initial_sigma = jnp.array([6, 6, 0.5, 0.5, 6])\n",
    "std_sine, std_cos = (0.125)**0.5, (0.125)**0.5  # standard deviation for sine and cosine\n",
    "initial_sigma = jnp.array([x_sigma[0], x_sigma[1], std_sine, std_cos, x_sigma[-1], std_force])\n",
    "initial_hyperparameters = jnp.array([initial_lamb] + initial_sigma.tolist())\n",
    "\n",
    "losses = [loss(initial_hyperparameters)]\n",
    "\n",
    "def callback(intermediate_result):\n",
    "    print(intermediate_result)\n",
    "    losses.append(intermediate_result.fun)\n",
    "\n",
    "\n",
    "\n",
    "bounds = [(1E-6, 1E-1)] + [(0, 30)] + [(0, 40)] + [(0, 1)] * 2 +[(0, 10)] + [(0, max_force*3)]  # bounds for lamb and sigma\n",
    "res = scipy.optimize.minimize(loss, x0=initial_hyperparameters, method='L-BFGS-B', jac=grad_loss, bounds=bounds, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f56bcf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, M, lamb = 4096, 1024, res.x[0]\n",
    "# N, M, lamb = 4096, 1024, 4.543e-03 # mine\n",
    "# N, M, lamb = 4096, 1024, 4.918e-04 # andrew\n",
    "\n",
    "# generate training data\n",
    "X, Y = generate_data_random_force_real_noise(num_steps=N, max_force=max_force, std=state_std)\n",
    "\n",
    "# Get the standard deviation of X\n",
    "sigma = res.x[1:]\n",
    "# sigma = np.array([1.000e+01,  1.000e+01,  9.916e-01,  6.063e-01, 7.005e+00,  2.000e+01]) # mine\n",
    "# sigma = np.array([15.41,  1.413e+01,  5.24,  0.97, 7.356,  13.52])    # andrew\n",
    "\n",
    "# train model\n",
    "alpha, X_prime, K = train_nonlinear_models(X, Y, M=M, lamb=lamb, sigma=sigma, kernel_fn=kernel_expanded)\n",
    "\n",
    "# predict using training set\n",
    "Y_pred = K @ alpha\n",
    "\n",
    "# plot_fit(X, Y, Y_pred, graph_title=\"Fit of the model\")\n",
    "plot_fit(Y, Y_pred, graph_title=\"Change in state\")\n",
    "\n",
    "\n",
    "# Example initial states for testing\n",
    "initial_states = [[0, -2, np.pi, 4, 1], [0, 0, np.pi, 5, 2], [0, 0, np.pi, 0, 10], [0, 0, 0.1, 0, 8]]\n",
    "# initial_states = [[0, 0, np.pi, 0, 15]]\n",
    "for initial_state in initial_states:\n",
    "    forecast_nonlinear_force(initial_state, num_steps=100, alpha=alpha, sigma=sigma, X_prime=X_prime, kernel_fn=kernel_expanded)\n",
    "\n",
    "non_linear_model_sin_force_real_noise_up = {\n",
    "    'lambda': res.x[0],\n",
    "    'sigma': res.x[1:],\n",
    "    'alpha': alpha,\n",
    "    'X_prime': X_prime,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fc8e220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 12.354158850450276\n",
      "Iteration: 1\n",
      "P: [1.07440303 0.79800523 1.79655112 3.20851321]\n",
      "Loss: 8.614962999129785\n",
      "\n",
      "Iteration: 2\n",
      "P: [1.1547514  0.85537847 2.31864157 4.45219549]\n",
      "Loss: 2.7777045515720546\n",
      "\n",
      "Iteration: 3\n",
      "P: [0.97908701 0.69029972 2.71525568 5.43646981]\n",
      "Loss: 1.1050906297925367\n",
      "\n",
      "Iteration: 4\n",
      "P: [0.83956772 0.70117863 2.84692541 5.53035347]\n",
      "Loss: 1.0252333115165515\n",
      "\n",
      "Iteration: 5\n",
      "P: [0.33847503 0.93751426 3.21031867 5.26757319]\n",
      "Loss: 0.5464674745828514\n",
      "\n",
      "Iteration: 6\n",
      "P: [-0.06012413  1.21428465  3.58957305  5.19473381]\n",
      "Loss: 0.34339958033346907\n",
      "\n",
      "Iteration: 7\n",
      "P: [-0.36594516  1.46867947  3.94353592  5.18817661]\n",
      "Loss: 0.2417484135669833\n",
      "\n",
      "Iteration: 8\n",
      "P: [-0.77380646  1.81967427  4.44294879  5.18923876]\n",
      "Loss: 0.1620356526134641\n",
      "\n",
      "Iteration: 9\n",
      "P: [-1.18237754  2.18622803  4.99507504  5.20041049]\n",
      "Loss: 0.11827932215163517\n",
      "\n",
      "Iteration: 10\n",
      "P: [-1.4547898   2.46234241  5.53391622  5.23076341]\n",
      "Loss: 0.098334129860981\n",
      "\n",
      "Iteration: 11\n",
      "P: [-1.5994569   2.66223084  6.17117723  5.28207848]\n",
      "Loss: 0.08394179882290531\n",
      "\n",
      "Iteration: 12\n",
      "P: [-1.63658952  2.87632939  7.18097834  5.44102982]\n",
      "Loss: 0.06516936713599542\n",
      "\n",
      "Iteration: 13\n",
      "P: [-1.51127092  3.08062116  8.51146171  5.75134042]\n",
      "Loss: 0.05029167096992693\n",
      "\n",
      "Iteration: 14\n",
      "P: [-1.70286766  3.48809587 10.91200353  5.8068916 ]\n",
      "Loss: 0.035044422657653396\n",
      "\n",
      "Iteration: 15\n",
      "P: [-1.711456    3.88701845 13.48109265  6.00876174]\n",
      "Loss: 0.031115286600501113\n",
      "\n",
      "Iteration: 16\n",
      "P: [-1.51722219  3.78586742 13.05728962  5.88008196]\n",
      "Loss: 0.025400798332547048\n",
      "\n",
      "Iteration: 17\n",
      "P: [-1.30951862  3.86859571 13.87256314  5.82972646]\n",
      "Loss: 0.02126429835068\n",
      "\n",
      "Iteration: 18\n",
      "P: [-0.69252871  4.17618458 16.79940254  5.68620376]\n",
      "Loss: 0.013829290775933645\n",
      "\n",
      "Iteration: 19\n",
      "P: [-0.22039932  4.32038779 18.51513823  5.59173155]\n",
      "Loss: 0.011539284553535922\n",
      "\n",
      "Iteration: 20\n",
      "P: [ 0.42465989  4.41684653 20.594548    5.44442917]\n",
      "Loss: 0.010002995346216847\n",
      "\n",
      "Iteration: 21\n",
      "P: [ 0.96132567  4.38858886 22.33780421  5.27370773]\n",
      "Loss: 0.00941954056784311\n",
      "\n",
      "Iteration: 22\n",
      "P: [ 1.3912472   4.23675859 23.14030359  5.14058879]\n",
      "Loss: 0.009271761041714233\n",
      "\n",
      "Iteration: 23\n",
      "P: [ 1.51216329  4.23159833 23.53082919  5.10027761]\n",
      "Loss: 0.009260104418896131\n",
      "\n",
      "Iteration: 24\n",
      "P: [ 1.6625575   4.16696054 23.16620238  5.07398622]\n",
      "Loss: 0.009245343372690118\n",
      "\n",
      "Iteration: 25\n",
      "P: [ 1.81127543  4.31882223 23.19868444  5.08523966]\n",
      "Loss: 0.009226188057902207\n",
      "\n",
      "Iteration: 26\n",
      "P: [ 1.82992419  4.39378806 23.04073368  5.09804405]\n",
      "Loss: 0.00921915947214147\n",
      "\n",
      "Iteration: 27\n",
      "P: [ 1.53749988  4.16602335 22.58038983  4.93884655]\n",
      "Loss: 0.009181345770041038\n",
      "\n",
      "Iteration: 28\n",
      "P: [ 1.36143647  3.83693784 22.18094637  4.68680964]\n",
      "Loss: 0.009155197674076243\n",
      "\n",
      "Iteration: 29\n",
      "P: [ 1.37453889  3.70163669 22.02264502  4.55383486]\n",
      "Loss: 0.009149423338416174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train policy\n",
    "initial_state = jnp.array([0, 0, 0.1, 0])\n",
    "sigma = jnp.array([10, 10, 10, 10])\n",
    "# sigma = jnp.array([5.8, 5.8, 1.5, 8.5])  # Example sigma values\n",
    "num_steps = 25\n",
    "target = jnp.array([0, 0, 0, 0])\n",
    "max_force = 7.5\n",
    "\n",
    "model_x_prime = jnp.array(non_linear_model_sin_force_real_noise_up['X_prime'])\n",
    "model_sigma = jnp.array(non_linear_model_sin_force_real_noise_up['sigma'])\n",
    "model_alpha = jnp.array(non_linear_model_sin_force_real_noise_up['alpha'])\n",
    "\n",
    "@jax.jit\n",
    "def kernel_expanded_jax(X, X_prime, sigma):\n",
    "    # create new X where 2 additional dimensions are added, replacing the angle with sin and cos\n",
    "    # angle dimension is removed\n",
    "    X_new = jnp.hstack((X[:,0:2], jnp.sin(X[:, 2:3]), jnp.cos(X[:, 2:3]), X[:, 3:]))  # (N, D+1)\n",
    "    X_prime_new = jnp.hstack((X_prime[:,0:2], jnp.sin(X_prime[:, 2:3]), jnp.cos(X_prime[:, 2:3]), X_prime[:, 3:]))  # (M, D+1)\n",
    "\n",
    "    X_e = jnp.expand_dims(X_new, axis=1)  # (N, 1, D+1)\n",
    "    X_prime_e = jnp.expand_dims(X_prime_new, axis=0)  # (1, M, D+1)\n",
    "\n",
    "    diff = X_e - X_prime_e  # (N, M, D+1)\n",
    "    scaled_squared_diff = (diff ** 2)/(2 * sigma ** 2) # (N, M, D+1)\n",
    "\n",
    "    K = jnp.exp(-jnp.sum(scaled_squared_diff, axis=-1))  # (N, M)\n",
    "    return K\n",
    "\n",
    "@jax.jit\n",
    "def loss_policy_jax(state, target, sigma):\n",
    "    delta = (state - target) / sigma\n",
    "    exponent = 0.5 * jnp.dot(delta, delta)\n",
    "    return 1 - jnp.exp(-exponent)\n",
    "\n",
    "@jax.jit\n",
    "def loss_rollout_linear_jax(P):\n",
    "    def scan_step_jax(state, _):\n",
    "        force = P @ state\n",
    "        force = max_force * jnp.tanh(force/max_force)\n",
    "\n",
    "        # add force as the last element to the state\n",
    "        current_state = jnp.concatenate([state, jnp.array([force])])\n",
    "        K = kernel_expanded_jax(jnp.expand_dims(current_state, axis=0), model_x_prime, model_sigma)\n",
    "        Y_pred = K @ model_alpha\n",
    "        next_state = jnp.ravel(current_state[:-1] + Y_pred)\n",
    "\n",
    "        loss = loss_policy_jax(next_state, target, sigma)\n",
    "        return next_state, loss\n",
    "\n",
    "    init_loss = loss_policy_jax(initial_state, target, sigma)\n",
    "    _, losses = jax.lax.scan(scan_step_jax, initial_state, None, length=num_steps)\n",
    "    return init_loss + losses.sum()\n",
    "\n",
    "initial_p = jnp.array([1, 1, 1, 1])  # initial policy parameters for upright initial starting position\n",
    "\n",
    "grad_loss_linear_jax = jax.grad(loss_rollout_linear_jax)\n",
    "\n",
    "losses = [loss_rollout_linear_jax(initial_p)]\n",
    "print(\"Initial loss:\", losses[0])\n",
    "\n",
    "def callback(intermediate_result):\n",
    "    print(\"Iteration:\", len(losses))\n",
    "    print(\"P:\", intermediate_result.x)\n",
    "    print(\"Loss:\", intermediate_result.fun)\n",
    "    print()\n",
    "    losses.append(intermediate_result.fun)\n",
    "\n",
    "res = scipy.optimize.minimize(loss_rollout_linear_jax, x0=initial_p, method='L-BFGS-B', jac=grad_loss_linear_jax, callback=callback, bounds=[(-30, 30)] * len(initial_p))\n",
    "\n",
    "def rollout_linear_force(initial_state, num_steps, P, max_force):\n",
    "    X_forecast = [initial_state.copy()]\n",
    "    \n",
    "    state = initial_state.copy()\n",
    "    for step in range(num_steps):\n",
    "        force = P @ state\n",
    "        force = max_force * np.tanh(force/max_force)\n",
    "        # add force as the last element to the state\n",
    "        current_state = jnp.concatenate([state, jnp.array([force])])\n",
    "        K = kernel_expanded_jax(jnp.expand_dims(current_state, axis=0), model_x_prime, model_sigma)\n",
    "\n",
    "        Y_pred = K @ model_alpha\n",
    "        state = jnp.ravel(current_state[:-1] + Y_pred)\n",
    "\n",
    "        remapped_state = state.copy()\n",
    "        # remap jax angle to be between -pi and pi PURELY FOR PLOTTING\n",
    "        remapped_state = np.array([remapped_state[0], remapped_state[1], remap_angle2(remapped_state[2]), remapped_state[3]])\n",
    "        X_forecast.append(remapped_state)\n",
    "\n",
    "    return np.array(X_forecast)\n",
    "\n",
    "P = res.x  # optimised policy matrix\n",
    "X = rollout_linear_force(initial_state=initial_state, num_steps=50, P=P, max_force=max_force)\n",
    "plot_policy(X, target, f\"Rollout Policy, initial_state: {initial_state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c8ec41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 43.95346032604399\n",
      "Iteration: 1\n",
      "P: [4.99972937 4.999206   4.96238035 5.0001769 ]\n",
      "Loss: 43.952028009560024\n",
      "\n",
      "Iteration: 2\n",
      "P: [ 4.90463407  4.72006152 -8.1630888   5.0619956 ]\n",
      "Loss: 41.43296279447876\n",
      "\n",
      "Iteration: 3\n",
      "P: [3.567857   0.54992484 1.04865043 7.37747562]\n",
      "Loss: 33.56850735440944\n",
      "\n",
      "Iteration: 4\n",
      "P: [ 2.63291922 -0.30095697  1.85500845  8.0075621 ]\n",
      "Loss: 30.52377354444375\n",
      "\n",
      "Iteration: 5\n",
      "P: [ 2.6431847  -0.29744175  1.86177793  8.00350976]\n",
      "Loss: 30.471866781230048\n",
      "\n",
      "Iteration: 6\n",
      "P: [ 2.7262608  -0.30470891  1.9397169   7.97358329]\n",
      "Loss: 30.28847278819443\n",
      "\n",
      "Iteration: 7\n",
      "P: [ 2.74004231 -0.31343863  1.95753527  7.9708824 ]\n",
      "Loss: 30.256475366797225\n",
      "\n",
      "Iteration: 8\n",
      "P: [ 2.73960226 -0.35187267  1.9786013   7.98263871]\n",
      "Loss: 30.151880809838463\n",
      "\n",
      "Iteration: 9\n",
      "P: [ 2.76696312 -0.39363776  2.02600809  7.98306969]\n",
      "Loss: 30.040174302883518\n",
      "\n",
      "Iteration: 10\n",
      "P: [ 2.78061938 -0.41820609  2.05167162  7.98435245]\n",
      "Loss: 29.99886264696524\n",
      "\n",
      "Iteration: 11\n",
      "P: [ 2.78719646 -0.43654283  2.06688781  7.98705505]\n",
      "Loss: 29.975595556707525\n",
      "\n",
      "Iteration: 12\n",
      "P: [ 2.79975974 -0.49557632  2.10558359  7.9999217 ]\n",
      "Loss: 29.915928143714446\n",
      "\n",
      "Iteration: 13\n",
      "P: [ 2.7973694  -0.53236536  2.11686647  8.01281001]\n",
      "Loss: 29.796115592398003\n",
      "\n",
      "Iteration: 14\n",
      "P: [ 2.79871363 -0.55478309  2.12721696  8.01931583]\n",
      "Loss: 29.76197488090937\n",
      "\n",
      "Iteration: 15\n",
      "P: [ 2.79958473 -0.57284676  2.13447593  8.02468431]\n",
      "Loss: 29.735251453769795\n",
      "\n",
      "Iteration: 16\n",
      "P: [ 2.80128259 -0.59764949  2.14237997  8.03194858]\n",
      "Loss: 29.700217697380836\n",
      "\n",
      "Iteration: 17\n",
      "P: [ 2.80663219 -0.62871332  2.14756719  8.03998499]\n",
      "Loss: 29.661144355132013\n",
      "\n",
      "Iteration: 18\n",
      "P: [ 2.81498957 -0.66930786  2.15059641  8.05001497]\n",
      "Loss: 29.612239310015898\n",
      "\n",
      "Iteration: 19\n",
      "P: [ 2.82554428 -0.70453911  2.14906029  8.05714425]\n",
      "Loss: 29.573927125996494\n",
      "\n",
      "Iteration: 20\n",
      "P: [ 2.86760722 -0.83486913  2.13415813  8.08225661]\n",
      "Loss: 29.435674943629035\n",
      "\n",
      "Iteration: 21\n",
      "P: [ 3.06861027 -1.42313602  2.03177856  8.19047833]\n",
      "Loss: 29.3653018101651\n",
      "\n",
      "Iteration: 22\n",
      "P: [ 2.96947378 -1.09200397  2.04889804  8.12405979]\n",
      "Loss: 28.281027275526288\n",
      "\n",
      "Iteration: 23\n",
      "P: [ 3.21163588 -1.69618035  1.84574067  8.22117211]\n",
      "Loss: 26.76185621484238\n",
      "\n",
      "Iteration: 24\n",
      "P: [ 3.21666123 -1.61698514  1.85676114  8.19816723]\n",
      "Loss: 26.510816461214617\n",
      "\n",
      "Iteration: 25\n",
      "P: [ 3.26765542 -1.69957208  1.81960021  8.19938435]\n",
      "Loss: 26.44678277097669\n",
      "\n",
      "Iteration: 26\n",
      "P: [ 3.92355268 -2.58689871  1.37213994  8.17269543]\n",
      "Loss: 24.37025497218808\n",
      "\n",
      "Iteration: 27\n",
      "P: [ 3.93094071 -2.59714481  1.36707202  8.17252937]\n",
      "Loss: 24.299341896202353\n",
      "\n",
      "Iteration: 28\n",
      "P: [ 3.93486134 -2.59721222  1.36530341  8.17097614]\n",
      "Loss: 24.286645503255315\n",
      "\n",
      "Iteration: 29\n",
      "P: [ 3.93707355 -2.59608479  1.3645394   8.16966516]\n",
      "Loss: 24.279459903974068\n",
      "\n",
      "Iteration: 30\n",
      "P: [ 3.93758207 -2.59200171  1.3651991   8.16779951]\n",
      "Loss: 24.266007366423636\n",
      "\n",
      "Iteration: 31\n",
      "P: [ 3.93895492 -2.5928191   1.36459774  8.16723913]\n",
      "Loss: 24.262538093040124\n",
      "\n",
      "Iteration: 32\n",
      "P: [ 3.94740808 -2.59861109  1.36104836  8.16356953]\n",
      "Loss: 24.24806286057955\n",
      "\n",
      "Iteration: 33\n",
      "P: [ 3.98385024 -2.63550772  1.34549087  8.14857892]\n",
      "Loss: 24.154175779516198\n",
      "\n",
      "Iteration: 34\n",
      "P: [ 4.0296549  -2.68548082  1.32599693  8.12981518]\n",
      "Loss: 24.020102281383675\n",
      "\n",
      "Iteration: 35\n",
      "P: [ 4.08551905 -2.7500276   1.30239124  8.1069733 ]\n",
      "Loss: 23.798268317978387\n",
      "\n",
      "Iteration: 36\n",
      "P: [ 4.15553799 -2.84092397  1.2730624   8.08012867]\n",
      "Loss: 23.412481524225782\n",
      "\n",
      "Iteration: 37\n",
      "P: [ 4.18119871 -2.87067726  1.26247202  8.06961114]\n",
      "Loss: 23.33075747994313\n",
      "\n",
      "Iteration: 38\n",
      "P: [ 4.21063779 -2.90574232  1.25052589  8.0575669 ]\n",
      "Loss: 23.25228600366473\n",
      "\n",
      "Iteration: 39\n",
      "P: [ 4.27532535 -2.97751942  1.22580096  8.02920692]\n",
      "Loss: 23.082566226274885\n",
      "\n",
      "Iteration: 40\n",
      "P: [ 4.28059191 -2.98511855  1.22460921  8.02804066]\n",
      "Loss: 22.927565596993684\n",
      "\n",
      "Iteration: 41\n",
      "P: [ 4.31600342 -3.03502154  1.21075252  8.01604722]\n",
      "Loss: 22.737721784015505\n",
      "\n",
      "Iteration: 42\n",
      "P: [ 4.76217944 -3.59022934  1.04858738  7.86377837]\n",
      "Loss: 22.387378886840583\n",
      "\n",
      "Iteration: 43\n",
      "P: [ 5.05405123 -3.91716648  0.94904525  7.76576031]\n",
      "Loss: 20.916209110763408\n",
      "\n",
      "Iteration: 44\n",
      "P: [ 5.05313599 -3.91598762  0.94939466  7.76610372]\n",
      "Loss: 20.915300927276196\n",
      "\n",
      "Iteration: 45\n",
      "P: [ 5.07856098 -3.93776611  0.94239277  7.75893725]\n",
      "Loss: 20.895048829008257\n",
      "\n",
      "Iteration: 46\n",
      "P: [ 6.14817772 -4.84926243  0.65123343  7.46393371]\n",
      "Loss: 19.75533628092175\n",
      "\n",
      "Iteration: 47\n",
      "P: [ 6.13193671 -4.83554274  0.6557015   7.46862554]\n",
      "Loss: 19.735760406785325\n",
      "\n",
      "Iteration: 48\n",
      "P: [ 6.12517503 -4.82963311  0.657566    7.47052491]\n",
      "Loss: 19.73175018917059\n",
      "\n",
      "Iteration: 49\n",
      "P: [ 6.10720351 -4.81436182  0.66413121  7.48121396]\n",
      "Loss: 19.631670356958754\n",
      "\n",
      "Iteration: 50\n",
      "P: [ 6.09839795 -4.80670647  0.66709152  7.48549477]\n",
      "Loss: 19.61063150041434\n",
      "\n",
      "Iteration: 51\n",
      "P: [ 6.090378   -4.79950102  0.67116226  7.49393367]\n",
      "Loss: 19.576482093020143\n",
      "\n",
      "Iteration: 52\n",
      "P: [ 6.08993311 -4.79994561  0.67158201  7.49460763]\n",
      "Loss: 19.56930761377754\n",
      "\n",
      "Iteration: 53\n",
      "P: [ 6.01870329 -4.79088102  0.7106147   7.55217924]\n",
      "Loss: 19.149580576040528\n",
      "\n",
      "Iteration: 54\n",
      "P: [ 6.02025769 -4.79118637  0.70979667  7.55097019]\n",
      "Loss: 18.75323448881003\n",
      "\n",
      "Iteration: 55\n",
      "P: [ 6.02516967 -4.79805041  0.70861332  7.54847754]\n",
      "Loss: 18.708637146924243\n",
      "\n",
      "Iteration: 56\n",
      "P: [ 6.0365217  -4.81292676  0.70566111  7.54256088]\n",
      "Loss: 18.661700205396844\n",
      "\n",
      "Iteration: 57\n",
      "P: [ 6.05355716 -4.83261134  0.70205614  7.53736883]\n",
      "Loss: 18.63015825122747\n",
      "\n",
      "Iteration: 58\n",
      "P: [ 6.08070589 -4.86116431  0.69711486  7.53280446]\n",
      "Loss: 18.568255793427884\n",
      "\n",
      "Iteration: 59\n",
      "P: [ 6.43445343 -5.21674828  0.63545926  7.48739841]\n",
      "Loss: 18.096770209936544\n",
      "\n",
      "Iteration: 60\n",
      "P: [ 6.45753097 -5.2377009   0.63196798  7.48697116]\n",
      "Loss: 17.806592311008036\n",
      "\n",
      "Iteration: 61\n",
      "P: [ 6.59476626 -5.37038348  0.60931778  7.47539382]\n",
      "Loss: 17.526613761577973\n",
      "\n",
      "Iteration: 62\n",
      "P: [ 6.62413213 -5.39836409  0.60456194  7.47336849]\n",
      "Loss: 17.49822462702752\n",
      "\n",
      "Iteration: 63\n",
      "P: [ 6.61853167 -5.3928195   0.60550714  7.47395716]\n",
      "Loss: 17.48984282555354\n",
      "\n",
      "Iteration: 64\n",
      "P: [ 6.62872101 -5.40236532  0.60384831  7.473276  ]\n",
      "Loss: 17.4854906050381\n",
      "\n",
      "Iteration: 65\n",
      "P: [ 6.63894407 -5.41169472  0.60218154  7.4726539 ]\n",
      "Loss: 17.482279327948564\n",
      "\n",
      "Iteration: 66\n",
      "P: [ 6.6489063  -5.42058405  0.60058882  7.47238968]\n",
      "Loss: 17.477084971768452\n",
      "\n",
      "Iteration: 67\n",
      "P: [ 6.67190463 -5.4409844   0.59692156  7.47199346]\n",
      "Loss: 17.468202835851102\n",
      "\n",
      "Iteration: 68\n",
      "P: [ 6.69067325 -5.45769955  0.59392202  7.47167484]\n",
      "Loss: 17.461980219530428\n",
      "\n",
      "Iteration: 69\n",
      "P: [ 6.74944187 -5.50945827  0.58460111  7.4716631 ]\n",
      "Loss: 17.41465379155457\n",
      "\n",
      "Iteration: 70\n",
      "P: [ 6.74001233 -5.50059718  0.58617744  7.47276845]\n",
      "Loss: 17.411508545798956\n",
      "\n",
      "Iteration: 71\n",
      "P: [ 6.73887748 -5.49958145  0.58636101  7.4728227 ]\n",
      "Loss: 17.411310746022707\n",
      "\n",
      "Iteration: 72\n",
      "P: [ 6.74874046 -5.50794237  0.58489787  7.474371  ]\n",
      "Loss: 17.397598279290364\n",
      "\n",
      "Iteration: 73\n",
      "P: [ 6.75445612 -5.51280973  0.58405269  7.47531572]\n",
      "Loss: 17.391566309197874\n",
      "\n",
      "Iteration: 74\n",
      "P: [ 6.76398945 -5.52070799  0.58272641  7.47813208]\n",
      "Loss: 17.379145901778998\n",
      "\n",
      "Iteration: 75\n",
      "P: [ 6.76120994 -5.51784056  0.58330299  7.48011771]\n",
      "Loss: 17.36851568974705\n",
      "\n",
      "Iteration: 76\n",
      "P: [ 6.77440875 -5.52966564  0.5812791   7.4812734 ]\n",
      "Loss: 17.354596498214438\n",
      "\n",
      "Iteration: 77\n",
      "P: [ 6.78411556 -5.53857891  0.57974809  7.48149982]\n",
      "Loss: 17.348444556881805\n",
      "\n",
      "Iteration: 78\n",
      "P: [ 6.79436056 -5.5482827   0.57806065  7.48068663]\n",
      "Loss: 17.3412864590922\n",
      "\n",
      "Iteration: 79\n",
      "P: [ 6.80127546 -5.55452159  0.57702682  7.48168147]\n",
      "Loss: 17.335922150294454\n",
      "\n",
      "Iteration: 80\n",
      "P: [ 6.80872575 -5.56116553  0.57597955  7.48371715]\n",
      "Loss: 17.328597432598407\n",
      "\n",
      "Iteration: 81\n",
      "P: [ 6.80945265 -5.56172719  0.57599742  7.48564763]\n",
      "Loss: 17.313093279989662\n",
      "\n",
      "Iteration: 82\n",
      "P: [ 6.81243418 -5.56436897  0.57563099  7.48721778]\n",
      "Loss: 17.307284225931202\n",
      "\n",
      "Iteration: 83\n",
      "P: [ 6.81714978 -5.56856525  0.57514593  7.49103032]\n",
      "Loss: 17.296305798243303\n",
      "\n",
      "Iteration: 84\n",
      "P: [ 6.81410677 -5.56579775  0.57577957  7.49304121]\n",
      "Loss: 17.292237936861643\n",
      "\n",
      "Iteration: 85\n",
      "P: [ 6.82707029 -5.57806239  0.57388209  7.49530467]\n",
      "Loss: 17.277322299425418\n",
      "\n",
      "Iteration: 86\n",
      "P: [ 6.83790027 -5.58857124  0.57213983  7.49485294]\n",
      "Loss: 17.26845629036934\n",
      "\n",
      "Iteration: 87\n",
      "P: [ 6.84197854 -5.59250965  0.57156978  7.49588293]\n",
      "Loss: 17.26610602487257\n",
      "\n",
      "Iteration: 88\n",
      "P: [ 6.84845104 -5.59895089  0.57071453  7.49806883]\n",
      "Loss: 17.258148312046433\n",
      "\n",
      "Iteration: 89\n",
      "P: [ 6.84223909 -5.59564699  0.57243726  7.50400309]\n",
      "Loss: 17.243647717813886\n",
      "\n",
      "Iteration: 90\n",
      "P: [ 6.83354178 -5.58974728  0.57431893  7.50709037]\n",
      "Loss: 17.233869121182632\n",
      "\n",
      "Iteration: 91\n",
      "P: [ 6.83223293 -5.59019246  0.57493722  7.51010887]\n",
      "Loss: 17.226007474504307\n",
      "\n",
      "Iteration: 92\n",
      "P: [ 6.83201421 -5.59081688  0.57516955  7.51156985]\n",
      "Loss: 17.22360471696837\n",
      "\n",
      "Iteration: 93\n",
      "P: [ 6.83609908 -5.59573244  0.57475261  7.51343277]\n",
      "Loss: 17.21940874353636\n",
      "\n",
      "Iteration: 94\n",
      "P: [ 6.84102674 -5.60074897  0.57404536  7.51432114]\n",
      "Loss: 17.215075423592562\n",
      "\n",
      "Iteration: 95\n",
      "P: [ 6.84132243 -5.60187978  0.57423429  7.5165724 ]\n",
      "Loss: 17.210528109616742\n",
      "\n",
      "Iteration: 96\n",
      "P: [ 6.83857531 -5.60104563  0.57521895  7.52231063]\n",
      "Loss: 17.202113573512836\n",
      "\n",
      "Iteration: 97\n",
      "P: [ 6.82926449 -5.59238477  0.57685802  7.52464486]\n",
      "Loss: 17.197865417927396\n",
      "\n",
      "Iteration: 98\n",
      "P: [ 6.83566341 -5.59875739  0.57588594  7.52512049]\n",
      "Loss: 17.189260275917537\n",
      "\n",
      "Iteration: 99\n",
      "P: [ 6.83775726 -5.60113555  0.5756572   7.52630187]\n",
      "Loss: 17.18688730597018\n",
      "\n",
      "Iteration: 100\n",
      "P: [ 6.84266918 -5.60630122  0.57498631  7.52763022]\n",
      "Loss: 17.182894540715342\n",
      "\n",
      "Iteration: 101\n",
      "P: [ 6.84966404 -5.61333575  0.57392858  7.52844938]\n",
      "Loss: 17.178619356239302\n",
      "\n",
      "Iteration: 102\n",
      "P: [ 6.85041314 -5.61461974  0.57396748  7.53028016]\n",
      "Loss: 17.175747901187467\n",
      "\n",
      "Iteration: 103\n",
      "P: [ 6.84905283 -5.61453115  0.57452451  7.5342338 ]\n",
      "Loss: 17.1701620310173\n",
      "\n",
      "Iteration: 104\n",
      "P: [ 6.84172156 -5.60827436  0.57592     7.53685737]\n",
      "Loss: 17.163332457347458\n",
      "\n",
      "Iteration: 105\n",
      "P: [ 6.84469472 -5.61202675  0.5756702   7.53956919]\n",
      "Loss: 17.15856475185562\n",
      "\n",
      "Iteration: 106\n",
      "P: [ 6.84912538 -5.61691823  0.57510178  7.5413355 ]\n",
      "Loss: 17.15421941448572\n",
      "\n",
      "Iteration: 107\n",
      "P: [ 6.85856499 -5.62638255  0.57362649  7.54196591]\n",
      "Loss: 17.151936781205297\n",
      "\n",
      "Iteration: 108\n",
      "P: [ 6.85603259 -5.62531288  0.57438435  7.54618434]\n",
      "Loss: 17.144975764508995\n",
      "\n",
      "Iteration: 109\n",
      "P: [ 6.85160522 -5.6211339   0.575123    7.54650916]\n",
      "Loss: 17.141581343042308\n",
      "\n",
      "Iteration: 110\n",
      "P: [ 6.84945286 -5.62043665  0.57579817  7.55053702]\n",
      "Loss: 17.13681539065367\n",
      "\n",
      "Iteration: 111\n",
      "P: [ 6.85025589 -5.62274133  0.57601529  7.55482649]\n",
      "Loss: 17.134631993211094\n",
      "\n",
      "Iteration: 112\n",
      "P: [ 6.85057428 -5.62343301  0.57603407  7.55575043]\n",
      "Loss: 17.1275929974635\n",
      "\n",
      "Iteration: 113\n",
      "P: [ 6.85341816 -5.62793155  0.57594303  7.56038624]\n",
      "Loss: 17.121148148885283\n",
      "\n",
      "Iteration: 114\n",
      "P: [ 6.85686768 -5.63252605  0.57563575  7.56357226]\n",
      "Loss: 17.1169836887577\n",
      "\n",
      "Iteration: 115\n",
      "P: [ 6.85934273 -5.63562677  0.57535696  7.56513801]\n",
      "Loss: 17.11395139776733\n",
      "\n",
      "Iteration: 116\n",
      "P: [ 6.85833916 -5.63585797  0.57576552  7.56825833]\n",
      "Loss: 17.10940443705132\n",
      "\n",
      "Iteration: 117\n",
      "P: [ 6.85670148 -5.63616505  0.57641394  7.5731246 ]\n",
      "Loss: 17.106316616850627\n",
      "\n",
      "Iteration: 118\n",
      "P: [ 6.85147313 -5.63135434  0.57731421  7.57381737]\n",
      "Loss: 17.10230122119565\n",
      "\n",
      "Iteration: 119\n",
      "P: [ 6.84878466 -5.6301613   0.57802799  7.57736518]\n",
      "Loss: 17.0996727204737\n",
      "\n",
      "Iteration: 120\n",
      "P: [ 6.84725149 -5.63076696  0.57867654  7.58245796]\n",
      "Loss: 17.09768204072142\n",
      "\n",
      "Iteration: 121\n",
      "P: [ 6.84739748 -5.63132145  0.57872031  7.58331729]\n",
      "Loss: 17.09291956242458\n",
      "\n",
      "Iteration: 122\n",
      "P: [ 6.84776715 -5.63450781  0.57917122  7.58981817]\n",
      "Loss: 17.08593895394907\n",
      "\n",
      "Iteration: 123\n",
      "P: [ 6.84846453 -5.63760237  0.5794848   7.59525935]\n",
      "Loss: 17.08124165572483\n",
      "\n",
      "Iteration: 124\n",
      "P: [ 6.84686872 -5.63815958  0.58013526  7.6012791 ]\n",
      "Loss: 17.075217198120125\n",
      "\n",
      "Iteration: 125\n",
      "P: [ 6.84826189 -5.64150456  0.58026417  7.60738746]\n",
      "Loss: 17.070142132417118\n",
      "\n",
      "Iteration: 126\n",
      "P: [ 6.84097525 -5.6512835   0.58453175  7.65494955]\n",
      "Loss: 17.04490701310068\n",
      "\n",
      "Iteration: 127\n",
      "P: [ 6.83861848 -5.65034655  0.58516587  7.65883976]\n",
      "Loss: 17.043566567305927\n",
      "\n",
      "Iteration: 128\n",
      "P: [ 6.82999489 -5.64282348  0.58674449  7.66164008]\n",
      "Loss: 17.036791235725072\n",
      "\n",
      "Iteration: 129\n",
      "P: [ 6.82925676 -5.64156892  0.58677019  7.66012238]\n",
      "Loss: 17.036334720960642\n",
      "\n",
      "Iteration: 130\n",
      "P: [ 6.82843932 -5.64141017  0.58702089  7.66183933]\n",
      "Loss: 17.03552421200983\n",
      "\n",
      "Iteration: 131\n",
      "P: [ 6.82697499 -5.6408735   0.58742533  7.66414353]\n",
      "Loss: 17.034830157093868\n",
      "\n",
      "Iteration: 132\n",
      "P: [ 6.82495942 -5.64025455  0.58800467  7.66745631]\n",
      "Loss: 17.033814959781196\n",
      "\n",
      "Iteration: 133\n",
      "P: [ 6.82290643 -5.63957926  0.58858619  7.6704377 ]\n",
      "Loss: 17.032025458612875\n",
      "\n",
      "Iteration: 134\n",
      "P: [ 6.81625801 -5.63592405  0.5901896   7.67604896]\n",
      "Loss: 17.027994246464008\n",
      "\n",
      "Iteration: 135\n",
      "P: [ 6.81180567 -5.63327657  0.59122832  7.67964365]\n",
      "Loss: 17.02668438221363\n",
      "\n",
      "Iteration: 136\n",
      "P: [ 6.80353715 -5.6280259   0.59309248  7.68507769]\n",
      "Loss: 17.02410727071842\n",
      "\n",
      "Iteration: 137\n",
      "P: [ 6.78924452 -5.61845758  0.5962171   7.69260767]\n",
      "Loss: 17.01882225652411\n",
      "\n",
      "Iteration: 138\n",
      "P: [ 6.77433015 -5.60833137  0.59944553  7.69950374]\n",
      "Loss: 17.013714882664527\n",
      "\n",
      "Iteration: 139\n",
      "P: [ 6.77079113 -5.60596566  0.60021905  7.70129213]\n",
      "Loss: 17.012627593939754\n",
      "\n",
      "Iteration: 140\n",
      "P: [ 6.7658069  -5.60258832  0.60129941  7.7036406 ]\n",
      "Loss: 17.01135062726937\n",
      "\n",
      "Iteration: 141\n",
      "P: [ 6.7575509  -5.59696407  0.60308254  7.70738157]\n",
      "Loss: 17.009896717369006\n",
      "\n",
      "Iteration: 142\n",
      "P: [ 6.75050185 -5.59216282  0.60460248  7.71036148]\n",
      "Loss: 17.00845084767789\n",
      "\n",
      "Iteration: 143\n",
      "P: [ 6.7385655  -5.58410467  0.60717975  7.7149557 ]\n",
      "Loss: 17.004845839522805\n",
      "\n",
      "Iteration: 144\n",
      "P: [ 6.7302328  -5.57822817  0.60893564  7.71764818]\n",
      "Loss: 17.00227507154474\n",
      "\n",
      "Iteration: 145\n",
      "P: [ 6.72424969 -5.57403594  0.61020256  7.71976107]\n",
      "Loss: 17.00136154961827\n",
      "\n",
      "Iteration: 146\n",
      "P: [ 6.71578829 -5.56796109  0.61196706  7.72234107]\n",
      "Loss: 16.99988930842519\n",
      "\n",
      "Iteration: 147\n",
      "P: [ 6.70409095 -5.55923304  0.61434425  7.72504916]\n",
      "Loss: 16.997067483722876\n",
      "\n",
      "Iteration: 148\n",
      "P: [ 6.69485796 -5.55204369  0.61618989  7.72697122]\n",
      "Loss: 16.992739783836445\n",
      "\n",
      "Iteration: 149\n",
      "P: [ 6.69182341 -5.54974297  0.61680429  7.72768539]\n",
      "Loss: 16.99175439917242\n",
      "\n",
      "Iteration: 150\n",
      "P: [ 6.68710095 -5.54613433  0.61775697  7.72876473]\n",
      "Loss: 16.990445145873554\n",
      "\n",
      "Iteration: 151\n",
      "P: [ 6.68162335 -5.54189527  0.6188555   7.72997904]\n",
      "Loss: 16.989453344977182\n",
      "\n",
      "Iteration: 152\n",
      "P: [ 6.67874258 -5.53952629  0.61941715  7.73056953]\n",
      "Loss: 16.988402506026553\n",
      "\n",
      "Iteration: 153\n",
      "P: [ 6.67336406 -5.5346862   0.62043057  7.73188488]\n",
      "Loss: 16.985505873452727\n",
      "\n",
      "Iteration: 154\n",
      "P: [ 6.67017063 -5.53208201  0.62106497  7.73277797]\n",
      "Loss: 16.985289060892697\n",
      "\n",
      "Iteration: 155\n",
      "P: [ 6.66976639 -5.53174355  0.62115537  7.73315404]\n",
      "Loss: 16.98499505424109\n",
      "\n",
      "Iteration: 156\n",
      "P: [ 6.66830271 -5.53071027  0.62149269  7.73427147]\n",
      "Loss: 16.98442297184843\n",
      "\n",
      "Iteration: 157\n",
      "P: [ 6.65917847 -5.52446484  0.62360624  7.74099247]\n",
      "Loss: 16.98217342329492\n",
      "\n",
      "Iteration: 158\n",
      "P: [ 6.66004284 -5.52635408  0.62370699  7.74426508]\n",
      "Loss: 16.97915691579912\n",
      "\n",
      "Iteration: 159\n",
      "P: [ 6.65910646 -5.52657387  0.62412683  7.74760886]\n",
      "Loss: 16.97847926415135\n",
      "\n",
      "Iteration: 160\n",
      "P: [ 6.66014154 -5.52756925  0.62394905  7.74756386]\n",
      "Loss: 16.978110916342583\n",
      "\n",
      "Iteration: 161\n",
      "P: [ 6.65639178 -5.5249736   0.62483608  7.75065695]\n",
      "Loss: 16.976272513696607\n",
      "\n",
      "Iteration: 162\n",
      "P: [ 6.65255519 -5.52198308  0.62556592  7.75029967]\n",
      "Loss: 16.975810939187827\n",
      "\n",
      "Iteration: 163\n",
      "P: [ 6.64812738 -5.51873045  0.6265485   7.75280796]\n",
      "Loss: 16.974339016305652\n",
      "\n",
      "Iteration: 164\n",
      "P: [ 6.63913257 -5.51173559  0.62843269  7.75601105]\n",
      "Loss: 16.97140933077878\n",
      "\n",
      "Iteration: 165\n",
      "P: [ 6.63633575 -5.50965207  0.62911592  7.75889336]\n",
      "Loss: 16.96966577038215\n",
      "\n",
      "Iteration: 166\n",
      "P: [ 6.63180466 -5.50655709  0.63017895  7.76202951]\n",
      "Loss: 16.967252716596686\n",
      "\n",
      "Iteration: 167\n",
      "P: [ 6.63031091 -5.5055099   0.63051783  7.76284474]\n",
      "Loss: 16.966732257330893\n",
      "\n",
      "Iteration: 168\n",
      "P: [ 6.62615861 -5.50254206  0.63139603  7.76369356]\n",
      "Loss: 16.96565538326081\n",
      "\n",
      "Iteration: 169\n",
      "P: [ 6.62363749 -5.50109095  0.6319983   7.76486889]\n",
      "Loss: 16.964962557651617\n",
      "\n",
      "Iteration: 170\n",
      "P: [ 6.62269101 -5.50065486  0.63226723  7.76600729]\n",
      "Loss: 16.964400654432417\n",
      "\n",
      "Iteration: 171\n",
      "P: [ 6.61820567 -5.49776637  0.63337921  7.76980728]\n",
      "Loss: 16.962871973800542\n",
      "\n",
      "Iteration: 172\n",
      "P: [ 6.60690448 -5.48972342  0.63580846  7.77222532]\n",
      "Loss: 16.96096839778883\n",
      "\n",
      "Iteration: 173\n",
      "P: [ 6.60488375 -5.48824734  0.63624584  7.77286814]\n",
      "Loss: 16.96017438035882\n",
      "\n",
      "Iteration: 174\n",
      "P: [ 6.59972613 -5.48434527  0.63738156  7.77526831]\n",
      "Loss: 16.95801668851286\n",
      "\n",
      "Iteration: 175\n",
      "P: [ 6.59873366 -5.48298976  0.63762107  7.77777838]\n",
      "Loss: 16.95536053447447\n",
      "\n",
      "Iteration: 176\n",
      "P: [ 6.60034243 -5.48355012  0.63714307  7.77583091]\n",
      "Loss: 16.954949469853787\n",
      "\n",
      "Iteration: 177\n",
      "P: [ 6.59706971 -5.48112763  0.63783508  7.77650313]\n",
      "Loss: 16.954072476424663\n",
      "\n",
      "Iteration: 178\n",
      "P: [ 6.59190057 -5.47709719  0.63889568  7.77729398]\n",
      "Loss: 16.953623065550605\n",
      "\n",
      "Iteration: 179\n",
      "P: [ 6.5925704  -5.47767165  0.63877398  7.77737422]\n",
      "Loss: 16.952803582190324\n",
      "\n",
      "Iteration: 180\n",
      "P: [ 6.58960662 -5.47552579  0.63944976  7.77878551]\n",
      "Loss: 16.950874367327\n",
      "\n",
      "Iteration: 181\n",
      "P: [ 6.57989384 -5.46831003  0.64160925  7.78285963]\n",
      "Loss: 16.948210242026157\n",
      "\n",
      "Iteration: 182\n",
      "P: [ 6.57891044 -5.46769398  0.64188312  7.78414809]\n",
      "Loss: 16.94685382361102\n",
      "\n",
      "Iteration: 183\n",
      "P: [ 6.57418588 -5.46436063  0.64301609  7.78739577]\n",
      "Loss: 16.945388530206777\n",
      "\n",
      "Iteration: 184\n",
      "P: [ 6.56897079 -5.46089364  0.6443341   7.79171407]\n",
      "Loss: 16.941850511029102\n",
      "\n",
      "Iteration: 185\n",
      "P: [ 6.56180584 -5.45550751  0.64598715  7.79574894]\n",
      "Loss: 16.94013667318565\n",
      "\n",
      "Iteration: 186\n",
      "P: [ 6.55342834 -5.44871065  0.64783618  7.79942583]\n",
      "Loss: 16.935042162442535\n",
      "\n",
      "Iteration: 187\n",
      "P: [ 6.55160692 -5.44732124  0.6482529   7.80036964]\n",
      "Loss: 16.934611423267175\n",
      "\n",
      "Iteration: 188\n",
      "P: [ 6.5456865  -5.44280518  0.64961181  7.80338177]\n",
      "Loss: 16.93324506435039\n",
      "\n",
      "Iteration: 189\n",
      "P: [ 6.54366706 -5.44138094  0.65010391  7.80462936]\n",
      "Loss: 16.931193474513375\n",
      "\n",
      "Iteration: 190\n",
      "P: [ 6.53479255 -5.43506609  0.65224609  7.80997948]\n",
      "Loss: 16.928717000043083\n",
      "\n",
      "Iteration: 191\n",
      "P: [ 6.53290396 -5.43429256  0.65282438  7.81199102]\n",
      "Loss: 16.925375157378003\n",
      "\n",
      "Iteration: 192\n",
      "P: [ 6.52948512 -5.43192819  0.65366398  7.81411838]\n",
      "Loss: 16.923243409902728\n",
      "\n",
      "Iteration: 193\n",
      "P: [ 6.52703903 -5.43023757  0.65426431  7.81560055]\n",
      "Loss: 16.922513798256023\n",
      "\n",
      "Iteration: 194\n",
      "P: [ 6.52452601 -5.4283651   0.65484932  7.81675579]\n",
      "Loss: 16.922009781848427\n",
      "\n",
      "Iteration: 195\n",
      "P: [ 6.5226656  -5.42681957  0.65524756  7.81722666]\n",
      "Loss: 16.921164305760822\n",
      "\n",
      "Iteration: 196\n",
      "P: [ 6.51571492 -5.4205243   0.65662362  7.81778502]\n",
      "Loss: 16.917811572056575\n",
      "\n",
      "Iteration: 197\n",
      "P: [ 6.51350584 -5.41845572  0.65702282  7.817229  ]\n",
      "Loss: 16.916388362648245\n",
      "\n",
      "Iteration: 198\n",
      "P: [ 6.509316   -5.41495257  0.65789165  7.81763186]\n",
      "Loss: 16.91538092375437\n",
      "\n",
      "Iteration: 199\n",
      "P: [ 6.50537162 -5.41181949  0.65872096  7.81774225]\n",
      "Loss: 16.91403182704592\n",
      "\n",
      "Iteration: 200\n",
      "P: [ 6.50324668 -5.41051644  0.65920611  7.81747337]\n",
      "Loss: 16.911754497429246\n",
      "\n",
      "Iteration: 201\n",
      "P: [ 6.50093718 -5.40869355  0.65968643  7.81734802]\n",
      "Loss: 16.911327895017276\n",
      "\n",
      "Iteration: 202\n",
      "P: [ 6.49931647 -5.40739896  0.66001312  7.81700476]\n",
      "Loss: 16.91076633129089\n",
      "\n",
      "Iteration: 203\n",
      "P: [ 6.49697951 -5.40587182  0.6606061   7.81821366]\n",
      "Loss: 16.909646763136024\n",
      "\n",
      "Iteration: 204\n",
      "P: [ 6.49301647 -5.40280645  0.66149093  7.81899807]\n",
      "Loss: 16.90861230730752\n",
      "\n",
      "Iteration: 205\n",
      "P: [ 6.48728317 -5.39825342  0.66280825  7.82115739]\n",
      "Loss: 16.90696968668499\n",
      "\n",
      "Iteration: 206\n",
      "P: [ 6.48376872 -5.39521124  0.66367826  7.8243706 ]\n",
      "Loss: 16.902548794280964\n",
      "\n",
      "Iteration: 207\n",
      "P: [ 6.47849268 -5.39080825  0.66495801  7.82820258]\n",
      "Loss: 16.900319514946784\n",
      "\n",
      "Iteration: 208\n",
      "P: [ 6.47625355 -5.38902192  0.66557951  7.83103376]\n",
      "Loss: 16.89936746006969\n",
      "\n",
      "Iteration: 209\n",
      "P: [ 6.47142016 -5.38553407  0.66686577  7.8354413 ]\n",
      "Loss: 16.895865825612393\n",
      "\n",
      "Iteration: 210\n",
      "P: [ 6.46940733 -5.38424859  0.66743381  7.83748155]\n",
      "Loss: 16.89508870403038\n",
      "\n",
      "Iteration: 211\n",
      "P: [ 6.46938914 -5.38510656  0.66757405  7.83797476]\n",
      "Loss: 16.893276455011335\n",
      "\n",
      "Iteration: 212\n",
      "P: [ 6.46741121 -5.38365276  0.6680654   7.83899619]\n",
      "Loss: 16.89252251252927\n",
      "\n",
      "Iteration: 213\n",
      "P: [ 6.46212972 -5.37958436  0.66933908  7.84131038]\n",
      "Loss: 16.890708207445666\n",
      "\n",
      "Iteration: 214\n",
      "P: [ 6.45986853 -5.37775824  0.66988155  7.84232378]\n",
      "Loss: 16.888121852162246\n",
      "\n",
      "Iteration: 215\n",
      "P: [ 6.45165211 -5.37095027  0.67183555  7.84629914]\n",
      "Loss: 16.8849642071967\n",
      "\n",
      "Iteration: 216\n",
      "P: [ 6.44831537 -5.36778586  0.67262159  7.84844718]\n",
      "Loss: 16.883499648646424\n",
      "\n",
      "Iteration: 217\n",
      "P: [ 6.44447008 -5.36487556  0.67359398  7.85068819]\n",
      "Loss: 16.87962776591611\n",
      "\n",
      "Iteration: 218\n",
      "P: [ 6.44269931 -5.3635628   0.67404955  7.85177677]\n",
      "Loss: 16.878628636169136\n",
      "\n",
      "Iteration: 219\n",
      "P: [ 6.44045383 -5.36266717  0.67476285  7.85381394]\n",
      "Loss: 16.87690176865439\n",
      "\n",
      "Iteration: 220\n",
      "P: [ 6.44122779 -5.3635242   0.67463352  7.85398546]\n",
      "Loss: 16.876395771004294\n",
      "\n",
      "Iteration: 221\n",
      "P: [ 6.43972234 -5.362488    0.67508447  7.85592788]\n",
      "Loss: 16.87511422037772\n",
      "\n",
      "Iteration: 222\n",
      "P: [ 6.43604108 -5.35982049  0.67614726  7.86023673]\n",
      "Loss: 16.873255528975175\n",
      "\n",
      "Iteration: 223\n",
      "P: [ 6.43416897 -5.35851363  0.67676744  7.86383981]\n",
      "Loss: 16.871844509635135\n",
      "\n",
      "Iteration: 224\n",
      "P: [ 6.43443705 -5.35888166  0.67683596  7.86588288]\n",
      "Loss: 16.87055952358986\n",
      "\n",
      "Iteration: 225\n",
      "P: [ 6.43328009 -5.35832071  0.67728373  7.8687177 ]\n",
      "Loss: 16.86978447685705\n",
      "\n",
      "Iteration: 226\n",
      "P: [ 6.43197978 -5.3578964   0.67786627  7.87288437]\n",
      "Loss: 16.869483233441375\n",
      "\n",
      "Iteration: 227\n",
      "P: [ 6.43233592 -5.35822777  0.67776175  7.87222181]\n",
      "Loss: 16.868974653892547\n",
      "\n",
      "Iteration: 228\n",
      "P: [ 6.43178079 -5.35774801  0.67792086  7.87296534]\n",
      "Loss: 16.868383156732488\n",
      "\n",
      "Iteration: 229\n",
      "P: [ 6.42649661 -5.35372457  0.67950286  7.88014075]\n",
      "Loss: 16.865799448503214\n",
      "\n",
      "Iteration: 230\n",
      "P: [ 6.42379153 -5.35113115  0.68003717  7.87977505]\n",
      "Loss: 16.863628619430852\n",
      "\n",
      "Iteration: 231\n",
      "P: [ 6.42014536 -5.34818168  0.68095552  7.8817616 ]\n",
      "Loss: 16.862183928955837\n",
      "\n",
      "Iteration: 232\n",
      "P: [ 6.41443482 -5.34362676  0.68228449  7.88252099]\n",
      "Loss: 16.86056806503959\n",
      "\n",
      "Iteration: 233\n",
      "P: [ 6.41544351 -5.34451343  0.68202075  7.88148496]\n",
      "Loss: 16.85791052322572\n",
      "\n",
      "Iteration: 234\n",
      "P: [ 6.4126101  -5.34227675  0.68268564  7.88177089]\n",
      "Loss: 16.85598676082523\n",
      "\n",
      "Iteration: 235\n",
      "P: [ 6.4107623  -5.3406761   0.68313785  7.88268037]\n",
      "Loss: 16.854914311561515\n",
      "\n",
      "Iteration: 236\n",
      "P: [ 6.40659388 -5.33739115  0.68423145  7.8852558 ]\n",
      "Loss: 16.852716082274974\n",
      "\n",
      "Iteration: 237\n",
      "P: [ 6.40310141 -5.33462692  0.68520321  7.88842008]\n",
      "Loss: 16.85075046307642\n",
      "\n",
      "Iteration: 238\n",
      "P: [ 6.39797378 -5.33032124  0.68649786  7.89098322]\n",
      "Loss: 16.8469841757196\n",
      "\n",
      "Iteration: 239\n",
      "P: [ 6.39251711 -5.32654003  0.68811393  7.89607098]\n",
      "Loss: 16.844169048802414\n",
      "\n",
      "Iteration: 240\n",
      "P: [ 6.38704251 -5.3236816   0.69013768  7.90566087]\n",
      "Loss: 16.837856308422438\n",
      "\n",
      "Iteration: 241\n",
      "P: [ 6.38613808 -5.32304467  0.69041958  7.90675452]\n",
      "Loss: 16.8370982155943\n",
      "\n",
      "Iteration: 242\n",
      "P: [ 6.38119645 -5.31894972  0.69179056  7.91105389]\n",
      "Loss: 16.8354152613263\n",
      "\n",
      "Iteration: 243\n",
      "P: [ 6.38144774 -5.3183945   0.691464    7.90800803]\n",
      "Loss: 16.83328070529271\n",
      "\n",
      "Iteration: 244\n",
      "P: [ 6.37856129 -5.31558433  0.69205035  7.9075203 ]\n",
      "Loss: 16.831683452528534\n",
      "\n",
      "Iteration: 245\n",
      "P: [ 6.37681747 -5.31409617  0.69243826  7.90729117]\n",
      "Loss: 16.831035188517525\n",
      "\n",
      "Iteration: 246\n",
      "P: [ 6.37442822 -5.31193112  0.69298207  7.90747929]\n",
      "Loss: 16.829808301111523\n",
      "\n",
      "Iteration: 247\n",
      "P: [ 6.37022727 -5.30839114  0.69407855  7.9095992 ]\n",
      "Loss: 16.826704137177092\n",
      "\n",
      "Iteration: 248\n",
      "P: [ 6.36543113 -5.3048548   0.69550826  7.91381439]\n",
      "Loss: 16.822540575136404\n",
      "\n",
      "Iteration: 249\n",
      "P: [ 6.35995618 -5.30129924  0.69740245  7.92172561]\n",
      "Loss: 16.816010699941696\n",
      "\n",
      "Iteration: 250\n",
      "P: [ 6.35891426 -5.30055666  0.69773211  7.92288518]\n",
      "Loss: 16.814946878033393\n",
      "\n",
      "Iteration: 251\n",
      "P: [ 6.35616591 -5.29850146  0.69857219  7.92560717]\n",
      "Loss: 16.81320857824435\n",
      "\n",
      "Iteration: 252\n",
      "P: [ 6.35295009 -5.2959066   0.69946089  7.92750315]\n",
      "Loss: 16.812356034710536\n",
      "\n",
      "Iteration: 253\n",
      "P: [ 6.35240779 -5.29524352  0.69951636  7.92664105]\n",
      "Loss: 16.810828807392493\n",
      "\n",
      "Iteration: 254\n",
      "P: [ 6.3482142  -5.29126955  0.70044796  7.92632169]\n",
      "Loss: 16.807623950680874\n",
      "\n",
      "Iteration: 255\n",
      "P: [ 6.34483532 -5.28788309  0.70128438  7.92816659]\n",
      "Loss: 16.80709950690379\n",
      "\n",
      "Iteration: 256\n",
      "P: [ 6.34193394 -5.28538365  0.70205943  7.92969566]\n",
      "Loss: 16.80505978309731\n",
      "\n",
      "Iteration: 257\n",
      "P: [ 6.33873723 -5.28291679  0.70301461  7.93233464]\n",
      "Loss: 16.804034537060375\n",
      "\n",
      "Iteration: 258\n",
      "P: [ 6.34163418 -5.28603068  0.70242324  7.93232512]\n",
      "Loss: 16.802073898688953\n",
      "\n",
      "Iteration: 259\n",
      "P: [ 6.34191033 -5.28693125  0.70256683  7.93411806]\n",
      "Loss: 16.80064270085459\n",
      "\n",
      "Iteration: 260\n",
      "P: [ 6.33947668 -5.2854666   0.70345551  7.93771387]\n",
      "Loss: 16.79873378724756\n",
      "\n",
      "Iteration: 261\n",
      "P: [ 6.33628498 -5.28322647  0.70446479  7.9403588 ]\n",
      "Loss: 16.79676772628591\n",
      "\n",
      "Iteration: 262\n",
      "P: [ 6.3343003  -5.28171354  0.70504824  7.9413719 ]\n",
      "Loss: 16.79408836506483\n",
      "\n",
      "Iteration: 263\n",
      "P: [ 6.32995996 -5.27783161  0.70617523  7.94287848]\n",
      "Loss: 16.791466411736593\n",
      "\n",
      "Iteration: 264\n",
      "P: [ 6.32391285 -5.27150099  0.70750562  7.94312933]\n",
      "Loss: 16.785437854066974\n",
      "\n",
      "Iteration: 265\n",
      "P: [ 6.32127605 -5.26930879  0.70827577  7.94500097]\n",
      "Loss: 16.784298749130404\n",
      "\n",
      "Iteration: 266\n",
      "P: [ 6.31699007 -5.26600437  0.70967826  7.94981809]\n",
      "Loss: 16.780967728025512\n",
      "\n",
      "Iteration: 267\n",
      "P: [ 6.31558239 -5.26559544  0.71043705  7.95443057]\n",
      "Loss: 16.775809979777616\n",
      "\n",
      "Iteration: 268\n",
      "P: [ 6.31287388 -5.26363526  0.71138647  7.95807531]\n",
      "Loss: 16.773981571878288\n",
      "\n",
      "Iteration: 269\n",
      "P: [ 6.3084921  -5.260366    0.71289362  7.963452  ]\n",
      "Loss: 16.77052195375813\n",
      "\n",
      "Iteration: 270\n",
      "P: [ 6.30569759 -5.2580809   0.71376219  7.96540663]\n",
      "Loss: 16.764885066648073\n",
      "\n",
      "Iteration: 271\n",
      "P: [ 6.30254591 -5.25547215  0.71473781  7.96796681]\n",
      "Loss: 16.762348854514595\n",
      "\n",
      "Iteration: 272\n",
      "P: [ 6.29932197 -5.25271544  0.71570242  7.97015854]\n",
      "Loss: 16.760665393881336\n",
      "\n",
      "Iteration: 273\n",
      "P: [ 6.29689565 -5.25035777  0.71632487  7.97073864]\n",
      "Loss: 16.757756875343627\n",
      "\n",
      "Iteration: 274\n",
      "P: [ 6.29332296 -5.24721749  0.71737829  7.97272879]\n",
      "Loss: 16.7531163362249\n",
      "\n",
      "Iteration: 275\n",
      "P: [ 6.29083867 -5.24514962  0.71815752  7.9746446 ]\n",
      "Loss: 16.751561089988204\n",
      "\n",
      "Iteration: 276\n",
      "P: [ 6.28477633 -5.24039489  0.72020772  7.98048088]\n",
      "Loss: 16.74752552851243\n",
      "\n",
      "Iteration: 277\n",
      "P: [ 6.28522739 -5.24132238  0.72032599  7.9823701 ]\n",
      "Loss: 16.742331270749585\n",
      "\n",
      "Iteration: 278\n",
      "P: [ 6.28100366 -5.23816351  0.72183603  7.98711097]\n",
      "Loss: 16.738571909391357\n",
      "\n",
      "Iteration: 279\n",
      "P: [ 6.27981202 -5.23735844  0.72231063  7.98884078]\n",
      "Loss: 16.736810983310715\n",
      "\n",
      "Iteration: 280\n",
      "P: [ 6.27734509 -5.23559904  0.72329698  7.99253795]\n",
      "Loss: 16.73344045540352\n",
      "\n",
      "Iteration: 281\n",
      "P: [ 6.27340174 -5.2326603   0.72476481  7.99745036]\n",
      "Loss: 16.728222902505454\n",
      "\n",
      "Iteration: 282\n",
      "P: [ 6.27200088 -5.23152625  0.72525212  7.99888806]\n",
      "Loss: 16.727523164936038\n",
      "\n",
      "Iteration: 283\n",
      "P: [ 6.27034244 -5.2297981   0.7256691   7.99913753]\n",
      "Loss: 16.72526411461472\n",
      "\n",
      "Iteration: 284\n",
      "P: [ 6.26306444 -5.2216376   0.72728437  7.99857222]\n",
      "Loss: 16.71883247416605\n",
      "\n",
      "Iteration: 285\n",
      "P: [ 6.26174329 -5.22048708  0.72771728  7.99970935]\n",
      "Loss: 16.71821977812757\n",
      "\n",
      "Iteration: 286\n",
      "P: [ 6.2613959  -5.22033934  0.72790799  8.00073802]\n",
      "Loss: 16.717253472314272\n",
      "\n",
      "Iteration: 287\n",
      "P: [ 6.25712452 -5.217869    0.72996447  8.01076252]\n",
      "Loss: 16.713508597964484\n",
      "\n",
      "Iteration: 288\n",
      "P: [ 6.26023406 -5.22091701  0.72910291  8.0095179 ]\n",
      "Loss: 16.710468757718665\n",
      "\n",
      "Iteration: 289\n",
      "P: [ 6.25741012 -5.21825202  0.72997536  8.01161149]\n",
      "Loss: 16.7076730532423\n",
      "\n",
      "Iteration: 290\n",
      "P: [ 6.25441453 -5.21562859  0.73101345  8.01492755]\n",
      "Loss: 16.70566749053696\n",
      "\n",
      "Iteration: 291\n",
      "P: [ 6.25128248 -5.21245524  0.73190348  8.01659431]\n",
      "Loss: 16.703303915761833\n",
      "\n",
      "Iteration: 292\n",
      "P: [ 6.24816848 -5.20952286  0.73291849  8.01946418]\n",
      "Loss: 16.699985415362175\n",
      "\n",
      "Iteration: 293\n",
      "P: [ 6.24604794 -5.20794221  0.73382154  8.023376  ]\n",
      "Loss: 16.698006498014177\n",
      "\n",
      "Iteration: 294\n",
      "P: [ 6.24324193 -5.20618807  0.73524702  8.03062834]\n",
      "Loss: 16.69148531214726\n",
      "\n",
      "Iteration: 295\n",
      "P: [ 6.24284578 -5.20580631  0.73535852  8.03059492]\n",
      "Loss: 16.69099205681618\n",
      "\n",
      "Iteration: 296\n",
      "P: [ 6.2437745  -5.20721032  0.7353245   8.03161181]\n",
      "Loss: 16.68776048985161\n",
      "\n",
      "Iteration: 297\n",
      "P: [ 6.24039453 -5.20547293  0.73714163  8.03927753]\n",
      "Loss: 16.683578594559258\n",
      "\n",
      "Iteration: 298\n",
      "P: [ 6.24117993 -5.20647659  0.73704041  8.03978945]\n",
      "Loss: 16.682647385230617\n",
      "\n",
      "Iteration: 299\n",
      "P: [ 6.2385732  -5.2035014   0.73763776  8.03977102]\n",
      "Loss: 16.67828907447164\n",
      "\n",
      "Iteration: 300\n",
      "P: [ 6.23468383 -5.19985626  0.73894341  8.04286324]\n",
      "Loss: 16.674682426318995\n",
      "\n",
      "Iteration: 301\n",
      "P: [ 6.23136619 -5.19614954  0.73978139  8.04369712]\n",
      "Loss: 16.6711327141145\n",
      "\n",
      "Iteration: 302\n",
      "P: [ 6.22556435 -5.19038183  0.74163011  8.04833446]\n",
      "Loss: 16.66893733881819\n",
      "\n",
      "Iteration: 303\n",
      "P: [ 6.22463375 -5.18934009  0.74190169  8.0492733 ]\n",
      "Loss: 16.668529238363753\n",
      "\n",
      "Iteration: 304\n",
      "P: [ 6.22496023 -5.19013555  0.74209334  8.05180257]\n",
      "Loss: 16.665786181303215\n",
      "\n",
      "Iteration: 305\n",
      "P: [ 6.22512607 -5.19114308  0.74258518  8.0566628 ]\n",
      "Loss: 16.66250270810013\n",
      "\n",
      "Iteration: 306\n",
      "P: [ 6.22713322 -5.19363524  0.7422609   8.05782053]\n",
      "Loss: 16.660709934037325\n",
      "\n",
      "Iteration: 307\n",
      "P: [ 6.22618469 -5.19330416  0.74295955  8.06198142]\n",
      "Loss: 16.6585000891348\n",
      "\n",
      "Iteration: 308\n",
      "P: [ 6.2249818  -5.19245367  0.74356611  8.06472136]\n",
      "Loss: 16.657199388292444\n",
      "\n",
      "Iteration: 309\n",
      "P: [ 6.22349061 -5.19217238  0.74480153  8.07181296]\n",
      "Loss: 16.655011882861928\n",
      "\n",
      "Iteration: 310\n",
      "P: [ 6.22104609 -5.18942287  0.74534342  8.07056513]\n",
      "Loss: 16.653600579392354\n",
      "\n",
      "Iteration: 311\n",
      "P: [ 6.21995869 -5.1875327   0.74513421  8.06555574]\n",
      "Loss: 16.650160056979328\n",
      "\n",
      "Iteration: 312\n",
      "P: [ 6.21923455 -5.18668297  0.74529255  8.06510986]\n",
      "Loss: 16.647512837882946\n",
      "\n",
      "Iteration: 313\n",
      "P: [ 6.21625266 -5.18432796  0.74666059  8.06949577]\n",
      "Loss: 16.64143376243311\n",
      "\n",
      "Iteration: 314\n",
      "P: [ 6.21138725 -5.17918696  0.74821082  8.0739362 ]\n",
      "Loss: 16.63646791349292\n",
      "\n",
      "Iteration: 315\n",
      "P: [ 6.21043967 -5.17836291  0.74862057  8.07554643]\n",
      "Loss: 16.634908339496118\n",
      "\n",
      "Iteration: 316\n",
      "P: [ 6.20887074 -5.17696916  0.74928454  8.07807868]\n",
      "Loss: 16.632959387497593\n",
      "\n",
      "Iteration: 317\n",
      "P: [ 6.20705573 -5.17537128  0.75005272  8.08067309]\n",
      "Loss: 16.631193665915788\n",
      "\n",
      "Iteration: 318\n",
      "P: [ 6.20596839 -5.17454374  0.75058305  8.08210843]\n",
      "Loss: 16.629330186923593\n",
      "\n",
      "Iteration: 319\n",
      "P: [ 6.20766433 -5.17716378  0.75064359  8.08491691]\n",
      "Loss: 16.62417990075322\n",
      "\n",
      "Iteration: 320\n",
      "P: [ 6.20658427 -5.17727914  0.75186744  8.0917056 ]\n",
      "Loss: 16.621432501281465\n",
      "\n",
      "Iteration: 321\n",
      "P: [ 6.20603188 -5.17665614  0.75199585  8.09128008]\n",
      "Loss: 16.621103694302146\n",
      "\n",
      "Iteration: 322\n",
      "P: [ 6.20552572 -5.17586711  0.75196584  8.08947568]\n",
      "Loss: 16.619285787789202\n",
      "\n",
      "Iteration: 323\n",
      "P: [ 6.2031027  -5.17297024  0.75254243  8.08961907]\n",
      "Loss: 16.614353854790938\n",
      "\n",
      "Iteration: 324\n",
      "P: [ 6.19995901 -5.16988479  0.75373357  8.09251223]\n",
      "Loss: 16.608960280362297\n",
      "\n",
      "Iteration: 325\n",
      "P: [ 6.19817635 -5.16815535  0.75443298  8.09451968]\n",
      "Loss: 16.6065291177956\n",
      "\n",
      "Iteration: 326\n",
      "P: [ 6.1877527  -5.15752072  0.75820166  8.10535186]\n",
      "Loss: 16.600825136092027\n",
      "\n",
      "Iteration: 327\n",
      "P: [ 6.18685139 -5.15644113  0.7584102   8.10535756]\n",
      "Loss: 16.600032844782067\n",
      "\n",
      "Iteration: 328\n",
      "P: [ 6.18800387 -5.15772635  0.75809107  8.10523664]\n",
      "Loss: 16.599257062867004\n",
      "\n",
      "Iteration: 329\n",
      "P: [ 6.19076822 -5.16074581  0.75726983  8.10341683]\n",
      "Loss: 16.59723047023292\n",
      "\n",
      "Iteration: 330\n",
      "P: [ 6.19151001 -5.16195508  0.75740342  8.1055015 ]\n",
      "Loss: 16.59409353909324\n",
      "\n",
      "Iteration: 331\n",
      "P: [ 6.18947063 -5.16050814  0.75870809  8.11182531]\n",
      "Loss: 16.587246335560128\n",
      "\n",
      "Iteration: 332\n",
      "P: [ 6.18889267 -5.16011238  0.759093    8.11363183]\n",
      "Loss: 16.58582684542622\n",
      "\n",
      "Iteration: 333\n",
      "P: [ 6.18767876 -5.15969429  0.76027043  8.11882767]\n",
      "Loss: 16.582883687042973\n",
      "\n",
      "Iteration: 334\n",
      "P: [ 6.18934219 -5.16183107  0.76005196  8.11990696]\n",
      "Loss: 16.581693198438202\n",
      "\n",
      "Iteration: 335\n",
      "P: [ 6.18818312 -5.16039386  0.76026398  8.11957166]\n",
      "Loss: 16.580255578401466\n",
      "\n",
      "Iteration: 336\n",
      "P: [ 6.18754631 -5.15980253  0.7605687   8.12058826]\n",
      "Loss: 16.579060866897787\n",
      "\n",
      "Iteration: 337\n",
      "P: [ 6.18107421 -5.1530578   0.7630375   8.12716597]\n",
      "Loss: 16.57046005294863\n",
      "\n",
      "Iteration: 338\n",
      "P: [ 6.17844576 -5.15005031  0.76380396  8.12845546]\n",
      "Loss: 16.565794527093775\n",
      "\n",
      "Iteration: 339\n",
      "P: [ 6.17571367 -5.14705744  0.76471981  8.13053657]\n",
      "Loss: 16.563964225499916\n",
      "\n",
      "Iteration: 340\n",
      "P: [ 6.17240642 -5.14374445  0.76612466  8.13500902]\n",
      "Loss: 16.561560805235963\n",
      "\n",
      "Iteration: 341\n",
      "P: [ 6.16965752 -5.14096836  0.76728161  8.13886562]\n",
      "Loss: 16.560423391509996\n",
      "\n",
      "Iteration: 342\n",
      "P: [ 6.16799796 -5.13926648  0.76796982  8.14101996]\n",
      "Loss: 16.559234768025544\n",
      "\n",
      "Iteration: 343\n",
      "P: [ 6.16539822 -5.13681848  0.76931608  8.14614617]\n",
      "Loss: 16.555458772443835\n",
      "\n",
      "Iteration: 344\n",
      "P: [ 6.16351405 -5.13537641  0.7708217   8.15296179]\n",
      "Loss: 16.54458767202417\n",
      "\n",
      "Iteration: 345\n",
      "P: [ 6.16429454 -5.13651129  0.77102276  8.15503515]\n",
      "Loss: 16.534976717545828\n",
      "\n",
      "Iteration: 346\n",
      "P: [ 6.17708788 -5.15523487  0.77409527  8.18857361]\n",
      "Loss: 16.297568188076742\n",
      "\n",
      "Iteration: 347\n",
      "P: [ 6.17729111 -5.15545708  0.77402981  8.1883862 ]\n",
      "Loss: 16.297434472507753\n",
      "\n",
      "Iteration: 348\n",
      "P: [ 6.17913513 -5.15664381  0.77219174  8.17907891]\n",
      "Loss: 16.28923950717913\n",
      "\n",
      "Iteration: 349\n",
      "P: [ 6.17994452 -5.15662743  0.77053121  8.17273626]\n",
      "Loss: 16.28059544992776\n",
      "\n",
      "Iteration: 350\n",
      "P: [ 6.17796911 -5.15502275  0.77201037  8.18188724]\n",
      "Loss: 16.268428888089847\n",
      "\n",
      "Iteration: 351\n",
      "P: [ 6.17665614 -5.15368407  0.77260492  8.18728181]\n",
      "Loss: 16.26160098349371\n",
      "\n",
      "Iteration: 352\n",
      "P: [ 6.17551944 -5.15260348  0.77327275  8.19184623]\n",
      "Loss: 16.260326317603898\n",
      "\n",
      "Iteration: 353\n",
      "P: [ 6.17543036 -5.15251734  0.77335582  8.19153826]\n",
      "Loss: 16.258741763176506\n",
      "\n",
      "Iteration: 354\n",
      "P: [ 6.17396965 -5.15109266  0.77431622  8.19444255]\n",
      "Loss: 16.25402082468657\n",
      "\n",
      "Iteration: 355\n",
      "P: [ 6.17102361 -5.14793379  0.77599399  8.19882995]\n",
      "Loss: 16.2456365662077\n",
      "\n",
      "Iteration: 356\n",
      "P: [ 6.16909555 -5.14474883  0.77636608  8.19291494]\n",
      "Loss: 16.222683431236586\n",
      "\n",
      "Iteration: 357\n",
      "P: [ 6.1671633  -5.14131378  0.77661294  8.18572501]\n",
      "Loss: 16.218776226266638\n",
      "\n",
      "Iteration: 358\n",
      "P: [ 6.16692932 -5.14105951  0.77680085  8.18592959]\n",
      "Loss: 16.217407633965895\n",
      "\n",
      "Iteration: 359\n",
      "P: [ 6.16751711 -5.14254698  0.7772516   8.19210011]\n",
      "Loss: 16.210298037702618\n",
      "\n",
      "Iteration: 360\n",
      "P: [ 6.16641895 -5.14147349  0.77789677  8.19518812]\n",
      "Loss: 16.20936572831035\n",
      "\n",
      "Iteration: 361\n",
      "P: [ 6.16508589 -5.14009682  0.77880271  8.19890562]\n",
      "Loss: 16.20419694107841\n",
      "\n",
      "Iteration: 362\n",
      "P: [ 6.1601493  -5.13486553  0.78253203  8.21317814]\n",
      "Loss: 16.186815634691882\n",
      "\n",
      "Iteration: 363\n",
      "P: [ 6.16042068 -5.13505857  0.78284738  8.21448821]\n",
      "Loss: 16.172729307491316\n",
      "\n",
      "Iteration: 364\n",
      "P: [ 6.15579062 -5.12991669  0.78650102  8.22882655]\n",
      "Loss: 16.15814142006487\n",
      "\n",
      "Iteration: 365\n",
      "P: [ 6.15282182 -5.12669913  0.78862184  8.23903704]\n",
      "Loss: 16.14236419851246\n",
      "\n",
      "Iteration: 366\n",
      "P: [ 6.14866698 -5.12149434  0.79150171  8.24971894]\n",
      "Loss: 16.124429494095615\n",
      "\n",
      "Iteration: 367\n",
      "P: [ 6.14798077 -5.12069853  0.79205551  8.25203062]\n",
      "Loss: 16.12174709157091\n",
      "\n",
      "Iteration: 368\n",
      "P: [ 6.14605643 -5.11849129  0.79394562  8.2606148 ]\n",
      "Loss: 16.112132030799824\n",
      "\n",
      "Iteration: 369\n",
      "P: [ 6.14508837 -5.11740968  0.79526228  8.26714869]\n",
      "Loss: 16.10530367817666\n",
      "\n",
      "Iteration: 370\n",
      "P: [ 6.14520695 -5.11756362  0.7967459   8.27563598]\n",
      "Loss: 16.091421368644905\n",
      "\n",
      "Iteration: 371\n",
      "P: [ 6.14358637 -5.11564292  0.79876696  8.28593315]\n",
      "Loss: 16.08195182539028\n",
      "\n",
      "Iteration: 372\n",
      "P: [ 6.14251926 -5.11410854  0.80141781  8.30047276]\n",
      "Loss: 16.059360488417518\n",
      "\n",
      "Iteration: 373\n",
      "P: [ 6.14114981 -5.11229699  0.80297305  8.30773688]\n",
      "Loss: 16.051334952749666\n",
      "\n",
      "Iteration: 374\n",
      "P: [ 6.13852968 -5.10863641  0.80558375  8.31900088]\n",
      "Loss: 16.03803162674826\n",
      "\n",
      "Iteration: 375\n",
      "P: [ 6.13432758 -5.10244943  0.80871432  8.32995022]\n",
      "Loss: 16.017141253046635\n",
      "\n",
      "Iteration: 376\n",
      "P: [ 6.13354753 -5.10117097  0.81013341  8.33671231]\n",
      "Loss: 16.01131077377405\n",
      "\n",
      "Iteration: 377\n",
      "P: [ 6.13375722 -5.10107816  0.81108932  8.34203314]\n",
      "Loss: 16.001202348725037\n",
      "\n",
      "Iteration: 378\n",
      "P: [ 6.13659969 -5.10376326  0.81238205  8.35230076]\n",
      "Loss: 15.97965920838224\n",
      "\n",
      "Iteration: 379\n",
      "P: [ 6.13603532 -5.1025722   0.81384665  8.35944148]\n",
      "Loss: 15.972648291830708\n",
      "\n",
      "Iteration: 380\n",
      "P: [ 6.13510586 -5.10070215  0.81578564  8.36872414]\n",
      "Loss: 15.965507363916151\n",
      "\n",
      "Iteration: 381\n",
      "P: [ 6.13347162 -5.09797948  0.81747841  8.37582979]\n",
      "Loss: 15.946266015113897\n",
      "\n",
      "Iteration: 382\n",
      "P: [ 6.12961717 -5.09113436  0.8224908   8.39810069]\n",
      "Loss: 15.92681242533735\n",
      "\n",
      "Iteration: 383\n",
      "P: [ 6.12971064 -5.09098009  0.82304577  8.40120982]\n",
      "Loss: 15.924263050614604\n",
      "\n",
      "Iteration: 384\n",
      "P: [ 6.13088722 -5.09200332  0.82346212  8.40494328]\n",
      "Loss: 15.909751461316189\n",
      "\n",
      "Iteration: 385\n",
      "P: [ 6.13637879 -5.09598682  0.82506626  8.4163519 ]\n",
      "Loss: 15.886344714320426\n",
      "\n",
      "Iteration: 386\n",
      "P: [ 6.13682359 -5.09660218  0.82507202  8.4177    ]\n",
      "Loss: 15.882779611679116\n",
      "\n",
      "Iteration: 387\n",
      "P: [ 6.13611685 -5.0953191   0.82653868  8.42603071]\n",
      "Loss: 15.872905570825393\n",
      "\n",
      "Iteration: 388\n",
      "P: [ 6.13572444 -5.09451183  0.82749747  8.43147469]\n",
      "Loss: 15.868344298329545\n",
      "\n",
      "Iteration: 389\n",
      "P: [ 6.1349832  -5.09289573  0.82909252  8.4400213 ]\n",
      "Loss: 15.858041096781912\n",
      "\n",
      "Iteration: 390\n",
      "P: [ 6.13204813 -5.08730548  0.83303333  8.45881045]\n",
      "Loss: 15.834037882802821\n",
      "\n",
      "Iteration: 391\n",
      "P: [ 6.13252189 -5.08670406  0.8346662   8.46807093]\n",
      "Loss: 15.823491405207056\n",
      "\n",
      "Iteration: 392\n",
      "P: [ 6.13315976 -5.08649182  0.83573033  8.47389208]\n",
      "Loss: 15.81658597412603\n",
      "\n",
      "Iteration: 393\n",
      "P: [ 6.13500028 -5.08675847  0.83734133  8.48260501]\n",
      "Loss: 15.809510160896364\n",
      "\n",
      "Iteration: 394\n",
      "P: [ 6.13467108 -5.08646354  0.83728767  8.48230347]\n",
      "Loss: 15.796127065721189\n",
      "\n",
      "Iteration: 395\n",
      "P: [ 6.13536189 -5.08577491  0.83892161  8.4912932 ]\n",
      "Loss: 15.783102026548088\n",
      "\n",
      "Iteration: 396\n",
      "P: [ 6.13713606 -5.08561561  0.84106693  8.5036759 ]\n",
      "Loss: 15.766273768647475\n",
      "\n",
      "Iteration: 397\n",
      "P: [ 6.1389328  -5.08624371  0.84219474  8.51094411]\n",
      "Loss: 15.754621289544463\n",
      "\n",
      "Iteration: 398\n",
      "P: [ 6.14563993 -5.09122398  0.84300988  8.52093249]\n",
      "Loss: 15.727907440535294\n",
      "\n",
      "Iteration: 399\n",
      "P: [ 6.14749041 -5.09109885  0.84527483  8.53481759]\n",
      "Loss: 15.711791017359017\n",
      "\n",
      "Iteration: 400\n",
      "P: [ 6.14779355 -5.09066585  0.8462551   8.54069999]\n",
      "Loss: 15.707317001604563\n",
      "\n",
      "Iteration: 401\n",
      "P: [ 6.14690618 -5.0890077   0.84766673  8.54872638]\n",
      "Loss: 15.694589833896492\n",
      "\n",
      "Iteration: 402\n",
      "P: [ 6.14590261 -5.08699647  0.84889321  8.55435336]\n",
      "Loss: 15.678899587748607\n",
      "\n",
      "Iteration: 403\n",
      "P: [ 6.1499648  -5.08616417  0.85384549  8.58431046]\n",
      "Loss: 15.654733937076964\n",
      "\n",
      "Iteration: 404\n",
      "P: [ 6.15012609 -5.08494192  0.85530543  8.59203812]\n",
      "Loss: 15.644453001010453\n",
      "\n",
      "Iteration: 405\n",
      "P: [ 6.15303137 -5.08427756  0.85852859  8.61070592]\n",
      "Loss: 15.633815234948068\n",
      "\n",
      "Iteration: 406\n",
      "P: [ 6.1537558  -5.08461878  0.85877586  8.61255072]\n",
      "Loss: 15.631947537010289\n",
      "\n",
      "Iteration: 407\n",
      "P: [ 6.15724164 -5.08439786  0.86224099  8.63422921]\n",
      "Loss: 15.62112863192878\n",
      "\n",
      "Iteration: 408\n",
      "P: [ 6.15932551 -5.08422102  0.86433243  8.6473354 ]\n",
      "Loss: 15.615624963860393\n",
      "\n",
      "Iteration: 409\n",
      "P: [ 6.16146731 -5.08491851  0.86547944  8.65575251]\n",
      "Loss: 15.608334173906885\n",
      "\n",
      "Iteration: 410\n",
      "P: [ 6.17583224 -5.09226532  0.86851849  8.68495497]\n",
      "Loss: 15.496655230875609\n",
      "\n",
      "Iteration: 411\n",
      "P: [ 6.18482978 -5.09593305  0.87165307  8.70968096]\n",
      "Loss: 15.436693605075465\n",
      "\n",
      "Iteration: 412\n",
      "P: [ 6.18659762 -5.09670173  0.87221131  8.71425539]\n",
      "Loss: 15.429013034220253\n",
      "\n",
      "Iteration: 413\n",
      "P: [ 6.2031411  -5.1044501   0.87695123  8.75532172]\n",
      "Loss: 15.388253186942238\n",
      "\n",
      "Iteration: 414\n",
      "P: [ 6.20436669 -5.10509835  0.87723682  8.75810658]\n",
      "Loss: 15.386203654403174\n",
      "\n",
      "Iteration: 415\n",
      "P: [ 6.20979524 -5.1076949   0.87875775  8.77154666]\n",
      "Loss: 15.377649626290015\n",
      "\n",
      "Iteration: 416\n",
      "P: [ 6.21110931 -5.10833068  0.87911929  8.77477326]\n",
      "Loss: 15.376745434629614\n",
      "\n",
      "Iteration: 417\n",
      "P: [ 6.21511176 -5.11029233  0.88020302  8.78458008]\n",
      "Loss: 15.3716333831589\n",
      "\n",
      "Iteration: 418\n",
      "P: [ 6.22098509 -5.11319321  0.88178151  8.79899697]\n",
      "Loss: 15.362063256319914\n",
      "\n",
      "Iteration: 419\n",
      "P: [ 6.22450265 -5.11494448  0.88272066  8.80766535]\n",
      "Loss: 15.358057955068874\n",
      "\n",
      "Iteration: 420\n",
      "P: [ 6.22870915 -5.11702567  0.88384956  8.81800566]\n",
      "Loss: 15.35162611634288\n",
      "\n",
      "Iteration: 421\n",
      "P: [ 6.22903868 -5.11718895  0.88393787  8.81881627]\n",
      "Loss: 15.351397748571012\n",
      "\n",
      "Iteration: 422\n",
      "P: [ 6.23107562 -5.11819884  0.88448497  8.82384882]\n",
      "Loss: 15.350049785722797\n",
      "\n",
      "Iteration: 423\n",
      "P: [ 6.23253016 -5.11891986  0.88487765  8.82746939]\n",
      "Loss: 15.348306949877598\n",
      "\n",
      "Iteration: 424\n",
      "P: [ 6.23527362 -5.12015477  0.88571703  8.83488688]\n",
      "Loss: 15.342003945940153\n",
      "\n",
      "Iteration: 425\n",
      "P: [ 6.23628537 -5.12062292  0.8860161   8.8375564 ]\n",
      "Loss: 15.34075984912988\n",
      "\n",
      "Iteration: 426\n",
      "P: [ 6.23825903 -5.12148512  0.88664026  8.84301075]\n",
      "Loss: 15.337983394653518\n",
      "\n",
      "Iteration: 427\n",
      "P: [ 6.24046652 -5.12233061  0.88743227  8.84967335]\n",
      "Loss: 15.33338524186243\n",
      "\n",
      "Iteration: 428\n",
      "P: [ 6.24169006 -5.12250845  0.88809941  8.8547242 ]\n",
      "Loss: 15.323508383389516\n",
      "\n",
      "Iteration: 429\n",
      "P: [ 6.24238343 -5.12270544  0.88840184  8.85713514]\n",
      "Loss: 15.321119770094372\n",
      "\n",
      "Iteration: 430\n",
      "P: [ 6.24330418 -5.12288711  0.88886594  8.86070682]\n",
      "Loss: 15.317582547948549\n",
      "\n",
      "Iteration: 431\n",
      "P: [ 6.24494136 -5.12292011  0.8899173   8.86839178]\n",
      "Loss: 15.314322862543197\n",
      "\n",
      "Iteration: 432\n",
      "P: [ 6.24407232 -5.12242282  0.88973328  8.86651689]\n",
      "Loss: 15.305188094151964\n",
      "\n",
      "Iteration: 433\n",
      "P: [ 6.24379065 -5.12142285  0.89032827  8.86976865]\n",
      "Loss: 15.292952010302523\n",
      "\n",
      "Iteration: 434\n",
      "P: [ 6.24378669 -5.12004187  0.89140368  8.87610556]\n",
      "Loss: 15.280753978774577\n",
      "\n",
      "Iteration: 435\n",
      "P: [ 6.24272313 -5.11844611  0.89195031  8.87836043]\n",
      "Loss: 15.270795174962714\n",
      "\n",
      "Iteration: 436\n",
      "P: [ 6.23498741 -5.1115827   0.89225261  8.87309578]\n",
      "Loss: 15.238455454879011\n",
      "\n",
      "Iteration: 437\n",
      "P: [ 6.23182485 -5.10980665  0.89157341  8.86620622]\n",
      "Loss: 15.228464732929597\n",
      "\n",
      "Iteration: 438\n",
      "P: [ 6.23183159 -5.1099109   0.89149429  8.86574534]\n",
      "Loss: 15.227808978766044\n",
      "\n",
      "Iteration: 439\n",
      "P: [ 6.23118952 -5.10948946  0.89139933  8.86459892]\n",
      "Loss: 15.227041661015297\n",
      "\n",
      "Iteration: 440\n",
      "P: [ 6.23181002 -5.1098414   0.89152067  8.8659108 ]\n",
      "Loss: 15.224561022620021\n",
      "\n",
      "Iteration: 441\n",
      "P: [ 6.23357898 -5.11046111  0.89216699  8.87143478]\n",
      "Loss: 15.219181949452656\n",
      "\n",
      "Iteration: 442\n",
      "P: [ 6.23719132 -5.11154706  0.89364007  8.88359634]\n",
      "Loss: 15.2149344370915\n",
      "\n",
      "Iteration: 443\n",
      "P: [ 6.23846386 -5.11185143  0.89423652  8.88830117]\n",
      "Loss: 15.208164653620784\n",
      "\n",
      "Iteration: 444\n",
      "P: [ 6.24338694 -5.11263831  0.89680881  8.90816689]\n",
      "Loss: 15.195600285711706\n",
      "\n",
      "Iteration: 445\n",
      "P: [ 6.24613319 -5.11277911  0.89846757  8.92056292]\n",
      "Loss: 15.188471654522951\n",
      "\n",
      "Iteration: 446\n",
      "P: [ 6.24724909 -5.11247672  0.89941884  8.92723587]\n",
      "Loss: 15.182787090888656\n",
      "\n",
      "Iteration: 447\n",
      "P: [ 6.25186029 -5.11261141  0.90207152  8.94662883]\n",
      "Loss: 15.16246823335659\n",
      "\n",
      "Iteration: 448\n",
      "P: [ 6.25821115 -5.11262874  0.90591699  8.97468223]\n",
      "Loss: 15.14154991057608\n",
      "\n",
      "Iteration: 449\n",
      "P: [ 6.26332895 -5.1123882   0.90924132  8.99870938]\n",
      "Loss: 15.126102429726576\n",
      "\n",
      "Iteration: 450\n",
      "P: [ 6.29285781 -5.11359933  0.926108    9.12273382]\n",
      "Loss: 15.094497429778942\n",
      "\n",
      "Iteration: 451\n",
      "P: [ 6.29285989 -5.11359942  0.92610918  9.12273677]\n",
      "Loss: 15.085051341465627\n",
      "\n",
      "Iteration: 452\n",
      "P: [ 6.29383611 -5.11364311  0.92666391  9.12682041]\n",
      "Loss: 15.084876331337584\n",
      "\n",
      "Iteration: 453\n",
      "P: [ 6.29645331 -5.11318709  0.92852012  9.13977445]\n",
      "Loss: 15.080722860536724\n",
      "\n",
      "Iteration: 454\n",
      "P: [ 6.29473786 -5.11243102  0.92795739  9.13478689]\n",
      "Loss: 15.073163760232385\n",
      "\n",
      "Iteration: 455\n",
      "P: [ 6.29445882 -5.11071546  0.92884874  9.13923194]\n",
      "Loss: 15.057555744330775\n",
      "\n",
      "Iteration: 456\n",
      "P: [ 6.29313766 -5.10968929  0.92869413  9.13689182]\n",
      "Loss: 15.050256755814141\n",
      "\n",
      "Iteration: 457\n",
      "P: [ 6.29205319 -5.10901706  0.92846187  9.13440686]\n",
      "Loss: 15.047477007739422\n",
      "\n",
      "Iteration: 458\n",
      "P: [ 6.29232646 -5.10866375  0.9288408   9.13674207]\n",
      "Loss: 15.046614358585332\n",
      "\n",
      "Iteration: 459\n",
      "P: [ 6.29206538 -5.10838121  0.92885672  9.13652266]\n",
      "Loss: 15.046381826416747\n",
      "\n",
      "Iteration: 460\n",
      "P: [ 6.29225064 -5.1083845   0.92896198  9.13729136]\n",
      "Loss: 15.04617307064233\n",
      "\n",
      "Iteration: 461\n",
      "P: [ 6.29850417 -5.10884754  0.93226475  9.16183333]\n",
      "Loss: 15.036372778624594\n",
      "\n",
      "Iteration: 462\n",
      "P: [ 6.29974573 -5.1088237   0.93299066  9.16707869]\n",
      "Loss: 15.035589979225628\n",
      "\n",
      "Iteration: 463\n",
      "P: [ 6.30144135 -5.10802995  0.93444647  9.17671468]\n",
      "Loss: 15.029941802232102\n",
      "\n",
      "Iteration: 464\n",
      "P: [ 6.30307082 -5.10750813  0.93570007  9.18520377]\n",
      "Loss: 15.0275127860111\n",
      "\n",
      "Iteration: 465\n",
      "P: [ 6.31243375 -5.10592755  0.94204211  9.22940743]\n",
      "Loss: 15.015778446929827\n",
      "\n",
      "Iteration: 466\n",
      "P: [ 6.31951263 -5.10451429  0.9469721   9.26354966]\n",
      "Loss: 15.009769751515606\n",
      "\n",
      "Iteration: 467\n",
      "P: [ 6.32101145 -5.10418818  0.94803372  9.27087564]\n",
      "Loss: 15.008363443256462\n",
      "\n",
      "Iteration: 468\n",
      "P: [ 6.32495687 -5.103402    0.95078455  9.28992848]\n",
      "Loss: 15.005930349677365\n",
      "\n",
      "Iteration: 469\n",
      "P: [ 6.32796539 -5.10278905  0.95289115  9.30450609]\n",
      "Loss: 15.00485033376182\n",
      "\n",
      "Iteration: 470\n",
      "P: [ 6.33207941 -5.1019063   0.95580118  9.32459988]\n",
      "Loss: 15.002683618770698\n",
      "\n",
      "Iteration: 471\n",
      "P: [ 6.33254106 -5.10179489  0.95613611  9.32690058]\n",
      "Loss: 15.00222087520652\n",
      "\n",
      "Iteration: 472\n",
      "P: [ 6.33386983 -5.10150932  0.95707684  9.33339602]\n",
      "Loss: 15.001756578112674\n",
      "\n",
      "Iteration: 473\n",
      "P: [ 6.33564553 -5.10112641  0.95833498  9.34208174]\n",
      "Loss: 15.001367701893424\n",
      "\n",
      "Iteration: 474\n",
      "P: [ 6.33683034 -5.10086766  0.95917753  9.34789538]\n",
      "Loss: 15.00111040206986\n",
      "\n",
      "Iteration: 475\n",
      "P: [ 6.33855126 -5.10049254  0.96040368  9.3563572 ]\n",
      "Loss: 15.000547605879026\n",
      "\n",
      "Iteration: 476\n",
      "P: [ 6.33940141 -5.10030819  0.96100811  9.36052927]\n",
      "Loss: 15.000414853706998\n",
      "\n",
      "Iteration: 477\n",
      "P: [ 6.34003393 -5.10017135  0.96145809  9.36363567]\n",
      "Loss: 15.000345707423396\n",
      "\n",
      "Iteration: 478\n",
      "P: [ 6.34100913 -5.09996167  0.96215188  9.36842661]\n",
      "Loss: 15.00021067958423\n",
      "\n",
      "Iteration: 479\n",
      "P: [ 6.34040873 -5.10026421  0.96161888  9.36492358]\n",
      "Loss: 14.999586969970343\n",
      "\n",
      "Iteration: 480\n",
      "P: [ 6.3400962  -5.1006      0.96123192  9.36252642]\n",
      "Loss: 14.999130744247802\n",
      "\n",
      "Iteration: 481\n",
      "P: [ 6.34120118 -5.10058654  0.9618808   9.36723665]\n",
      "Loss: 14.998087752878769\n",
      "\n",
      "Iteration: 482\n",
      "P: [ 6.34147712 -5.10061511  0.96202328  9.36831049]\n",
      "Loss: 14.997948477276767\n",
      "\n",
      "Iteration: 483\n",
      "P: [ 6.34146455 -5.10084896  0.96187214  9.36750332]\n",
      "Loss: 14.99749945784852\n",
      "\n",
      "Iteration: 484\n",
      "P: [ 6.34142963 -5.10113287  0.96167709  9.36643917]\n",
      "Loss: 14.997168239447154\n",
      "\n",
      "Iteration: 485\n",
      "P: [ 6.34180163 -5.10143653  0.96170589  9.36703071]\n",
      "Loss: 14.996983614542794\n",
      "\n",
      "Iteration: 486\n",
      "P: [ 6.34177143 -5.10144552  0.96168227  9.36687011]\n",
      "Loss: 14.99697515268843\n",
      "\n",
      "Iteration: 487\n",
      "P: [ 6.34173901 -5.10143119  0.96167058  9.36676767]\n",
      "Loss: 14.996951960496977\n",
      "\n",
      "Iteration: 488\n",
      "P: [ 6.34155836 -5.10139016  0.9615708   9.36599744]\n",
      "Loss: 14.996735456814848\n",
      "\n",
      "Iteration: 489\n",
      "P: [ 6.34140532 -5.10138886  0.96144487  9.36509384]\n",
      "Loss: 14.996425087715785\n",
      "\n",
      "Iteration: 490\n",
      "P: [ 6.34138012 -5.10137434  0.9613813   9.36463615]\n",
      "Loss: 14.995936809110004\n",
      "\n",
      "Iteration: 491\n",
      "P: [ 6.34243024 -5.10135501  0.96182698  9.36793159]\n",
      "Loss: 14.994681368366736\n",
      "\n",
      "Iteration: 492\n",
      "P: [ 6.34319266 -5.10215356  0.96158594  9.36725799]\n",
      "Loss: 14.991098923515572\n",
      "\n",
      "Iteration: 493\n",
      "P: [ 6.34386631 -5.10269554  0.96150036  9.3673745 ]\n",
      "Loss: 14.989673978009767\n",
      "\n",
      "Iteration: 494\n",
      "P: [ 6.34750624 -5.10517176  0.96152731  9.37091502]\n",
      "Loss: 14.979659846274503\n",
      "\n",
      "Iteration: 495\n",
      "P: [ 6.34977563 -5.10675952  0.96146159  9.37259898]\n",
      "Loss: 14.976445845214414\n",
      "\n",
      "Iteration: 496\n",
      "P: [ 6.35819963 -5.1129146   0.96102825  9.37780961]\n",
      "Loss: 14.95157304535627\n",
      "\n",
      "Iteration: 497\n",
      "P: [ 6.36154339 -5.11526057  0.96088197  9.37995732]\n",
      "Loss: 14.945201918458649\n",
      "\n",
      "Iteration: 498\n",
      "P: [ 6.36526463 -5.11777919  0.96075819  9.3825234 ]\n",
      "Loss: 14.937366315711138\n",
      "\n",
      "Iteration: 499\n",
      "P: [ 6.38119661 -5.1285946   0.96026554  9.3937993 ]\n",
      "Loss: 14.901333059701889\n",
      "\n",
      "Iteration: 500\n",
      "P: [ 6.39024885 -5.1346371   0.96001509  9.40030592]\n",
      "Loss: 14.879784160120256\n",
      "\n",
      "Iteration: 501\n",
      "P: [ 6.41007198 -5.14721453  0.95962059  9.41495736]\n",
      "Loss: 14.8307855851597\n",
      "\n",
      "Iteration: 502\n",
      "P: [ 6.42492867 -5.15555795  0.95959405  9.42670621]\n",
      "Loss: 14.775231612981704\n",
      "\n",
      "Iteration: 503\n",
      "P: [ 6.44895744 -5.17256008  0.95885862  9.44446835]\n",
      "Loss: 14.70280248077819\n",
      "\n",
      "Iteration: 504\n",
      "P: [ 6.45458511 -5.17631102  0.95872438  9.4486571 ]\n",
      "Loss: 14.690857874724015\n",
      "\n",
      "Iteration: 505\n",
      "P: [ 6.47128325 -5.18701802  0.9584451   9.46148324]\n",
      "Loss: 14.678262259990806\n",
      "\n",
      "Iteration: 506\n",
      "P: [ 6.47918626 -5.19146885  0.95845635  9.46792316]\n",
      "Loss: 14.64558033798488\n",
      "\n",
      "Iteration: 507\n",
      "P: [ 6.4809552  -5.19240804  0.95850245  9.46961477]\n",
      "Loss: 14.610936251806061\n",
      "\n",
      "Iteration: 508\n",
      "P: [ 6.50721631 -5.20837154  0.95836153  9.49098486]\n",
      "Loss: 14.537991013506034\n",
      "\n",
      "Iteration: 509\n",
      "P: [ 6.52999303 -5.2224228   0.95820181  9.50947253]\n",
      "Loss: 14.493665973214359\n",
      "\n",
      "Iteration: 510\n",
      "P: [ 6.59047387 -5.25976361  0.95782589  9.55894156]\n",
      "Loss: 14.41118187181325\n",
      "\n",
      "Iteration: 511\n",
      "P: [ 6.60433689 -5.2683165   0.95773529  9.57024212]\n",
      "Loss: 14.384419574755833\n",
      "\n",
      "Iteration: 512\n",
      "P: [ 6.60870023 -5.27062472  0.95780061  9.57406247]\n",
      "Loss: 14.37222358670836\n",
      "\n",
      "Iteration: 513\n",
      "P: [ 6.62158848 -5.27804427  0.9578487   9.58495007]\n",
      "Loss: 14.353105554914654\n",
      "\n",
      "Iteration: 514\n",
      "P: [ 6.62763023 -5.28138995  0.95790252  9.59013686]\n",
      "Loss: 14.347343532056177\n",
      "\n",
      "Iteration: 515\n",
      "P: [ 6.63284759 -5.28407909  0.95799576  9.59473796]\n",
      "Loss: 14.334227742540167\n",
      "\n",
      "Iteration: 516\n",
      "P: [ 6.6423001  -5.28869175  0.9582248   9.60322845]\n",
      "Loss: 14.311777125581637\n",
      "\n",
      "Iteration: 517\n",
      "P: [ 6.64530241 -5.29022012  0.95828278  9.6058868 ]\n",
      "Loss: 14.306951978309213\n",
      "\n",
      "Iteration: 518\n",
      "P: [ 6.64859052 -5.29182343  0.95836257  9.60883972]\n",
      "Loss: 14.3030885262067\n",
      "\n",
      "Iteration: 519\n",
      "P: [ 6.6538024  -5.29421502  0.9585233   9.6136062 ]\n",
      "Loss: 14.296344881652002\n",
      "\n",
      "Iteration: 520\n",
      "P: [ 6.65794173 -5.29586708  0.95870714  9.61753046]\n",
      "Loss: 14.28184606634028\n",
      "\n",
      "Iteration: 521\n",
      "P: [ 6.66085575 -5.29710761  0.95881893  9.62024941]\n",
      "Loss: 14.278000970005273\n",
      "\n",
      "Iteration: 522\n",
      "P: [ 6.66394603 -5.29832767  0.9589592   9.62318675]\n",
      "Loss: 14.272644272177688\n",
      "\n",
      "Iteration: 523\n",
      "P: [ 6.66947676 -5.30019722  0.95928321  9.62863521]\n",
      "Loss: 14.258271784428638\n",
      "\n",
      "Iteration: 524\n",
      "P: [ 6.6739691  -5.30150051  0.95959645  9.63319299]\n",
      "Loss: 14.246717065235478\n",
      "\n",
      "Iteration: 525\n",
      "P: [ 6.67758259 -5.30248182  0.95986405  9.63690081]\n",
      "Loss: 14.239661499057854\n",
      "\n",
      "Iteration: 526\n",
      "P: [ 6.68323037 -5.30365137  0.96036683  9.642918  ]\n",
      "Loss: 14.225126241735175\n",
      "\n",
      "Iteration: 527\n",
      "P: [ 6.68683678 -5.30168346  0.96130529  9.64833876]\n",
      "Loss: 14.199547210769484\n",
      "\n",
      "Iteration: 528\n",
      "P: [ 6.68947525 -5.30002143  0.96204857  9.65247989]\n",
      "Loss: 14.184822358670637\n",
      "\n",
      "Iteration: 529\n",
      "P: [ 6.68966711 -5.3003593   0.96199909  9.65251991]\n",
      "Loss: 14.182974971766782\n",
      "\n",
      "Iteration: 530\n",
      "P: [ 6.69309367 -5.30095815  0.96233215  9.65625588]\n",
      "Loss: 14.179201939392279\n",
      "\n",
      "Iteration: 531\n",
      "P: [ 6.69470843 -5.30129499  0.96247725  9.65798884]\n",
      "Loss: 14.178244523856742\n",
      "\n",
      "Iteration: 532\n",
      "P: [ 6.69643852 -5.30161428  0.9626442   9.65988458]\n",
      "Loss: 14.175725097457157\n",
      "\n",
      "Iteration: 533\n",
      "P: [ 6.69853507 -5.30225398  0.9627894   9.66203766]\n",
      "Loss: 14.172868045009695\n",
      "\n",
      "Iteration: 534\n",
      "P: [ 6.69964373 -5.30256013  0.96287351  9.663195  ]\n",
      "Loss: 14.171897036725445\n",
      "\n",
      "Iteration: 535\n",
      "P: [ 6.70268318 -5.30339332  0.96310833  9.66639245]\n",
      "Loss: 14.168606193921608\n",
      "\n",
      "Iteration: 536\n",
      "P: [ 6.70495408 -5.30404269  0.96328286  9.66880747]\n",
      "Loss: 14.165931758720207\n",
      "\n",
      "Iteration: 537\n",
      "P: [ 6.7060379  -5.30433648  0.96336873  9.66996094]\n",
      "Loss: 14.16542592858904\n",
      "\n",
      "Iteration: 538\n",
      "P: [ 6.70827165 -5.30488551  0.96356284  9.67240454]\n",
      "Loss: 14.163827097303583\n",
      "\n",
      "Iteration: 539\n",
      "P: [ 6.70976485 -5.3052065   0.96370745  9.67409942]\n",
      "Loss: 14.161289593587982\n",
      "\n",
      "Iteration: 540\n",
      "P: [ 6.71111589 -5.30552012  0.96383072  9.67560136]\n",
      "Loss: 14.160303847132484\n",
      "\n",
      "Iteration: 541\n",
      "P: [ 6.71223915 -5.305775    0.96393548  9.67686094]\n",
      "Loss: 14.159736467248528\n",
      "\n",
      "Iteration: 542\n",
      "P: [ 6.71352877 -5.30604856  0.96406208  9.67833398]\n",
      "Loss: 14.158518478844732\n",
      "\n",
      "Iteration: 543\n",
      "P: [ 6.71524747 -5.30650849  0.96421701  9.68030856]\n",
      "Loss: 14.156330232680949\n",
      "\n",
      "Iteration: 544\n",
      "P: [ 6.71664009 -5.30685711  0.96434494  9.68189676]\n",
      "Loss: 14.155500222807506\n",
      "\n",
      "Iteration: 545\n",
      "P: [ 6.71860964 -5.3073914   0.96452153  9.68416129]\n",
      "Loss: 14.154714565719054\n",
      "\n",
      "Iteration: 546\n",
      "P: [ 6.71949975 -5.30768692  0.96459557  9.68520826]\n",
      "Loss: 14.152712667677566\n",
      "\n",
      "Iteration: 547\n",
      "P: [ 6.72060835 -5.30801389  0.96469227  9.68649516]\n",
      "Loss: 14.151910374790415\n",
      "\n",
      "Iteration: 548\n",
      "P: [ 6.72195418 -5.3084181   0.96480935  9.68806464]\n",
      "Loss: 14.151154776139888\n",
      "\n",
      "Iteration: 549\n",
      "P: [ 6.72391051 -5.30903117  0.96497791  9.69036652]\n",
      "Loss: 14.150039431057037\n",
      "\n",
      "Iteration: 550\n",
      "P: [ 6.7253467  -5.30950956  0.96510255  9.69210262]\n",
      "Loss: 14.148323175309288\n",
      "\n",
      "Iteration: 551\n",
      "P: [ 6.72669178 -5.30993859  0.96521947  9.69370427]\n",
      "Loss: 14.147590168490284\n",
      "\n",
      "Iteration: 552\n",
      "P: [ 6.72769361 -5.31026273  0.96530677  9.69490537]\n",
      "Loss: 14.147247871771775\n",
      "\n",
      "Iteration: 553\n",
      "P: [ 6.72894192 -5.31067882  0.96541567  9.6964197 ]\n",
      "Loss: 14.14654537482418\n",
      "\n",
      "Iteration: 554\n",
      "P: [ 6.73141113 -5.31210473  0.96555436  9.69960656]\n",
      "Loss: 14.145250823018023\n",
      "\n",
      "Iteration: 555\n",
      "P: [ 6.73410019 -5.31328372  0.96575201  9.70295049]\n",
      "Loss: 14.144641802022184\n",
      "\n",
      "Iteration: 556\n",
      "P: [ 6.73531505 -5.313779    0.96584662  9.70445418]\n",
      "Loss: 14.144608142830663\n",
      "\n",
      "Iteration: 557\n",
      "P: [ 6.73568213 -5.31400026  0.96586651  9.70493477]\n",
      "Loss: 14.14456220109559\n",
      "\n",
      "Iteration: 558\n",
      "P: [ 6.73509761 -5.31366048  0.96583466  9.7041856 ]\n",
      "Loss: 14.144483600931048\n",
      "\n",
      "Iteration: 559\n",
      "P: [ 6.73486303 -5.31335916  0.96584543  9.70385461]\n",
      "Loss: 14.144299748632633\n",
      "\n",
      "Iteration: 560\n",
      "P: [ 6.7346863  -5.31294152  0.96588127  9.7035748 ]\n",
      "Loss: 14.14405774271878\n",
      "\n",
      "Iteration: 561\n",
      "P: [ 6.73358326 -5.3119584   0.96587283  9.70212313]\n",
      "Loss: 14.143869115503277\n",
      "\n",
      "Iteration: 562\n",
      "P: [ 6.73404893 -5.31204253  0.96592576  9.70269397]\n",
      "Loss: 14.143753547071471\n",
      "\n",
      "Iteration: 563\n",
      "P: [ 6.73519023 -5.31264192  0.9659993   9.70416464]\n",
      "Loss: 14.143397675999658\n",
      "\n",
      "Iteration: 564\n",
      "P: [ 6.73917829 -5.31437985  0.96631745  9.70933103]\n",
      "Loss: 14.142369758929844\n",
      "\n",
      "Iteration: 565\n",
      "P: [ 6.739946   -5.31452768  0.9664078   9.71031307]\n",
      "Loss: 14.14216597460173\n",
      "\n",
      "Iteration: 566\n",
      "P: [ 6.74131212 -5.31480001  0.96657518  9.71213389]\n",
      "Loss: 14.141313125135719\n",
      "\n",
      "Iteration: 567\n",
      "P: [ 6.74413642 -5.31475736  0.96704832  9.71615433]\n",
      "Loss: 14.138017511247961\n",
      "\n",
      "Iteration: 568\n",
      "P: [ 6.74696189 -5.3143364   0.9676296   9.72059638]\n",
      "Loss: 14.13246627941413\n",
      "\n",
      "Iteration: 569\n",
      "P: [ 6.74804889 -5.31436952  0.96780832  9.72218675]\n",
      "Loss: 14.131060784294261\n",
      "\n",
      "Iteration: 570\n",
      "P: [ 6.75183188 -5.31521104  0.9682867   9.72749458]\n",
      "Loss: 14.129419760834272\n",
      "\n",
      "Iteration: 571\n",
      "P: [ 6.75453477 -5.31625331  0.9685436   9.73117055]\n",
      "Loss: 14.12727821617006\n",
      "\n",
      "Iteration: 572\n",
      "P: [ 6.75694565 -5.31690482  0.96883088  9.734565  ]\n",
      "Loss: 14.12581021364441\n",
      "\n",
      "Iteration: 573\n",
      "P: [ 6.75796288 -5.31626462  0.96914415  9.73637984]\n",
      "Loss: 14.123644444056998\n",
      "\n",
      "Iteration: 574\n",
      "P: [ 6.76976935 -5.31996172  0.97046913  9.75302236]\n",
      "Loss: 14.12011921131156\n",
      "\n",
      "Iteration: 575\n",
      "P: [ 6.77132798 -5.32051766  0.97063287  9.75521996]\n",
      "Loss: 14.118677307927486\n",
      "\n",
      "Iteration: 576\n",
      "P: [ 6.77303524 -5.31993761  0.97107536  9.75825335]\n",
      "Loss: 14.113952569305896\n",
      "\n",
      "Iteration: 577\n",
      "P: [ 6.77572831 -5.32042756  0.97146063  9.76228198]\n",
      "Loss: 14.112738010323318\n",
      "\n",
      "Iteration: 578\n",
      "P: [ 6.78085281 -5.32093081  0.97229952  9.77027835]\n",
      "Loss: 14.108526694520682\n",
      "\n",
      "Iteration: 579\n",
      "P: [ 6.79402322 -5.32403137  0.97407999  9.79012754]\n",
      "Loss: 14.102640071616337\n",
      "\n",
      "Iteration: 580\n",
      "P: [ 6.79803385 -5.32495081  0.97462487  9.79615717]\n",
      "Loss: 14.099494038100465\n",
      "\n",
      "Iteration: 581\n",
      "P: [ 6.79950983 -5.325108    0.97486796  9.79849602]\n",
      "Loss: 14.098608917467622\n",
      "\n",
      "Iteration: 582\n",
      "P: [ 6.79918202 -5.32428518  0.97499698  9.79847663]\n",
      "Loss: 14.096951192241258\n",
      "\n",
      "Iteration: 583\n",
      "P: [ 6.7996985  -5.32424986  0.97510562  9.79937947]\n",
      "Loss: 14.09611744437997\n",
      "\n",
      "Iteration: 584\n",
      "P: [ 6.80622281 -5.3250757   0.97616716  9.80981628]\n",
      "Loss: 14.092890628038157\n",
      "\n",
      "Iteration: 585\n",
      "P: [ 6.81551094 -5.32708451  0.97748959  9.82419544]\n",
      "Loss: 14.089765700968675\n",
      "\n",
      "Iteration: 586\n",
      "P: [ 6.81708312 -5.32752942  0.97769318  9.82660651]\n",
      "Loss: 14.087566493021454\n",
      "\n",
      "Iteration: 587\n",
      "P: [ 6.81930169 -5.32789298  0.97803832  9.83013889]\n",
      "Loss: 14.086583413441371\n",
      "\n",
      "Iteration: 588\n",
      "P: [ 6.82176503 -5.3282848   0.97842467  9.83407247]\n",
      "Loss: 14.085847962089819\n",
      "\n",
      "Iteration: 589\n",
      "P: [ 6.82376401 -5.32834284  0.97880107  9.83745633]\n",
      "Loss: 14.085192861987847\n",
      "\n",
      "Iteration: 590\n",
      "P: [ 6.82400597 -5.32819157  0.97888658  9.83800244]\n",
      "Loss: 14.08446301931498\n",
      "\n",
      "Iteration: 591\n",
      "P: [ 6.82712522 -5.32884563  0.97934217  9.84291861]\n",
      "Loss: 14.083087651344094\n",
      "\n",
      "Iteration: 592\n",
      "P: [ 6.83112937 -5.32957481  0.9799534   9.84930807]\n",
      "Loss: 14.082302469270767\n",
      "\n",
      "Iteration: 593\n",
      "P: [ 6.83358036 -5.33014402  0.98030158  9.85317322]\n",
      "Loss: 14.08068116846916\n",
      "\n",
      "Iteration: 594\n",
      "P: [ 6.83614233 -5.33063269  0.98068963  9.85727285]\n",
      "Loss: 14.08002402917956\n",
      "\n",
      "Iteration: 595\n",
      "P: [ 6.83916944 -5.33115407  0.98116314  9.86217655]\n",
      "Loss: 14.078934129872508\n",
      "\n",
      "Iteration: 596\n",
      "P: [ 6.84353864 -5.33236261  0.98174477  9.86904713]\n",
      "Loss: 14.076504084519966\n",
      "\n",
      "Iteration: 597\n",
      "P: [ 6.84706586 -5.33317932  0.98225019  9.8746742 ]\n",
      "Loss: 14.075343586003958\n",
      "\n",
      "Iteration: 598\n",
      "P: [ 6.85183368 -5.33413715  0.98296654  9.88235498]\n",
      "Loss: 14.074016062151602\n",
      "\n",
      "Iteration: 599\n",
      "P: [ 6.85512086 -5.33469046  0.98348749  9.88774919]\n",
      "Loss: 14.072996231216711\n",
      "\n",
      "Iteration: 600\n",
      "P: [ 6.86686272 -5.33643706  0.98540933  9.9072819 ]\n",
      "Loss: 14.069541269862555\n",
      "\n",
      "Iteration: 601\n",
      "P: [ 6.8675559  -5.33648327  0.98553893  9.90851922]\n",
      "Loss: 14.067660065733335\n",
      "\n",
      "Iteration: 602\n",
      "P: [ 6.87307476 -5.33794269  0.98629066  9.91727146]\n",
      "Loss: 14.06577932494676\n",
      "\n",
      "Iteration: 603\n",
      "P: [ 6.87470341 -5.33827541  0.98653598  9.91992385]\n",
      "Loss: 14.065436510459959\n",
      "\n",
      "Iteration: 604\n",
      "P: [ 6.87761386 -5.33875928  0.98700156  9.92475486]\n",
      "Loss: 14.064904093573706\n",
      "\n",
      "Iteration: 605\n",
      "P: [ 6.87969082 -5.33893233  0.98737581  9.92834006]\n",
      "Loss: 14.063917712305605\n",
      "\n",
      "Iteration: 606\n",
      "P: [ 6.88455201 -5.33998467  0.98809602  9.93627542]\n",
      "Loss: 14.062266703658212\n",
      "\n",
      "Iteration: 607\n",
      "P: [ 6.89310928 -5.34193839  0.98934015  9.95021149]\n",
      "Loss: 14.060107393708282\n",
      "\n",
      "Iteration: 608\n",
      "P: [ 6.89489061 -5.34231812  0.98960552  9.95312754]\n",
      "Loss: 14.05956433989577\n",
      "\n",
      "Iteration: 609\n",
      "P: [ 6.89779357 -5.34288668  0.9900502   9.95792116]\n",
      "Loss: 14.05911295267127\n",
      "\n",
      "Iteration: 610\n",
      "P: [ 6.89879852 -5.34290114  0.99024805  9.95971968]\n",
      "Loss: 14.058190802725125\n",
      "\n",
      "Iteration: 611\n",
      "P: [ 6.91007807 -5.34561797  0.99184852  9.97807292]\n",
      "Loss: 14.053910339739991\n",
      "\n",
      "Iteration: 612\n",
      "P: [ 6.91267553 -5.3461828   0.99223205  9.98233856]\n",
      "Loss: 14.053329859241146\n",
      "\n",
      "Iteration: 613\n",
      "P: [ 6.91664017 -5.34706079  0.99281286  9.98884924]\n",
      "Loss: 14.052318901554694\n",
      "\n",
      "Iteration: 614\n",
      "P: [ 6.92626242 -5.34911912  0.99423835 10.00472207]\n",
      "Loss: 14.049837489607295\n",
      "\n",
      "Iteration: 615\n",
      "P: [ 6.92873711 -5.34965825  0.99460108 10.00881006]\n",
      "Loss: 14.048097213832127\n",
      "\n",
      "Iteration: 616\n",
      "P: [ 6.93337684 -5.35069543  0.9952769  10.01643711]\n",
      "Loss: 14.046764901136264\n",
      "\n",
      "Iteration: 617\n",
      "P: [ 6.93482586 -5.35101383  0.99548921 10.01882373]\n",
      "Loss: 14.046560735659298\n",
      "\n",
      "Iteration: 618\n",
      "P: [ 6.93722815 -5.35157972  0.99583129 10.02275496]\n",
      "Loss: 14.045995263840988\n",
      "\n",
      "Iteration: 619\n",
      "P: [ 6.94416666 -5.35326323  0.99680495 10.0340763 ]\n",
      "Loss: 14.04418201997955\n",
      "\n",
      "Iteration: 620\n",
      "P: [ 6.95028295 -5.3549304   0.99761349 10.04392422]\n",
      "Loss: 14.042070552719013\n",
      "\n",
      "Iteration: 621\n",
      "P: [ 6.95521841 -5.35613029  0.99830357 10.05197607]\n",
      "Loss: 14.040532016110452\n",
      "\n",
      "Iteration: 622\n",
      "P: [ 6.95666906 -5.35647846  0.99850708 10.05434596]\n",
      "Loss: 14.040295457869016\n",
      "\n",
      "Iteration: 623\n",
      "P: [ 6.9599754  -5.35722144  0.9989811  10.05978356]\n",
      "Loss: 14.03878824898221\n",
      "\n",
      "Iteration: 624\n",
      "P: [ 6.96603578 -5.35846941  0.9998732  10.06982944]\n",
      "Loss: 14.036601392380934\n",
      "\n",
      "Iteration: 625\n",
      "P: [ 6.96814272 -5.35896472  1.00016972 10.07327814]\n",
      "Loss: 14.035981300586384\n",
      "\n",
      "Iteration: 626\n",
      "P: [ 6.97068516 -5.35967144  1.00050076 10.0773596 ]\n",
      "Loss: 14.035222049881964\n",
      "\n",
      "Iteration: 627\n",
      "P: [ 6.97209759 -5.36035529  1.00061421 10.07941385]\n",
      "Loss: 14.03438469618427\n",
      "\n",
      "Iteration: 628\n",
      "P: [ 6.97428937 -5.36084631  1.00092712 10.0830175 ]\n",
      "Loss: 14.033711740124525\n",
      "\n",
      "Iteration: 629\n",
      "P: [ 6.97568347 -5.36109531  1.00114037 10.0853545 ]\n",
      "Loss: 14.032967282792429\n",
      "\n",
      "Iteration: 630\n",
      "P: [ 6.98327861 -5.36337747  1.0020675  10.09736426]\n",
      "Loss: 14.028440979371586\n",
      "\n",
      "Iteration: 631\n",
      "P: [ 6.98529477 -5.36398671  1.00231321 10.10055084]\n",
      "Loss: 14.027505403244346\n",
      "\n",
      "Iteration: 632\n",
      "P: [ 6.99337208 -5.36652133  1.0032692  10.11323052]\n",
      "Loss: 14.023383472226255\n",
      "\n",
      "Iteration: 633\n",
      "P: [ 6.99940497 -5.36842379  1.00397815 10.12268485]\n",
      "Loss: 14.020766709747841\n",
      "\n",
      "Iteration: 634\n",
      "P: [ 7.01771532 -5.37449765  1.00604085 10.15110517]\n",
      "Loss: 14.016808882141317\n",
      "\n",
      "Iteration: 635\n",
      "P: [ 7.01776019 -5.37452619  1.00603736 10.15114602]\n",
      "Loss: 14.014289357540548\n",
      "\n",
      "Iteration: 636\n",
      "P: [ 7.02095502 -5.37536402  1.00644696 10.15625362]\n",
      "Loss: 14.011207510504807\n",
      "\n",
      "Iteration: 637\n",
      "P: [ 7.023812   -5.37615245  1.00680253 10.16078785]\n",
      "Loss: 14.008766751328094\n",
      "\n",
      "Iteration: 638\n",
      "P: [ 7.02544677 -5.3765985   1.00700646 10.16338306]\n",
      "Loss: 14.00764884646127\n",
      "\n",
      "Iteration: 639\n",
      "P: [ 7.03001147 -5.37796498  1.0075423  10.17052349]\n",
      "Loss: 14.004019513549208\n",
      "\n",
      "Iteration: 640\n",
      "P: [ 7.03369544 -5.37898381  1.00798609 10.17631265]\n",
      "Loss: 13.999720515970893\n",
      "\n",
      "Iteration: 641\n",
      "P: [ 7.03710617 -5.38007421  1.00837048 10.18159979]\n",
      "Loss: 13.997769272115084\n",
      "\n",
      "Iteration: 642\n",
      "P: [ 7.03910041 -5.38071403  1.00859423 10.18468772]\n",
      "Loss: 13.996791437037947\n",
      "\n",
      "Iteration: 643\n",
      "P: [ 7.04238377 -5.38178483  1.00895762 10.18975568]\n",
      "Loss: 13.995434098455958\n",
      "\n",
      "Iteration: 644\n",
      "P: [ 7.04738881 -5.38347472  1.00949593 10.19743154]\n",
      "Loss: 13.99359056584062\n",
      "\n",
      "Iteration: 645\n",
      "P: [ 7.05072046 -5.38469267  1.00982866 10.20245943]\n",
      "Loss: 13.989351216625026\n",
      "\n",
      "Iteration: 646\n",
      "P: [ 7.05570486 -5.38637782  1.01035943 10.2100824 ]\n",
      "Loss: 13.987000716903907\n",
      "\n",
      "Iteration: 647\n",
      "P: [ 7.0640637  -5.38916112  1.01125139 10.22286254]\n",
      "Loss: 13.982716140288412\n",
      "\n",
      "Iteration: 648\n",
      "P: [ 7.06763052 -5.39032669  1.01162999 10.22830154]\n",
      "Loss: 13.977946654816057\n",
      "\n",
      "Iteration: 649\n",
      "P: [ 7.07137894 -5.39159079  1.01202392 10.23401154]\n",
      "Loss: 13.975517759722162\n",
      "\n",
      "Iteration: 650\n",
      "P: [ 7.07209873 -5.39183433  1.01209923 10.2351068 ]\n",
      "Loss: 13.975148678534419\n",
      "\n",
      "Iteration: 651\n",
      "P: [ 7.07511802 -5.39286358  1.01241268 10.23969286]\n",
      "Loss: 13.973876576045237\n",
      "\n",
      "Iteration: 652\n",
      "P: [ 7.07805775 -5.39389358  1.01271013 10.24413294]\n",
      "Loss: 13.972536619321243\n",
      "\n",
      "Iteration: 653\n",
      "P: [ 7.08230544 -5.39546035  1.01311877 10.25048025]\n",
      "Loss: 13.96868248811313\n",
      "\n",
      "Iteration: 654\n",
      "P: [ 7.08638082 -5.39704104  1.01348946 10.25650016]\n",
      "Loss: 13.964602619745328\n",
      "\n",
      "Iteration: 655\n",
      "P: [ 7.09097838 -5.39874552  1.01392852 10.26335854]\n",
      "Loss: 13.962941767524873\n",
      "\n",
      "Iteration: 656\n",
      "P: [ 7.09350166 -5.39972762  1.01415531 10.26707462]\n",
      "Loss: 13.960616205676184\n",
      "\n",
      "Iteration: 657\n",
      "P: [ 7.09968178 -5.40209153  1.01471989 10.27620293]\n",
      "Loss: 13.957366649550208\n",
      "\n",
      "Iteration: 658\n",
      "P: [ 7.10879123 -5.40543818  1.01556329 10.28965783]\n",
      "Loss: 13.947117545590375\n",
      "\n",
      "Iteration: 659\n",
      "P: [ 7.11038733 -5.40602951  1.01571121 10.29201784]\n",
      "Loss: 13.945877638672917\n",
      "\n",
      "Iteration: 660\n",
      "P: [ 7.11345608 -5.40715208  1.01599657 10.29655434]\n",
      "Loss: 13.943520873265422\n",
      "\n",
      "Iteration: 661\n",
      "P: [ 7.11678859 -5.4083655   1.01630613 10.30147706]\n",
      "Loss: 13.941397612516813\n",
      "\n",
      "Iteration: 662\n",
      "P: [ 7.1225077  -5.41042395  1.01683727 10.30991519]\n",
      "Loss: 13.93746706435809\n",
      "\n",
      "Iteration: 663\n",
      "P: [ 7.12753233 -5.41218536  1.01730455 10.31731289]\n",
      "Loss: 13.93187430567753\n",
      "\n",
      "Iteration: 664\n",
      "P: [ 7.13050647 -5.41328123  1.01757393 10.32167872]\n",
      "Loss: 13.929963924190881\n",
      "\n",
      "Iteration: 665\n",
      "P: [ 7.13292611 -5.41419851  1.01778695 10.32521175]\n",
      "Loss: 13.928931820301548\n",
      "\n",
      "Iteration: 666\n",
      "P: [ 7.1353501  -5.41518655  1.01798499 10.32870589]\n",
      "Loss: 13.926670495671907\n",
      "\n",
      "Iteration: 667\n",
      "P: [ 7.14041169 -5.41743097  1.01835798 10.33588208]\n",
      "Loss: 13.920262196986508\n",
      "\n",
      "Iteration: 668\n",
      "P: [ 7.14469013 -5.41929248  1.01866646 10.34189713]\n",
      "Loss: 13.914971279393765\n",
      "\n",
      "Iteration: 669\n",
      "P: [ 7.15075033 -5.42189826  1.01910574 10.35041466]\n",
      "Loss: 13.908724465417437\n",
      "\n",
      "Iteration: 670\n",
      "P: [ 7.15884521 -5.42557046  1.01963355 10.36158375]\n",
      "Loss: 13.89732915857345\n",
      "\n",
      "Iteration: 671\n",
      "P: [ 7.16171544 -5.42683337  1.01983212 10.36558339]\n",
      "Loss: 13.894512289123735\n",
      "\n",
      "Iteration: 672\n",
      "P: [ 7.16469545 -5.42816031  1.02003148 10.36970906]\n",
      "Loss: 13.891432756800738\n",
      "\n",
      "Iteration: 673\n",
      "P: [ 7.16988828 -5.43050113  1.02036891 10.37686128]\n",
      "Loss: 13.886507590981772\n",
      "\n",
      "Iteration: 674\n",
      "P: [ 7.17984337 -5.43508085  1.02098331 10.39045171]\n",
      "Loss: 13.881906144689884\n",
      "\n",
      "Iteration: 675\n",
      "P: [ 7.18016426 -5.43532906  1.0209628  10.39073334]\n",
      "Loss: 13.869824805577219\n",
      "\n",
      "Iteration: 676\n",
      "P: [ 7.18742817 -5.4388135   1.0213629  10.40047317]\n",
      "Loss: 13.862119135987852\n",
      "\n",
      "Iteration: 677\n",
      "P: [ 7.193262   -5.44169833  1.02166411 10.40823469]\n",
      "Loss: 13.8573633794522\n",
      "\n",
      "Iteration: 678\n",
      "P: [ 7.19777346 -5.44401666  1.02187579 10.41417194]\n",
      "Loss: 13.845615566783119\n",
      "\n",
      "Iteration: 679\n",
      "P: [ 7.20655725 -5.44844779  1.02230856 10.42579643]\n",
      "Loss: 13.839219244527838\n",
      "\n",
      "Iteration: 680\n",
      "P: [ 7.21071516 -5.45059482  1.02250366 10.43127541]\n",
      "Loss: 13.828778696300683\n",
      "\n",
      "Iteration: 681\n",
      "P: [ 7.21938398 -5.45503877  1.02290991 10.44267741]\n",
      "Loss: 13.824510464395479\n",
      "\n",
      "Iteration: 682\n",
      "P: [ 7.21819904 -5.454478    1.0228389  10.44106347]\n",
      "Loss: 13.820783955464643\n",
      "\n",
      "Iteration: 683\n",
      "P: [ 7.22285852 -5.45694241  1.0230306  10.44709425]\n",
      "Loss: 13.815043144048166\n",
      "\n",
      "Iteration: 684\n",
      "P: [ 7.22478933 -5.45799565  1.02309929 10.44955405]\n",
      "Loss: 13.812693526712666\n",
      "\n",
      "Iteration: 685\n",
      "P: [ 7.22729366 -5.45939477  1.02317625 10.45269937]\n",
      "Loss: 13.809810357022766\n",
      "\n",
      "Iteration: 686\n",
      "P: [ 7.22844731 -5.46007768  1.02319324 10.45407454]\n",
      "Loss: 13.804797681064711\n",
      "\n",
      "Iteration: 687\n",
      "P: [ 7.23012684 -5.4608289   1.02327876 10.45627172]\n",
      "Loss: 13.795090176691202\n",
      "\n",
      "Iteration: 688\n",
      "P: [ 7.23618154 -5.46378941  1.02356215 10.46417614]\n",
      "Loss: 13.790908422189846\n",
      "\n",
      "Iteration: 689\n",
      "P: [ 7.23897089 -5.46487765  1.02377797 10.4681195 ]\n",
      "Loss: 13.780521779506694\n",
      "\n",
      "Iteration: 690\n",
      "P: [ 7.26652881 -5.47768346  1.02536279 10.50526035]\n",
      "Loss: 13.749808346305871\n",
      "\n",
      "Iteration: 691\n",
      "P: [ 7.27471333 -5.48141289  1.02584598 10.51632116]\n",
      "Loss: 13.744969757545997\n",
      "\n",
      "Iteration: 692\n",
      "P: [ 7.28963098 -5.48793772  1.02678645 10.53665967]\n",
      "Loss: 13.731753014718143\n",
      "\n",
      "Iteration: 693\n",
      "P: [ 7.30525945 -5.49415584  1.02788889 10.55827967]\n",
      "Loss: 13.708753567203908\n",
      "\n",
      "Iteration: 694\n",
      "P: [ 7.31348868 -5.49756719  1.02844525 10.56960389]\n",
      "Loss: 13.70429011699655\n",
      "\n",
      "Iteration: 695\n",
      "P: [ 7.32638216 -5.50251475  1.02939932 10.58758327]\n",
      "Loss: 13.692958035824795\n",
      "\n",
      "Iteration: 696\n",
      "P: [ 7.33495316 -5.50665795  1.02980968 10.59880483]\n",
      "Loss: 13.684460349108923\n",
      "\n",
      "Iteration: 697\n",
      "P: [ 7.34713708 -5.51267976  1.03033473 10.61453368]\n",
      "Loss: 13.662794118133222\n",
      "\n",
      "Iteration: 698\n",
      "P: [ 7.36290727 -5.51984309  1.03121155 10.63558315]\n",
      "Loss: 13.647525128744642\n",
      "\n",
      "Iteration: 699\n",
      "P: [ 7.37291395 -5.52407807  1.03184761 10.64919842]\n",
      "Loss: 13.638847123304778\n",
      "\n",
      "Iteration: 700\n",
      "P: [ 7.37930994 -5.52698301  1.03218881 10.657668  ]\n",
      "Loss: 13.629928159119848\n",
      "\n",
      "Iteration: 701\n",
      "P: [ 7.38840775 -5.5310918   1.03268366 10.66975008]\n",
      "Loss: 13.623310196957185\n",
      "\n",
      "Iteration: 702\n",
      "P: [ 7.41134152 -5.54148258  1.03390037 10.70007378]\n",
      "Loss: 13.616798525394147\n",
      "\n",
      "Iteration: 703\n",
      "P: [ 7.40909093 -5.54046379  1.03375167 10.6969581 ]\n",
      "Loss: 13.597919336359032\n",
      "\n",
      "Iteration: 704\n",
      "P: [ 7.4174025  -5.54374285  1.03429986 10.70826705]\n",
      "Loss: 13.585576730369308\n",
      "\n",
      "Iteration: 705\n",
      "P: [ 7.43419179 -5.55098168  1.03525526 10.73062937]\n",
      "Loss: 13.570270794763113\n",
      "\n",
      "Iteration: 706\n",
      "P: [ 7.44481084 -5.55549394  1.03587452 10.74481872]\n",
      "Loss: 13.564725732088272\n",
      "\n",
      "Iteration: 707\n",
      "P: [ 7.45551453 -5.55990431  1.03651669 10.75915268]\n",
      "Loss: 13.55439592232664\n",
      "\n",
      "Iteration: 708\n",
      "P: [ 7.46916941 -5.56640241  1.0371225  10.77677004]\n",
      "Loss: 13.53901306969968\n",
      "\n",
      "Iteration: 709\n",
      "P: [ 7.47740896 -5.56961068  1.03763603 10.78782206]\n",
      "Loss: 13.527492239888286\n",
      "\n",
      "Iteration: 710\n",
      "P: [ 7.49060738 -5.57528429  1.0383651  10.8052927 ]\n",
      "Loss: 13.51575642547755\n",
      "\n",
      "Iteration: 711\n",
      "P: [ 7.502648   -5.5805267   1.03900972 10.82116027]\n",
      "Loss: 13.507599447612208\n",
      "\n",
      "Iteration: 712\n",
      "P: [ 7.52106138 -5.58917215  1.03984083 10.84494273]\n",
      "Loss: 13.49089476770459\n",
      "\n",
      "Iteration: 713\n",
      "P: [ 7.5248254  -5.59096729  1.03999061 10.84971956]\n",
      "Loss: 13.483752205775238\n",
      "\n",
      "Iteration: 714\n",
      "P: [ 7.53508143 -5.59563504  1.04046815 10.86297589]\n",
      "Loss: 13.475989937352276\n",
      "\n",
      "Iteration: 715\n",
      "P: [ 7.55472073 -5.60424238  1.04144871 10.88854484]\n",
      "Loss: 13.462209409315433\n",
      "\n",
      "Iteration: 716\n",
      "P: [ 7.57388778 -5.61201239  1.04254469 10.91391136]\n",
      "Loss: 13.438465075525732\n",
      "\n",
      "Iteration: 717\n",
      "P: [ 7.58361165 -5.61580474  1.04307334 10.92659197]\n",
      "Loss: 13.424953835921519\n",
      "\n",
      "Iteration: 718\n",
      "P: [ 7.60300234 -5.62427175  1.0440332  10.9517876 ]\n",
      "Loss: 13.403773549845715\n",
      "\n",
      "Iteration: 719\n",
      "P: [ 7.6100555  -5.62723678  1.04440593 10.96101851]\n",
      "Loss: 13.39989019607575\n",
      "\n",
      "Iteration: 720\n",
      "P: [ 7.6176478  -5.63054979  1.04477632 10.97085763]\n",
      "Loss: 13.394425943794554\n",
      "\n",
      "Iteration: 721\n",
      "P: [ 7.64727689 -5.64403364  1.04607631 11.0087864 ]\n",
      "Loss: 13.381059680506105\n",
      "\n",
      "Iteration: 722\n",
      "P: [ 7.64888411 -5.64529616  1.04600964 11.0104056 ]\n",
      "Loss: 13.367637261711325\n",
      "\n",
      "Iteration: 723\n",
      "P: [ 7.65380346 -5.64770456  1.04617965 11.01655309]\n",
      "Loss: 13.364096576380494\n",
      "\n",
      "Iteration: 724\n",
      "P: [ 7.66910309 -5.6547445   1.0468185  11.03601653]\n",
      "Loss: 13.358009166783726\n",
      "\n",
      "Iteration: 725\n",
      "P: [ 7.68494002 -5.66176069  1.04753832 11.05633408]\n",
      "Loss: 13.353271363598344\n",
      "\n",
      "Iteration: 726\n",
      "P: [ 7.69713276 -5.66717848  1.04807127 11.07188239]\n",
      "Loss: 13.344491947020083\n",
      "\n",
      "Iteration: 727\n",
      "P: [ 7.72163871 -5.67754491  1.04920733 11.10323538]\n",
      "Loss: 13.32758758116634\n",
      "\n",
      "Iteration: 728\n",
      "P: [ 7.73780094 -5.68440849  1.04997048 11.12398913]\n",
      "Loss: 13.30853149092535\n",
      "\n",
      "Iteration: 729\n",
      "P: [ 7.74713721 -5.688249    1.05043038 11.13601924]\n",
      "Loss: 13.297478538520329\n",
      "\n",
      "Iteration: 730\n",
      "P: [ 7.75682441 -5.69084076  1.05114833 11.14909392]\n",
      "Loss: 13.269010213548153\n",
      "\n",
      "Iteration: 731\n",
      "P: [ 7.78997646 -5.70396786  1.05286474 11.19200524]\n",
      "Loss: 13.245021182797567\n",
      "\n",
      "Iteration: 732\n",
      "P: [ 7.78800717 -5.70305453  1.05278551 11.18951131]\n",
      "Loss: 13.244637723463851\n",
      "\n",
      "Iteration: 733\n",
      "P: [ 7.79228071 -5.70442681  1.05306119 11.19517487]\n",
      "Loss: 13.241419432772831\n",
      "\n",
      "Iteration: 734\n",
      "P: [ 7.7993478  -5.70702097  1.0534571  11.20438481]\n",
      "Loss: 13.239951373137272\n",
      "\n",
      "Iteration: 735\n",
      "P: [ 7.80188133 -5.70826661  1.05354053 11.20753414]\n",
      "Loss: 13.236252407833435\n",
      "\n",
      "Iteration: 736\n",
      "P: [ 7.80865218 -5.71117871  1.05383495 11.21612504]\n",
      "Loss: 13.229267394029199\n",
      "\n",
      "Iteration: 737\n",
      "P: [ 7.81368871 -5.71327115  1.0540696  11.22256019]\n",
      "Loss: 13.226312893492496\n",
      "\n",
      "Iteration: 738\n",
      "P: [ 7.82009027 -5.71592797  1.0543663  11.23073121]\n",
      "Loss: 13.22319147106119\n",
      "\n",
      "Iteration: 739\n",
      "P: [ 7.83152139 -5.7206512   1.05489465 11.24530729]\n",
      "Loss: 13.217355952653849\n",
      "\n",
      "Iteration: 740\n",
      "P: [ 7.84004275 -5.72418695  1.05527673 11.25612371]\n",
      "Loss: 13.20669546817556\n",
      "\n",
      "Iteration: 741\n",
      "P: [ 7.8468151  -5.72696942  1.05558956 11.26475237]\n",
      "Loss: 13.2019240282643\n",
      "\n",
      "Iteration: 742\n",
      "P: [ 7.85145477 -5.72887602  1.05580289 11.2706593 ]\n",
      "Loss: 13.200615629634378\n",
      "\n",
      "Iteration: 743\n",
      "P: [ 7.85397291 -5.72989191  1.05592015 11.27386484]\n",
      "Loss: 13.197558195819482\n",
      "\n",
      "Iteration: 744\n",
      "P: [ 7.8589418  -5.73191678  1.05614861 11.2801843 ]\n",
      "Loss: 13.19411325248277\n",
      "\n",
      "Iteration: 745\n",
      "P: [ 7.87280958 -5.73782453  1.05673122 11.29766189]\n",
      "Loss: 13.184465438999132\n",
      "\n",
      "Iteration: 746\n",
      "P: [ 7.88091811 -5.74146425  1.05702748 11.307744  ]\n",
      "Loss: 13.177642713235386\n",
      "\n",
      "Iteration: 747\n",
      "P: [ 7.89052537 -5.74564024  1.0574111  11.31979017]\n",
      "Loss: 13.16953920801208\n",
      "\n",
      "Iteration: 748\n",
      "P: [ 7.89479636 -5.74750791  1.05757881 11.32513638]\n",
      "Loss: 13.168506307673011\n",
      "\n",
      "Iteration: 749\n",
      "P: [ 7.89619507 -5.74814429  1.05762736 11.32686681]\n",
      "Loss: 13.166437375628096\n",
      "\n",
      "Iteration: 750\n",
      "P: [ 7.90957276 -5.75412711  1.05811775 11.34349936]\n",
      "Loss: 13.161557447257048\n",
      "\n",
      "Iteration: 751\n",
      "P: [ 7.90924855 -5.75401899  1.05809479 11.34305832]\n",
      "Loss: 13.156057050827949\n",
      "\n",
      "Iteration: 752\n",
      "P: [ 7.91800727 -5.75796593  1.05840556 11.35391108]\n",
      "Loss: 13.150534432257968\n",
      "\n",
      "Iteration: 753\n",
      "P: [ 7.92278819 -5.7601209   1.05857453 11.35983213]\n",
      "Loss: 13.148666718558937\n",
      "\n",
      "Iteration: 754\n",
      "P: [ 7.92849254 -5.76268864  1.0587748  11.36688921]\n",
      "Loss: 13.144894628584813\n",
      "\n",
      "Iteration: 755\n",
      "P: [ 7.94056695 -5.76789587  1.05925242 11.38199287]\n",
      "Loss: 13.137784230176448\n",
      "\n",
      "Iteration: 756\n",
      "P: [ 7.94103104 -5.76811425  1.05926596 11.38255768]\n",
      "Loss: 13.136919511299935\n",
      "\n",
      "Iteration: 757\n",
      "P: [ 7.94660579 -5.77061814  1.05946053 11.38944694]\n",
      "Loss: 13.133510943551721\n",
      "\n",
      "Iteration: 758\n",
      "P: [ 7.9573441  -5.77534832  1.05985417 11.4027707 ]\n",
      "Loss: 13.124881565998264\n",
      "\n",
      "Iteration: 759\n",
      "P: [ 7.96270319 -5.77773384  1.06004504 11.40940332]\n",
      "Loss: 13.122766278177965\n",
      "\n",
      "Iteration: 760\n",
      "P: [ 7.97673198 -5.78397102  1.06054151 11.42674801]\n",
      "Loss: 13.118099691066108\n",
      "\n",
      "Iteration: 761\n",
      "P: [ 7.97909137 -5.78501106  1.06062183 11.42964676]\n",
      "Loss: 13.109842858077078\n",
      "\n",
      "Iteration: 762\n",
      "P: [ 7.99085279 -5.79026608  1.06102647 11.44414357]\n",
      "Loss: 13.103948869972863\n",
      "\n",
      "Iteration: 763\n",
      "P: [ 7.99614552 -5.79256522  1.06122464 11.45071787]\n",
      "Loss: 13.101723705324071\n",
      "\n",
      "Iteration: 764\n",
      "P: [ 8.00625316 -5.79684918  1.0616133  11.46327943]\n",
      "Loss: 13.092506744674024\n",
      "\n",
      "Iteration: 765\n",
      "P: [ 8.01316072 -5.79980782  1.06187183 11.47184251]\n",
      "Loss: 13.089412176913429\n",
      "\n",
      "Iteration: 766\n",
      "P: [ 8.03110011 -5.80721819  1.06258846 11.49418868]\n",
      "Loss: 13.081149210617129\n",
      "\n",
      "Iteration: 767\n",
      "P: [ 8.03074595 -5.80677084  1.06261913 11.49384201]\n",
      "Loss: 13.069317784143763\n",
      "\n",
      "Iteration: 768\n",
      "P: [ 8.0339152  -5.80801663  1.06275342 11.49780135]\n",
      "Loss: 13.066074595828644\n",
      "\n",
      "Iteration: 769\n",
      "P: [ 8.04251257 -5.81139712  1.06312426 11.50857359]\n",
      "Loss: 13.060812388744298\n",
      "\n",
      "Iteration: 770\n",
      "P: [ 8.04746629 -5.8133455   1.06334065 11.51479364]\n",
      "Loss: 13.058592443534096\n",
      "\n",
      "Iteration: 771\n",
      "P: [ 8.05118434 -5.81471726  1.06351919 11.51950312]\n",
      "Loss: 13.054448644982342\n",
      "\n",
      "Iteration: 772\n",
      "P: [ 8.05807444 -5.81715062  1.0638635  11.52825168]\n",
      "Loss: 13.047552525832067\n",
      "\n",
      "Iteration: 773\n",
      "P: [ 8.06674169 -5.82046805  1.06424768 11.53912584]\n",
      "Loss: 13.039193008316582\n",
      "\n",
      "Iteration: 774\n",
      "P: [ 8.07352374 -5.82305468  1.06455147 11.54764598]\n",
      "Loss: 13.035167567683354\n",
      "\n",
      "Iteration: 775\n",
      "P: [ 8.07778117 -5.82468977  1.06473823 11.55298039]\n",
      "Loss: 13.032894618021428\n",
      "\n",
      "Iteration: 776\n",
      "P: [ 8.08976603 -5.82933136  1.06525081 11.56795016]\n",
      "Loss: 13.025885864781651\n",
      "\n",
      "Iteration: 777\n",
      "P: [ 8.09538261 -5.831757    1.0654443  11.57484273]\n",
      "Loss: 13.017556128933538\n",
      "\n",
      "Iteration: 778\n",
      "P: [ 8.10472296 -5.83555881  1.06581036 11.58642349]\n",
      "Loss: 13.011498777009384\n",
      "\n",
      "Iteration: 779\n",
      "P: [ 8.11427311 -5.83948871  1.06617677 11.59824386]\n",
      "Loss: 13.007984695818836\n",
      "\n",
      "Iteration: 780\n",
      "P: [ 8.12177948 -5.84267747  1.06644381 11.60747464]\n",
      "Loss: 13.002313654313722\n",
      "\n",
      "Iteration: 781\n",
      "P: [ 8.13779787 -5.84956797  1.06699411 11.62711404]\n",
      "Loss: 12.990875799663678\n",
      "\n",
      "Iteration: 782\n",
      "P: [ 8.14429076 -5.85232544  1.06722461 11.63509594]\n",
      "Loss: 12.988330138896703\n",
      "\n",
      "Iteration: 783\n",
      "P: [ 8.15302559 -5.8560836   1.06752309 11.64579808]\n",
      "Loss: 12.984743365769921\n",
      "\n",
      "Iteration: 784\n",
      "P: [ 8.17231388 -5.86445238  1.06816227 11.66936374]\n",
      "Loss: 12.975362079397174\n",
      "\n",
      "Iteration: 785\n",
      "P: [ 8.18617781 -5.8706546   1.06857613 11.68615955]\n",
      "Loss: 12.967991919821854\n",
      "\n",
      "Iteration: 786\n",
      "P: [ 8.20255803 -5.87779988  1.06910769 11.70613399]\n",
      "Loss: 12.957466722855097\n",
      "\n",
      "Iteration: 787\n",
      "P: [ 8.20587985 -5.87927877  1.06920767 11.71015935]\n",
      "Loss: 12.955435960582195\n",
      "\n",
      "Iteration: 788\n",
      "P: [ 8.20860841 -5.88048667  1.06929166 11.71347196]\n",
      "Loss: 12.954271716203367\n",
      "\n",
      "Iteration: 789\n",
      "P: [ 8.21469473 -5.88318547  1.06947775 11.72085681]\n",
      "Loss: 12.952042522685362\n",
      "\n",
      "Iteration: 790\n",
      "P: [ 8.21982263 -5.8854656   1.06963274 11.72707275]\n",
      "Loss: 12.950446731581716\n",
      "\n",
      "Iteration: 791\n",
      "P: [ 8.22996619 -5.88999487  1.06993397 11.73935059]\n",
      "Loss: 12.94647743779654\n",
      "\n",
      "Iteration: 792\n",
      "P: [ 8.23776443 -5.89352827  1.0701529  11.74874965]\n",
      "Loss: 12.941704400337924\n",
      "\n",
      "Iteration: 793\n",
      "P: [ 8.24417707 -5.89640771  1.07033937 11.75649903]\n",
      "Loss: 12.938575035491253\n",
      "\n",
      "Iteration: 794\n",
      "P: [ 8.24657322 -5.8974854   1.07040862 11.75939329]\n",
      "Loss: 12.937891219836194\n",
      "\n",
      "Iteration: 795\n",
      "P: [ 8.25084948 -5.89941784  1.07052997 11.76455152]\n",
      "Loss: 12.937100531508028\n",
      "\n",
      "Iteration: 796\n",
      "P: [ 8.25358184 -5.90066422  1.07060468 11.76783852]\n",
      "Loss: 12.935320134093903\n",
      "\n",
      "Iteration: 797\n",
      "P: [ 8.26384342 -5.90534092  1.07088625 11.7801862 ]\n",
      "Loss: 12.932826415987678\n",
      "\n",
      "Iteration: 798\n",
      "P: [ 8.27121009 -5.90874355  1.07107728 11.78901534]\n",
      "Loss: 12.927812931568722\n",
      "\n",
      "Iteration: 799\n",
      "P: [ 8.27695576 -5.91137722  1.07123125 11.79591737]\n",
      "Loss: 12.924989317117388\n",
      "\n",
      "Iteration: 800\n",
      "P: [ 8.27859307 -5.91212905  1.07127479 11.79788317]\n",
      "Loss: 12.92457653704673\n",
      "\n",
      "Iteration: 801\n",
      "P: [ 8.28217967 -5.91378186  1.07136874 11.80218475]\n",
      "Loss: 12.923829018613615\n",
      "\n",
      "Iteration: 802\n",
      "P: [ 8.28504701 -5.91511069  1.07144201 11.80561787]\n",
      "Loss: 12.922370629416072\n",
      "\n",
      "Iteration: 803\n",
      "P: [ 8.29204905 -5.91837091  1.0716172  11.8139897 ]\n",
      "Loss: 12.918663351209462\n",
      "\n",
      "Iteration: 804\n",
      "P: [ 8.2969378  -5.92064104  1.07174102 11.81983958]\n",
      "Loss: 12.91802573897647\n",
      "\n",
      "Iteration: 805\n",
      "P: [ 8.30044808 -5.92228804  1.07182577 11.82402678]\n",
      "Loss: 12.9152707581835\n",
      "\n",
      "Iteration: 806\n",
      "P: [ 8.30444738 -5.92415762  1.07192401 11.82880265]\n",
      "Loss: 12.914056674996194\n",
      "\n",
      "Iteration: 807\n",
      "P: [ 8.31311614 -5.92822542  1.07213319 11.83914276]\n",
      "Loss: 12.912264802491025\n",
      "\n",
      "Iteration: 808\n",
      "P: [ 8.31563906 -5.92943046  1.07218889 11.84213565]\n",
      "Loss: 12.90860610642274\n",
      "\n",
      "Iteration: 809\n",
      "P: [ 8.32282706 -5.93281616  1.07235922 11.85069959]\n",
      "Loss: 12.90579797179114\n",
      "\n",
      "Iteration: 810\n",
      "P: [ 8.32522673 -5.93395     1.07241522 11.85355586]\n",
      "Loss: 12.905344841690974\n",
      "\n",
      "Iteration: 811\n",
      "P: [ 8.3308968  -5.93664149  1.0725445  11.86029514]\n",
      "Loss: 12.902513136744327\n",
      "\n",
      "Iteration: 812\n",
      "P: [ 8.33607525 -5.93912228  1.07265704 11.86643246]\n",
      "Loss: 12.899322910289287\n",
      "\n",
      "Iteration: 813\n",
      "P: [ 8.34136522 -5.94164487  1.07277484 11.872711  ]\n",
      "Loss: 12.897421444261377\n",
      "\n",
      "Iteration: 814\n",
      "P: [ 8.34482363 -5.9433008   1.07285021 11.87681045]\n",
      "Loss: 12.89654332503608\n",
      "\n",
      "Iteration: 815\n",
      "P: [ 8.35117733 -5.94635992  1.07298455 11.88432868]\n",
      "Loss: 12.893285091836196\n",
      "\n",
      "Iteration: 816\n",
      "P: [ 8.35753377 -5.94945823  1.07310974 11.89182069]\n",
      "Loss: 12.889041379148805\n",
      "\n",
      "Iteration: 817\n",
      "P: [ 8.36352686 -5.95236168  1.07323209 11.89889827]\n",
      "Loss: 12.886566171667562\n",
      "\n",
      "Iteration: 818\n",
      "P: [ 8.36745373 -5.95427164  1.07331043 11.90352987]\n",
      "Loss: 12.885480548349298\n",
      "\n",
      "Iteration: 819\n",
      "P: [ 8.37492683 -5.95792769  1.07345433 11.91232757]\n",
      "Loss: 12.882447204498638\n",
      "\n",
      "Iteration: 820\n",
      "P: [ 8.38287095 -5.96184395  1.07360006 11.9216566 ]\n",
      "Loss: 12.876873700606536\n",
      "\n",
      "Iteration: 821\n",
      "P: [ 8.38944212 -5.96507369  1.07372296 11.92938087]\n",
      "Loss: 12.874788856892305\n",
      "\n",
      "Iteration: 822\n",
      "P: [ 8.40325287 -5.97189127  1.07397407 11.94559212]\n",
      "Loss: 12.870007221553182\n",
      "\n",
      "Iteration: 823\n",
      "P: [ 8.41770711 -5.97907068  1.07422612 11.96252428]\n",
      "Loss: 12.860911550166945\n",
      "\n",
      "Iteration: 824\n",
      "P: [ 8.4265425  -5.98344691  1.07438318 11.97288394]\n",
      "Loss: 12.857995154588687\n",
      "\n",
      "Iteration: 825\n",
      "P: [ 8.43189681 -5.98610596  1.07447666 11.9791565 ]\n",
      "Loss: 12.85672556870527\n",
      "\n",
      "Iteration: 826\n",
      "P: [ 8.43605482 -5.98817796  1.07454753 11.9840221 ]\n",
      "Loss: 12.854878318566081\n",
      "\n",
      "Iteration: 827\n",
      "P: [ 8.44881838 -5.99456065  1.07475965 11.99894026]\n",
      "Loss: 12.849510159483371\n",
      "\n",
      "Iteration: 828\n",
      "P: [ 8.45141646 -5.99585749  1.0748034  12.00197877]\n",
      "Loss: 12.848871230033392\n",
      "\n",
      "Iteration: 829\n",
      "P: [ 8.45559259 -5.99794826  1.07487222 12.006858  ]\n",
      "Loss: 12.847862499584506\n",
      "\n",
      "Iteration: 830\n",
      "P: [ 8.46111732 -6.00072024  1.07496179 12.01330817]\n",
      "Loss: 12.846371994774273\n",
      "\n",
      "Iteration: 831\n",
      "P: [ 8.4684994  -6.00443783  1.07507815 12.02191613]\n",
      "Loss: 12.843211439813702\n",
      "\n",
      "Iteration: 832\n",
      "P: [ 8.47215904 -6.00627775  1.07513658 12.0261859 ]\n",
      "Loss: 12.842730628646654\n",
      "\n",
      "Iteration: 833\n",
      "P: [ 8.47429332 -6.00735579  1.07516944 12.02867209]\n",
      "Loss: 12.841622548831447\n",
      "\n",
      "Iteration: 834\n",
      "P: [ 8.47729918 -6.00887182  1.07521626 12.03217534]\n",
      "Loss: 12.840972226396731\n",
      "\n",
      "Iteration: 835\n",
      "P: [ 8.48080862 -6.0106449   1.07527018 12.03626309]\n",
      "Loss: 12.839969928895355\n",
      "\n",
      "Iteration: 836\n",
      "P: [ 8.48968884 -6.01516787  1.07539783 12.04657835]\n",
      "Loss: 12.836909460179156\n",
      "\n",
      "Iteration: 837\n",
      "P: [ 8.49226046 -6.01647559  1.07543529 12.04956715]\n",
      "Loss: 12.836426601805014\n",
      "\n",
      "Iteration: 838\n",
      "P: [ 8.49692815 -6.01885856  1.07550104 12.0549848 ]\n",
      "Loss: 12.835397325179711\n",
      "\n",
      "Iteration: 839\n",
      "P: [ 8.50164553 -6.02127384  1.0755658  12.0604547 ]\n",
      "Loss: 12.834005142588712\n",
      "\n",
      "Iteration: 840\n",
      "P: [ 8.5228367  -6.03223115  1.07583073 12.08494257]\n",
      "Loss: 12.831377780361006\n",
      "\n",
      "Iteration: 841\n",
      "P: [ 8.5327967  -6.03736574  1.07595898 12.09646405]\n",
      "Loss: 12.827727567096723\n",
      "\n",
      "Iteration: 842\n",
      "P: [ 8.53905877 -6.0405974   1.07603878 12.10370518]\n",
      "Loss: 12.825994544625898\n",
      "\n",
      "Iteration: 843\n",
      "P: [ 8.54406446 -6.04318776  1.07610086 12.10948799]\n",
      "Loss: 12.822339049262455\n",
      "\n",
      "Iteration: 844\n",
      "P: [ 8.54892338 -6.04569757  1.07616223 12.11510482]\n",
      "Loss: 12.821299331894812\n",
      "\n",
      "Iteration: 845\n",
      "P: [ 8.54892338 -6.04569757  1.07616223 12.11510482]\n",
      "Loss: 12.82127397139786\n",
      "\n",
      "Iteration: 846\n",
      "P: [ 8.54892338 -6.04569757  1.07616223 12.11510482]\n",
      "Loss: 12.82127397139786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "initial_state = jnp.array([0, 0, np.pi, 0])\n",
    "sigma = jnp.array([10, 10, 4, 10])\n",
    "num_steps = 50\n",
    "target = jnp.array([0, 0, 0, 0])\n",
    "max_force = 10\n",
    "initial_p = jnp.array([5, 5, 5, 5])  # initial policy parameters for upright initial starting position\n",
    "\n",
    "model_x_prime = jnp.array(non_linear_model_sin_force_real_noise_up['X_prime'])\n",
    "model_sigma = jnp.array(non_linear_model_sin_force_real_noise_up['sigma'])\n",
    "model_alpha = jnp.array(non_linear_model_sin_force_real_noise_up['alpha'])\n",
    "\n",
    "@jax.jit\n",
    "def kernel_expanded_jax(X, X_prime, sigma):\n",
    "    # create new X where 2 additional dimensions are added, replacing the angle with sin and cos\n",
    "    # angle dimension is removed\n",
    "    X_new = jnp.hstack((X[:,0:2], jnp.sin(X[:, 2:3]), jnp.cos(X[:, 2:3]), X[:, 3:]))  # (N, D+1)\n",
    "    X_prime_new = jnp.hstack((X_prime[:,0:2], jnp.sin(X_prime[:, 2:3]), jnp.cos(X_prime[:, 2:3]), X_prime[:, 3:]))  # (M, D+1)\n",
    "\n",
    "    X_e = jnp.expand_dims(X_new, axis=1)  # (N, 1, D+1)\n",
    "    X_prime_e = jnp.expand_dims(X_prime_new, axis=0)  # (1, M, D+1)\n",
    "\n",
    "    diff = X_e - X_prime_e  # (N, M, D+1)\n",
    "    scaled_squared_diff = (diff ** 2)/(2 * sigma ** 2) # (N, M, D+1)\n",
    "\n",
    "    K = jnp.exp(-jnp.sum(scaled_squared_diff, axis=-1))  # (N, M)\n",
    "    return K\n",
    "\n",
    "@jax.jit\n",
    "def loss_policy_jax(state, target, sigma):\n",
    "    delta = (state - target) / sigma\n",
    "    exponent = 0.5 * jnp.dot(delta, delta)\n",
    "    return 1 - jnp.exp(-exponent)\n",
    "\n",
    "@jax.jit\n",
    "def loss_rollout_linear_jax(P):\n",
    "    def scan_step_jax(state, _):\n",
    "        force = P @ state\n",
    "        force = max_force * jnp.tanh(force/max_force)\n",
    "\n",
    "        # add force as the last element to the state\n",
    "        current_state = jnp.concatenate([state, jnp.array([force])])\n",
    "        K = kernel_expanded_jax(jnp.expand_dims(current_state, axis=0), model_x_prime, model_sigma)\n",
    "        Y_pred = K @ model_alpha\n",
    "        next_state = jnp.ravel(current_state[:-1] + Y_pred)\n",
    "\n",
    "        loss = loss_policy_jax(next_state, target, sigma)\n",
    "        return next_state, loss\n",
    "\n",
    "    init_loss = loss_policy_jax(initial_state, target, sigma)\n",
    "    _, losses = jax.lax.scan(scan_step_jax, initial_state, None, length=num_steps)\n",
    "    return init_loss + losses.sum()\n",
    "\n",
    "grad_loss_linear_jax = jax.grad(loss_rollout_linear_jax)\n",
    "\n",
    "losses = [loss_rollout_linear_jax(initial_p)]\n",
    "print(\"Initial loss:\", losses[0])\n",
    "\n",
    "def callback(intermediate_result):\n",
    "    print(\"Iteration:\", len(losses))\n",
    "    print(\"P:\", intermediate_result.x)\n",
    "    print(\"Loss:\", intermediate_result.fun)\n",
    "    print()\n",
    "    losses.append(intermediate_result.fun)\n",
    "\n",
    "res = scipy.optimize.minimize(loss_rollout_linear_jax, x0=initial_p, method='L-BFGS-B', jac=grad_loss_linear_jax, callback=callback, bounds=[(-30, 30)] * len(initial_p))\n",
    "\n",
    "def rollout_linear_force(initial_state, num_steps, P, max_force):\n",
    "    X_forecast = [initial_state.copy()]\n",
    "    \n",
    "    state = initial_state.copy()\n",
    "    for step in range(num_steps):\n",
    "        force = P @ state\n",
    "        force = max_force * np.tanh(force/max_force)\n",
    "        # add force as the last element to the state\n",
    "        current_state = jnp.concatenate([state, jnp.array([force])])\n",
    "        K = kernel_expanded_jax(jnp.expand_dims(current_state, axis=0), model_x_prime, model_sigma)\n",
    "\n",
    "        Y_pred = K @ model_alpha\n",
    "        state = jnp.ravel(current_state[:-1] + Y_pred)\n",
    "\n",
    "        remapped_state = state.copy()\n",
    "        # remap jax angle to be between -pi and pi PURELY FOR PLOTTING\n",
    "        remapped_state = np.array([remapped_state[0], remapped_state[1], remap_angle2(remapped_state[2]), remapped_state[3]])\n",
    "        X_forecast.append(remapped_state)\n",
    "\n",
    "    return np.array(X_forecast)\n",
    "\n",
    "P = res.x  # optimised policy matrix\n",
    "X = rollout_linear_force(initial_state=initial_state, num_steps=25, P=P, max_force=max_force)\n",
    "plot_policy(X, target, f\"Rollout Policy, initial_state: {initial_state}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
