{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97516087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CartPole import CartPole, remap_angle, cartpole_step, remap_angle2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "matplotlib.use('TkAgg') \n",
    "import scipy\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c761453e",
   "metadata": {},
   "source": [
    "---\n",
    "# Task 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf2f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important helper functions for all tasks\n",
    "\n",
    "def get_std(X):\n",
    "    return np.std(X, axis=0)\n",
    "\n",
    "def convert_dict_to_array(data):\n",
    "    # zip all the values in the dictionary together and convert it to a numpy array\n",
    "    # suppose the keys are not known beforehand\n",
    "    keys = list(data.keys())\n",
    "    values = [data[key] for key in keys]\n",
    "    return np.array(list(zip(*values)))\n",
    "\n",
    "\n",
    "def rollout(initial_state, initial_force, num_steps, visual=True, max_force=20):\n",
    "    \"\"\"\n",
    "    Simulate the CartPole environment for a given number of steps.\n",
    "    \n",
    "    Args:\n",
    "        initial_state (tuple): The initial state of the environment.\n",
    "        it should be a tuple of the form (cart_location, cart_velocity, \n",
    "                                        pole_angle, pole_velocity).\n",
    "\n",
    "        initial_force (float): The initial force applied to the cart.\n",
    "        num_steps (int): The number of steps to simulate.\n",
    "    \n",
    "    Returns:\n",
    "        data: A dictionary containing the cart location, cart velocity, \n",
    "              pole angle and pole angular velocity at each step.\n",
    "    \"\"\"\n",
    "    env = CartPole(visual=visual, max_force=max_force)\n",
    "    env.reset()\n",
    "\n",
    "    data = {'cart_location': [],\n",
    "            'cart_velocity': [],\n",
    "            'pole_angle': [],\n",
    "            'pole_velocity': []\n",
    "        }\n",
    "    \n",
    "    # Set the initial state\n",
    "    env.setState(initial_state)\n",
    "\n",
    "    # Perform the action for the specified number of steps\n",
    "    for step in range(num_steps + 1):\n",
    "        # Store the current state\n",
    "        data['cart_location'].append(env.cart_location)\n",
    "        data['cart_velocity'].append(env.cart_velocity)\n",
    "        data['pole_angle'].append(env.pole_angle)\n",
    "        data['pole_velocity'].append(env.pole_velocity)\n",
    "\n",
    "        # Perform the action\n",
    "        env.performAction(initial_force)\n",
    "\n",
    "        # remap the angle to be between -pi and pi\n",
    "        env.remap_angle()\n",
    "    \n",
    "    # close the plot\n",
    "    if visual:\n",
    "        env.close_plot()\n",
    "        plt.close()\n",
    "        \n",
    "    return data\n",
    "\n",
    "# Plotting functions --------------------------------------------------------\n",
    "def plot_policy(X, target, graph_title):\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15, 6))\n",
    "    titles = ['cart_location', 'cart_velocity', 'pole_angle', 'pole_velocity']\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            title = titles[i * 2 + j]\n",
    "            ax[i, j].plot(np.arange(0, len(X[:, i * 2 + j])), X[:, i * 2 + j], 'r-', label='policy')\n",
    "            ax[i, j].plot(np.arange(0, len(X[:, i * 2 + j])), [target[i * 2 + j]] * len(X[:, i * 2 + j]), 'b--', label='target')\n",
    "            # ax[i, j].set_title(title)\n",
    "            ax[i, j].set_xlabel('Iterations')\n",
    "            ax[i, j].set_ylabel(title)\n",
    "            ax[i, j].grid()\n",
    "            ax[i, j].legend()\n",
    "    \n",
    "    # center the title on top of the figure\n",
    "    fig.suptitle(graph_title)\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 1])  # Adjust the rect to make space for the title\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_fit(Y_actual, Y_pred, graph_title):\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15, 8))\n",
    "    titles = ['cart_location', 'cart_velocity', 'pole_angle', 'pole_velocity']\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            title = titles[i * 2 + j]\n",
    "            # make scatter plot dots smaller\n",
    "            # colour the scatter plot dots dark blue\n",
    "            ax[i, j].scatter(Y_actual[:, i * 2 + j], Y_pred[:, i * 2 + j], label='pred', s=2, color='darkblue')\n",
    "            ax[i, j].plot(Y_actual[:, i * 2 + j], Y_actual[:, i * 2 + j], 'r--', label='Y = X')\n",
    "            # ax[i, j].set_title(title)\n",
    "            ax[i, j].set_xlabel('actual change in state')\n",
    "            ax[i, j].set_ylabel(title)\n",
    "            ax[i, j].grid()\n",
    "            ax[i, j].legend()\n",
    "\n",
    "    # center the title on top of the figure\n",
    "    fig.suptitle(graph_title)\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 1])  # Adjust the rect to make space for the title\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_actual_pred_iterations(X_actual, X_forecast, graph_title):\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15, 6))\n",
    "    titles = ['cart_location', 'cart_velocity', 'pole_angle', 'pole_velocity']\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            title = titles[i * 2 + j]\n",
    "            ax[i, j].plot(np.arange(0, len(X_actual[:, i * 2 + j])), X_actual[:, i * 2 + j], 'r-', label='actual')\n",
    "            ax[i, j].plot(np.arange(0, len(X_forecast[:, i * 2 + j])), X_forecast[:, i * 2 + j], 'b--', label='forecast')\n",
    "            # ax[i, j].set_title(title)\n",
    "            ax[i, j].set_xlabel('Iterations')\n",
    "            ax[i, j].set_ylabel(title)\n",
    "            ax[i, j].grid()\n",
    "            ax[i, j].legend()\n",
    "    \n",
    "    # center the title on top of the figure\n",
    "    fig.suptitle(graph_title)\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 1])  # Adjust the rect to make space for the title\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.show()\n",
    "\n",
    "def plot_actual_pred_time(X_actual, X_forecast, graph_title):\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15, 6))\n",
    "    titles = ['cart_location', 'cart_velocity', 'pole_angle', 'pole_velocity']\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            title = titles[i * 2 + j]\n",
    "            ax[i, j].plot(0.1 * np.arange(0, len(X_actual[:, i * 2 + j])), X_actual[:, i * 2 + j], 'r-', label='actual')\n",
    "            ax[i, j].plot(0.1 * np.arange(0, len(X_forecast[:, i * 2 + j])), X_forecast[:, i * 2 + j], 'b--', label='forecast')\n",
    "            # ax[i, j].set_title(title)\n",
    "            ax[i, j].set_xlabel('time')\n",
    "            ax[i, j].set_ylabel(title)\n",
    "            ax[i, j].grid()\n",
    "            ax[i, j].legend()\n",
    "    \n",
    "    # center the title on top of the figure\n",
    "    fig.suptitle(graph_title)\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 1])  # Adjust the rect to make space for the title\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.show()\n",
    "\n",
    "def forecast_nonlinear_force(initial_state, num_steps, alpha, sigma, X_prime, kernel_fn, max_force=20):\n",
    "    x_state = initial_state[:-1]  # exclude the force from the state\n",
    "    initial_force = initial_state[-1]  # force is the last element of the state\n",
    "    # obtain the actual state\n",
    "    X_actual = convert_dict_to_array(rollout(x_state, initial_force, num_steps, visual=False, max_force=max_force))\n",
    "\n",
    "    current_state = np.array(initial_state)\n",
    "    current_x_state = np.array(x_state)\n",
    "    X_forecast = [current_x_state.copy()]\n",
    "    for i in range(num_steps):\n",
    "        # calculate the kernel for the current state\n",
    "        K = kernel_fn(np.expand_dims(current_state, axis=0), X_prime, sigma)\n",
    "\n",
    "        Y_pred = K @ alpha\n",
    "        current_x_state = (current_state[:-1] + Y_pred).flatten()\n",
    "        current_state = np.concatenate([current_x_state, current_state[-1:]]) # keep the force unchanged\n",
    "\n",
    "        # remap the angle to be between -pi and pi PURELY FOR PLOTTING\n",
    "        # The original state is still used for the forecast\n",
    "        remapped_state = current_x_state.copy()\n",
    "        remapped_state[2] = remap_angle(remapped_state[2])\n",
    "        X_forecast.append(remapped_state)\n",
    "\n",
    "    X_forecast = np.array(X_forecast)\n",
    "    \n",
    "    plot_actual_pred_iterations(X_actual, X_forecast, graph_title=f\"Forecast for initial state: {initial_state[0]:.2f}, {initial_state[1]:.2f}, {initial_state[2]:.2f}, {initial_state[3]:.2f} with force {initial_state[4]:.2f}\")\n",
    "    plot_actual_pred_time(X_actual, X_forecast, graph_title=f\"Forecast for initial state: {initial_state[0]:.2f}, {initial_state[1]:.2f}, {initial_state[2]:.2f}, {initial_state[3]:.2f} with force {initial_state[4]:.2f}\")\n",
    "\n",
    "\n",
    "# training functions --------------------------------------------------------\n",
    "def generate_data_random_force(num_steps, max_force=20):\n",
    "    env = CartPole(visual=False, max_force=max_force)\n",
    "    env.reset()\n",
    "    x_data = {\n",
    "        'cart_location': [],\n",
    "        'cart_velocity': [],\n",
    "        'pole_angle': [],\n",
    "        'pole_velocity': [],\n",
    "        'force': []\n",
    "    }\n",
    "\n",
    "    y_data = {\n",
    "        'cart_location': [],\n",
    "        'cart_velocity': [],\n",
    "        'pole_angle': [],\n",
    "        'pole_velocity': []\n",
    "    }\n",
    "    for i in range(num_steps):\n",
    "        initial_state = [np.random.uniform(-10, 10), np.random.uniform(-10, 10),\n",
    "                         np.random.uniform(-np.pi, np.pi), np.random.uniform(-15, 15)]\n",
    "        initial_force = np.random.uniform(-env.max_force, env.max_force)\n",
    "        env.reset()\n",
    "        env.setState(initial_state)\n",
    "        env.performAction(initial_force)\n",
    "\n",
    "        # remap the angle to be between -pi and pi\n",
    "        # env.remap_angle()\n",
    "        \n",
    "        next_state = env.getState()\n",
    "    \n",
    "        x_data['cart_location'].append(initial_state[0])\n",
    "        x_data['cart_velocity'].append(initial_state[1])\n",
    "        x_data['pole_angle'].append(initial_state[2])\n",
    "        x_data['pole_velocity'].append(initial_state[3])\n",
    "        x_data['force'].append(initial_force)\n",
    "\n",
    "        y_data['cart_location'].append(next_state[0] - initial_state[0])\n",
    "        y_data['cart_velocity'].append(next_state[1] - initial_state[1])\n",
    "        y_data['pole_angle'].append(next_state[2] - initial_state[2])\n",
    "        y_data['pole_velocity'].append(next_state[3] - initial_state[3])\n",
    "\n",
    "    X = convert_dict_to_array(x_data)\n",
    "    Y = convert_dict_to_array(y_data)\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def generate_data_random_force_observed_noise(num_steps, max_force, y_std, noise_factor):\n",
    "    env = CartPole(visual=False, max_force=max_force)\n",
    "    env.reset()\n",
    "    x_data = {\n",
    "        'cart_location': [],\n",
    "        'cart_velocity': [],\n",
    "        'pole_angle': [],\n",
    "        'pole_velocity': [],\n",
    "        'force': []\n",
    "    }\n",
    "\n",
    "    y_data = {\n",
    "        'cart_location': [],\n",
    "        'cart_velocity': [],\n",
    "        'pole_angle': [],\n",
    "        'pole_velocity': []\n",
    "    }\n",
    "    for i in range(num_steps):\n",
    "        initial_state = [np.random.uniform(-10, 10), np.random.uniform(-10, 10),\n",
    "                         np.random.uniform(-np.pi, np.pi), np.random.uniform(-15, 15)]\n",
    "        initial_force = np.random.uniform(-env.max_force, env.max_force)\n",
    "        env.reset()\n",
    "        env.setState(initial_state)\n",
    "        env.performAction(initial_force)\n",
    "\n",
    "        # remap the angle to be between -pi and pi\n",
    "        # env.remap_angle()\n",
    "        \n",
    "        next_state = env.getState()\n",
    "    \n",
    "        x_data['cart_location'].append(initial_state[0])\n",
    "        x_data['cart_velocity'].append(initial_state[1])\n",
    "        x_data['pole_angle'].append(initial_state[2])\n",
    "        x_data['pole_velocity'].append(initial_state[3])\n",
    "        x_data['force'].append(initial_force)\n",
    "\n",
    "        y_data['cart_location'].append(next_state[0] - initial_state[0])\n",
    "        y_data['cart_velocity'].append(next_state[1] - initial_state[1])\n",
    "        y_data['pole_angle'].append(next_state[2] - initial_state[2])\n",
    "        y_data['pole_velocity'].append(next_state[3] - initial_state[3])\n",
    "\n",
    "        # add noise to observations y\n",
    "        noise_std = noise_factor * y_std\n",
    "        noise = np.random.normal(0, noise_std, size=(4,))\n",
    "        y_data['cart_location'][-1] += noise[0]\n",
    "        y_data['cart_velocity'][-1] += noise[1]\n",
    "        y_data['pole_angle'][-1] += noise[2]\n",
    "        y_data['pole_velocity'][-1] += noise[3]\n",
    "\n",
    "\n",
    "    X = convert_dict_to_array(x_data)\n",
    "    Y = convert_dict_to_array(y_data)\n",
    "    \n",
    "    # print(\"shape of X:\", X.shape, \"\\nshape of Y:\", Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "def tikhonov_solve(K, regularisation_matrix, Y,lamb):\n",
    "    \"\"\"\n",
    "    Solve the Tikhonov regularization problem.\n",
    "    \n",
    "    Args:\n",
    "        K (numpy.ndarray): The kernel matrix. (N, M)\n",
    "        regularisation_matrix (numpy.ndarray): The regularization matrix. (M, M)\n",
    "        Y (numpy.ndarray): The output data. (N, D)\n",
    "        lamb (float): The regularization parameter.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: The weights of the model.\n",
    "    \"\"\"\n",
    "    Y_solve = (K.T) @ Y  # (N, D)\n",
    "\n",
    "    regularisation_term = lamb * regularisation_matrix # (M, M)\n",
    "\n",
    "    X_solve = ((K.T) @ K) + regularisation_term # (M, M)\n",
    "\n",
    "    alpha = np.linalg.lstsq(X_solve, Y_solve, rcond=None)[0]  # (M, D)\n",
    "    \n",
    "    return alpha\n",
    "\n",
    "def train_nonlinear_models(X, Y, M, lamb, sigma, kernel_fn):\n",
    "  \n",
    "\n",
    "    # choose M random points from X\n",
    "    # indices = np.random.choice(X.shape[0], M, replace=False)\n",
    "    # X_prime = X[indices]\n",
    "    X_prime = X[:M] # (M, D)\n",
    "\n",
    "    # Create the kernel matrix\n",
    "    K = kernel_fn(X, X_prime, sigma) # (N, M)\n",
    "\n",
    "    # Create the regularization matrix\n",
    "    regularisation_matrix = kernel_fn(X_prime, X_prime, sigma) # (M, M)\n",
    "\n",
    "    # solve the Tikhonov regularization problem\n",
    "    alpha = tikhonov_solve(K, regularisation_matrix, Y, lamb)\n",
    "\n",
    "    return alpha, X_prime, K\n",
    "\n",
    "def kernel_expanded(X, X_prime, sigma):\n",
    "    # create new X where 2 additional dimensions are added, replacing the angle with sin and cos\n",
    "    # angle dimension is removed\n",
    "    X_new = np.hstack((X[:,0:2], np.sin(X[:, 2:3]), np.cos(X[:, 2:3]), X[:, 3:]))  # (N, D+1)\n",
    "    X_prime_new = np.hstack((X_prime[:,0:2], np.sin(X_prime[:, 2:3]), np.cos(X_prime[:, 2:3]), X_prime[:, 3:]))  # (M, D+1)\n",
    "\n",
    "    X_e = np.expand_dims(X_new, axis=1)  # (N, 1, D+1)\n",
    "    X_prime_e = np.expand_dims(X_prime_new, axis=0)  # (1, M, D+1)\n",
    "\n",
    "    diff = X_e - X_prime_e  # (N, M, D+1)\n",
    "    scaled_squared_diff = (diff ** 2)/(2 * sigma ** 2) # (N, M, D+1)\n",
    "\n",
    "    K = np.exp(-np.sum(scaled_squared_diff, axis=-1))  # (N, M)\n",
    "    return K\n",
    "\n",
    "\n",
    "# jax helper functions ---------------------------------------------------\n",
    "\n",
    "def train_nonlinear_models_j(X, Y, M, lamb, sigma, kernel_fn):\n",
    "    # choose M points from X\n",
    "    X_prime = X[:M] # (M, D)\n",
    "\n",
    "    # Create the kernel matrix\n",
    "    K = kernel_fn(X, X_prime, sigma) # (N, M)\n",
    "\n",
    "    # Create the regularization matrix\n",
    "    regularisation_matrix = kernel_fn(X_prime, X_prime, sigma) # (M, M)\n",
    "\n",
    "    alpha = tikhonov_solve_j(K, regularisation_matrix, Y, lamb)\n",
    "    return alpha, X_prime, K\n",
    "\n",
    "\n",
    "\n",
    "def tikhonov_solve_j(K, regularisation_matrix, Y,lamb):\n",
    "    \"\"\"\n",
    "    Solve the Tikhonov regularization problem.\n",
    "    \n",
    "    Args:\n",
    "        K (numpy.ndarray): The kernel matrix. (N, M)\n",
    "        regularisation_matrix (numpy.ndarray): The regularization matrix. (M, M)\n",
    "        Y (numpy.ndarray): The output data. (N, D)\n",
    "        lamb (float): The regularization parameter.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: The weights of the model.\n",
    "    \"\"\"\n",
    "    Y_solve = (K.T) @ Y  # (N, D)\n",
    "\n",
    "    regularisation_term = lamb * regularisation_matrix # (M, M)\n",
    "    X_solve = ((K.T) @ K) + regularisation_term # (M, M)\n",
    "\n",
    "    alpha = jnp.linalg.lstsq(X_solve, Y_solve, rcond=None, numpy_resid=True)[0]  # (M, D)\n",
    "    return alpha\n",
    "\n",
    "@jax.jit\n",
    "def kernel_expanded_j(X, X_prime, sigma):\n",
    "    # create new X where 2 additional dimensions are added, replacing the angle with sin and cos\n",
    "    # angle dimension is removed\n",
    "    X_new = jnp.hstack((X[:,0:2], jnp.sin(X[:, 2:3]), jnp.cos(X[:, 2:3]), X[:, 3:]))  # (N, D+1)\n",
    "    X_prime_new = jnp.hstack((X_prime[:,0:2], jnp.sin(X_prime[:, 2:3]), jnp.cos(X_prime[:, 2:3]), X_prime[:, 3:]))  # (M, D+1)\n",
    "\n",
    "    X_e = jnp.expand_dims(X_new, axis=1)  # (N, 1, D+1)\n",
    "    X_prime_e = jnp.expand_dims(X_prime_new, axis=0)  # (1, M, D+1)\n",
    "\n",
    "    diff = X_e - X_prime_e  # (N, M, D+1)\n",
    "    scaled_squared_diff = (diff ** 2)/(2 * sigma ** 2) # (N, M, D+1)\n",
    "\n",
    "    K = jnp.exp(-jnp.sum(scaled_squared_diff, axis=-1))  # (N, M)\n",
    "    return K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe88aa22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of Y: [0.58454333 1.48055989 0.89009544 3.76791994]\n"
     ]
    }
   ],
   "source": [
    "N_train, N_test = 4096, 2048\n",
    "X_no_noise, Y_no_noise = generate_data_random_force(num_steps=N_train+N_test)\n",
    "Y_std = get_std(Y_no_noise)\n",
    "print(\"Standard deviation of Y:\", Y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdc7084b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fun: 0.10889331652703485\n",
      "   x: [ 4.934e-02  5.828e+00  5.797e+00  4.659e-01  4.849e-01  8.636e+00\n",
      "        8.668e+00]\n",
      " fun: 0.1000162303872198\n",
      "   x: [ 1.110e-02  5.852e+00  5.821e+00  5.912e-01  5.690e-01  8.631e+00\n",
      "        8.682e+00]\n",
      " fun: 0.09550732271147852\n",
      "   x: [ 3.304e-02  5.903e+00  5.875e+00  7.427e-01  6.270e-01  8.616e+00\n",
      "        8.716e+00]\n",
      " fun: 0.09323989907321284\n",
      "   x: [ 1.000e-06  5.971e+00  5.950e+00  8.931e-01  6.693e-01  8.594e+00\n",
      "        8.763e+00]\n",
      " fun: 0.09176179915921187\n",
      "   x: [ 2.687e-02  6.033e+00  6.017e+00  1.000e+00  6.862e-01  8.575e+00\n",
      "        8.805e+00]\n",
      " fun: 0.09129587816421625\n",
      "   x: [ 2.395e-02  6.043e+00  6.029e+00  1.000e+00  6.723e-01  8.571e+00\n",
      "        8.813e+00]\n",
      " fun: 0.08921904873569404\n",
      "   x: [ 2.122e-03  6.181e+00  6.185e+00  1.000e+00  5.508e-01  8.524e+00\n",
      "        8.911e+00]\n",
      " fun: 0.08601675388625508\n",
      "   x: [ 1.400e-02  6.327e+00  6.346e+00  1.000e+00  5.719e-01  8.476e+00\n",
      "        9.012e+00]\n",
      " fun: 0.07405275248815116\n",
      "   x: [ 4.281e-02  7.274e+00  7.389e+00  1.000e+00  5.942e-01  8.168e+00\n",
      "        9.671e+00]\n",
      " fun: 0.0656888045265592\n",
      "   x: [ 6.435e-02  8.461e+00  8.695e+00  9.660e-01  5.878e-01  7.782e+00\n",
      "        1.050e+01]\n",
      " fun: 0.05991563927978481\n",
      "   x: [ 7.123e-02  9.933e+00  1.027e+01  7.924e-01  6.019e-01  7.446e+00\n",
      "        1.147e+01]\n",
      " fun: 0.056095397545232684\n",
      "   x: [ 8.955e-02  1.169e+01  1.215e+01  7.654e-01  5.903e-01  7.052e+00\n",
      "        1.264e+01]\n",
      " fun: 0.053941038218828154\n",
      "   x: [ 1.561e-02  1.380e+01  1.451e+01  1.000e+00  7.815e-01  6.644e+00\n",
      "        1.436e+01]\n",
      " fun: 0.052071220865611056\n",
      "   x: [ 6.470e-02  1.555e+01  1.636e+01  1.000e+00  7.184e-01  6.219e+00\n",
      "        1.547e+01]\n",
      " fun: 0.05143437445195173\n",
      "   x: [ 6.464e-02  1.692e+01  1.785e+01  1.000e+00  7.262e-01  5.917e+00\n",
      "        1.644e+01]\n",
      " fun: 0.05051374095673828\n",
      "   x: [ 4.614e-02  1.758e+01  1.888e+01  1.000e+00  5.021e-01  5.974e+00\n",
      "        1.776e+01]\n",
      " fun: 0.049910926327087976\n",
      "   x: [ 4.302e-02  2.005e+01  2.150e+01  1.000e+00  5.773e-01  5.414e+00\n",
      "        1.938e+01]\n",
      " fun: 0.04971727559980503\n",
      "   x: [ 3.157e-02  2.149e+01  2.318e+01  1.000e+00  5.738e-01  5.219e+00\n",
      "        2.072e+01]\n",
      " fun: 0.049623910407160916\n",
      "   x: [ 2.917e-02  2.256e+01  2.439e+01  1.000e+00  5.935e-01  5.060e+00\n",
      "        2.163e+01]\n",
      " fun: 0.04945428927053646\n",
      "   x: [ 2.664e-02  2.393e+01  2.602e+01  1.000e+00  6.302e-01  4.959e+00\n",
      "        2.301e+01]\n",
      " fun: 0.049211541157602776\n",
      "   x: [ 2.227e-02  2.538e+01  2.791e+01  1.000e+00  6.744e-01  5.052e+00\n",
      "        2.493e+01]\n",
      " fun: 0.048934078573546064\n",
      "   x: [ 1.694e-02  2.646e+01  2.958e+01  1.000e+00  7.100e-01  5.444e+00\n",
      "        2.709e+01]\n",
      " fun: 0.04871648377750138\n",
      "   x: [ 1.039e-02  2.701e+01  3.082e+01  1.000e+00  7.218e-01  6.096e+00\n",
      "        2.926e+01]\n",
      " fun: 0.0486642517780662\n",
      "   x: [ 1.253e-02  2.701e+01  3.104e+01  1.000e+00  7.182e-01  6.367e+00\n",
      "        2.987e+01]\n",
      " fun: 0.048599107876692166\n",
      "   x: [ 9.279e-03  2.710e+01  3.153e+01  1.000e+00  6.958e-01  6.801e+00\n",
      "        3.102e+01]\n",
      " fun: 0.04858622960007128\n",
      "   x: [ 8.597e-03  2.713e+01  3.169e+01  1.000e+00  6.737e-01  6.934e+00\n",
      "        3.140e+01]\n",
      " fun: 0.04858353746654097\n",
      "   x: [ 9.367e-03  2.701e+01  3.156e+01  1.000e+00  6.546e-01  6.949e+00\n",
      "        3.131e+01]\n",
      " fun: 0.04858294086117976\n",
      "   x: [ 9.752e-03  2.692e+01  3.141e+01  1.000e+00  6.427e-01  6.898e+00\n",
      "        3.110e+01]\n",
      " fun: 0.04858225386300233\n",
      "   x: [ 1.002e-02  2.687e+01  3.131e+01  1.000e+00  6.431e-01  6.851e+00\n",
      "        3.093e+01]\n",
      " fun: 0.048547496304823225\n",
      "   x: [ 1.097e-02  2.679e+01  3.099e+01  1.000e+00  6.317e-01  6.822e+00\n",
      "        3.020e+01]\n",
      " fun: 0.04838710869735901\n",
      "   x: [ 1.763e-02  2.701e+01  2.937e+01  1.000e+00  5.791e-01  7.040e+00\n",
      "        2.465e+01]\n",
      " fun: 0.04831150982719262\n",
      "   x: [ 1.392e-02  2.809e+01  3.101e+01  1.000e+00  6.139e-01  7.473e+00\n",
      "        2.667e+01]\n",
      " fun: 0.04824449616427033\n",
      "   x: [ 1.365e-02  2.923e+01  3.205e+01  1.000e+00  6.146e-01  7.653e+00\n",
      "        2.681e+01]\n",
      " fun: 0.04809187755638285\n",
      "   x: [ 1.437e-02  3.000e+01  3.946e+01  1.000e+00  6.044e-01  8.372e+00\n",
      "        2.663e+01]\n",
      " fun: 0.04805895882010418\n",
      "   x: [ 1.783e-02  3.000e+01  4.000e+01  1.000e+00  5.763e-01  8.398e+00\n",
      "        2.571e+01]\n",
      " fun: 0.0479922374712851\n",
      "   x: [ 2.560e-02  3.000e+01  4.000e+01  9.997e-01  5.304e-01  8.007e+00\n",
      "        2.370e+01]\n",
      " fun: 0.04790227633433623\n",
      "   x: [ 4.031e-02  3.000e+01  4.000e+01  9.987e-01  5.078e-01  6.500e+00\n",
      "        2.285e+01]\n",
      " fun: 0.04788285272877675\n",
      "   x: [ 3.142e-02  3.000e+01  4.000e+01  1.000e+00  5.638e-01  6.904e+00\n",
      "        2.375e+01]\n",
      " fun: 0.047875153904313794\n",
      "   x: [ 3.208e-02  3.000e+01  4.000e+01  9.993e-01  5.520e-01  6.765e+00\n",
      "        2.374e+01]\n",
      " fun: 0.047873989624319074\n",
      "   x: [ 3.158e-02  3.000e+01  4.000e+01  9.990e-01  5.453e-01  6.740e+00\n",
      "        2.367e+01]\n",
      " fun: 0.04787383506630044\n",
      "   x: [ 3.111e-02  3.000e+01  4.000e+01  9.990e-01  5.475e-01  6.734e+00\n",
      "        2.376e+01]\n",
      " fun: 0.047873810085010425\n",
      "   x: [ 3.062e-02  3.000e+01  4.000e+01  9.991e-01  5.476e-01  6.756e+00\n",
      "        2.382e+01]\n"
     ]
    }
   ],
   "source": [
    "# train sine cosine model\n",
    "\n",
    "N_train, N_test, M = 4096, 2048, 1024\n",
    "max_force = 15\n",
    "\n",
    "X, Y = generate_data_random_force_observed_noise(num_steps=N_train+N_test, max_force=max_force, y_std=Y_std, noise_factor=0.1)\n",
    "X = jnp.array(X)\n",
    "Y = jnp.array(Y)\n",
    "X_prime = X[:M]\n",
    "\n",
    "X_train = X[:N_train]\n",
    "Y_train = Y[:N_train]\n",
    "\n",
    "X_val = X[-N_test:]\n",
    "Y_val = Y[-N_test:]\n",
    "\n",
    "def loss(parameters):\n",
    "    lamb = parameters[0]\n",
    "    sigma = parameters[1:]\n",
    "    # train model\n",
    "    alpha, X_prime, _= train_nonlinear_models_j(X_train, Y_train, M=M, lamb=lamb, sigma=sigma, kernel_fn=kernel_expanded_j)\n",
    "\n",
    "    # predict using validation set\n",
    "    K_val = kernel_expanded_j(X_val, X_prime, sigma)\n",
    "    Y_pred = K_val @ alpha\n",
    "\n",
    "    mse = jnp.mean((Y_val - Y_pred) ** 2)\n",
    "    return mse\n",
    "\n",
    "# create a function that calculates the gradient of the loss function using jax.grad\n",
    "grad_loss = jax.grad(loss)\n",
    "\n",
    "initial_lamb = 1E-4\n",
    "std_force = max_force / (3**0.5)  # standard deviation for force\n",
    "x_sigma = get_std(X)\n",
    "# initial_sigma = jnp.array([6, 6, 0.5, 0.5, 6])\n",
    "std_sine, std_cos = (0.125)**0.5, (0.125)**0.5  # standard deviation for sine and cosine\n",
    "initial_sigma = jnp.array([x_sigma[0], x_sigma[1], std_sine, std_cos, x_sigma[-1], std_force])\n",
    "initial_hyperparameters = jnp.array([initial_lamb] + initial_sigma.tolist())\n",
    "\n",
    "losses = [loss(initial_hyperparameters)]\n",
    "\n",
    "def callback(intermediate_result):\n",
    "    print(intermediate_result)\n",
    "    losses.append(intermediate_result.fun)\n",
    "\n",
    "\n",
    "\n",
    "bounds = [(1E-6, 1E-1)] + [(0, 30)] + [(0, 40)] + [(0, 1)] * 2 +[(0, 10)] + [(0, max_force*3)]  # bounds for lamb and sigma\n",
    "res = scipy.optimize.minimize(loss, x0=initial_hyperparameters, method='L-BFGS-B', jac=grad_loss, bounds=bounds, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "079c31a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal lambda: 0.030620290457778494\n",
      "optimal sigma: [30.         40.          0.99912816  0.54763817  6.75635011 23.82006105]\n",
      "initial loss 0.130074461398551\n",
      "Final loss: 0.047873810085010425\n",
      "number of iterations: 42\n"
     ]
    }
   ],
   "source": [
    "print(\"optimal lambda:\", res.x[0])\n",
    "print(\"optimal sigma:\", res.x[1:])\n",
    "print(\"initial loss\", losses[0])\n",
    "print(\"Final loss:\", res.fun)\n",
    "print(\"number of iterations:\", len(losses) - 1)\n",
    "\n",
    "def plot_loss(losses):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.plot(losses, label='Loss')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss over iterations')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a878ca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, M, lamb = 4096, 1024, res.x[0]\n",
    "# N, M, lamb = 4096, 1024, 4.543e-03 # mine\n",
    "# N, M, lamb = 4096, 1024, 4.918e-04 # andrew\n",
    "max_force=15\n",
    "# generate training data\n",
    "X, Y = generate_data_random_force_observed_noise(num_steps=N, max_force=max_force, y_std=Y_std, noise_factor=0.1)\n",
    "\n",
    "# Get the standard deviation of X\n",
    "sigma = res.x[1:]\n",
    "# sigma = np.array([1.000e+01,  1.000e+01,  9.916e-01,  6.063e-01, 7.005e+00,  2.000e+01]) # mine\n",
    "# sigma = np.array([15.41,  1.413e+01,  5.24,  0.97, 7.356,  13.52])    # andrew\n",
    "\n",
    "# train model\n",
    "alpha, X_prime, K = train_nonlinear_models(X, Y, M=M, lamb=lamb, sigma=sigma, kernel_fn=kernel_expanded)\n",
    "\n",
    "# predict using training set\n",
    "Y_pred = K @ alpha\n",
    "\n",
    "# plot_fit(X, Y, Y_pred, graph_title=\"Fit of the model\")\n",
    "plot_fit(Y, Y_pred, graph_title=\"Change in state\")\n",
    "\n",
    "\n",
    "# Example initial states for testing\n",
    "initial_states = [[0, -2, np.pi, 4, 1], [0, 0, np.pi, 5, 2], [0, 0, np.pi, 0, 10], [0, 0, 0.1, 0, 8]]\n",
    "# initial_states = [[0, 0, np.pi, 0, 15]]\n",
    "for initial_state in initial_states:\n",
    "    forecast_nonlinear_force(initial_state, num_steps=100, alpha=alpha, sigma=sigma, X_prime=X_prime, kernel_fn=kernel_expanded)\n",
    "\n",
    "non_linear_model_sin_force = {\n",
    "    'lambda': res.x[0],\n",
    "    'sigma': res.x[1:],\n",
    "    'alpha': alpha,\n",
    "    'X_prime': X_prime,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b784478b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 19.528658634983024\n",
      "Iteration: 1\n",
      "P: [0.97506613 1.01115828 1.28523116 1.56189376]\n",
      "Loss: 18.83115554589682\n",
      "\n",
      "Iteration: 2\n",
      "P: [0.57986872 1.00135361 4.90201646 5.93005205]\n",
      "Loss: 3.918634816138515\n",
      "\n",
      "Iteration: 3\n",
      "P: [0.55040736 1.01073538 5.08736642 6.13331937]\n",
      "Loss: 3.879024059019882\n",
      "\n",
      "Iteration: 4\n",
      "P: [0.19011987 1.23546483 5.9786596  6.63033225]\n",
      "Loss: 2.933194875772463\n",
      "\n",
      "Iteration: 5\n",
      "P: [-0.63193355  2.67166093  7.76179612  6.61447473]\n",
      "Loss: 0.3364584207041035\n",
      "\n",
      "Iteration: 6\n",
      "P: [-0.68914849  2.7907202   7.91562828  6.60263461]\n",
      "Loss: 0.30417956478597286\n",
      "\n",
      "Iteration: 7\n",
      "P: [-2.58757275  6.24789333 10.80704093  6.03599088]\n",
      "Loss: 0.050585858167582876\n",
      "\n",
      "Iteration: 8\n",
      "P: [-2.7219648   6.5260379  11.12776837  5.99288938]\n",
      "Loss: 0.04536069380650409\n",
      "\n",
      "Iteration: 9\n",
      "P: [-3.07075065  7.39837315 12.43094171  5.88743894]\n",
      "Loss: 0.03779289700024635\n",
      "\n",
      "Iteration: 10\n",
      "P: [-2.97789129  7.42384976 12.86220751  5.94681027]\n",
      "Loss: 0.034589726077199234\n",
      "\n",
      "Iteration: 11\n",
      "P: [-2.71441343  7.90745287 15.33520523  6.15701947]\n",
      "Loss: 0.02513063205220012\n",
      "\n",
      "Iteration: 12\n",
      "P: [-2.49348084  8.59509091 18.28905607  6.34904135]\n",
      "Loss: 0.019412490368551083\n",
      "\n",
      "Iteration: 13\n",
      "P: [-2.23604969  9.22174259 21.3948097   6.44322348]\n",
      "Loss: 0.01641239168026376\n",
      "\n",
      "Iteration: 14\n",
      "P: [-1.45195598  8.65966463 23.41691771  5.88804106]\n",
      "Loss: 0.015259384527851583\n",
      "\n",
      "Iteration: 15\n",
      "P: [-0.80907864  8.38130129 24.03039185  5.73137769]\n",
      "Loss: 0.014839743244299819\n",
      "\n",
      "Iteration: 16\n",
      "P: [ 1.86923285  7.47279741 25.36788393  5.45732674]\n",
      "Loss: 0.013456804110391074\n",
      "\n",
      "Iteration: 17\n",
      "P: [ 5.79276219  5.94466807 23.76124264  5.19195594]\n",
      "Loss: 0.012817140466742427\n",
      "\n",
      "Iteration: 18\n",
      "P: [ 4.90672936  6.40216219 25.23842757  5.26421739]\n",
      "Loss: 0.012590921674658806\n",
      "\n",
      "Iteration: 19\n",
      "P: [ 5.52144572  6.15449107 25.57881711  5.18963273]\n",
      "Loss: 0.012524070627982442\n",
      "\n",
      "Iteration: 20\n",
      "P: [ 5.27291565  6.1003317  26.25277661  5.45580769]\n",
      "Loss: 0.012299016057317536\n",
      "\n",
      "Iteration: 21\n",
      "P: [ 5.73101793  5.78416041 26.54052373  5.33545051]\n",
      "Loss: 0.012263845448503341\n",
      "\n",
      "Iteration: 22\n",
      "P: [ 5.38739926  4.51256938 26.27118641  4.71494224]\n",
      "Loss: 0.012071934880200641\n",
      "\n",
      "Iteration: 23\n",
      "P: [ 4.20162983  2.1497537  24.89208485  3.58447818]\n",
      "Loss: 0.011900276862312098\n",
      "\n",
      "Iteration: 24\n",
      "P: [ 4.64270766  1.87800217 24.79132027  3.44070981]\n",
      "Loss: 0.011813485763135567\n",
      "\n",
      "Iteration: 25\n",
      "P: [ 4.57883435  1.45895812 24.30862724  3.16643677]\n",
      "Loss: 0.011801800399801943\n",
      "\n",
      "Iteration: 26\n",
      "P: [ 4.49847594  1.52281349 24.02814234  3.11647251]\n",
      "Loss: 0.01178810321792989\n",
      "\n",
      "Iteration: 27\n",
      "P: [ 4.30590997  1.59013202 23.71659745  3.12431787]\n",
      "Loss: 0.011778442850932436\n",
      "\n",
      "Iteration: 28\n",
      "P: [ 4.15444045  1.57946994 23.30745872  3.08688295]\n",
      "Loss: 0.011775783544648588\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train policy\n",
    "initial_state = jnp.array([0, 0, 0.1, 0])\n",
    "sigma = jnp.array([10, 10, 7, 10])\n",
    "# sigma = jnp.array([5.8, 5.8, 1.5, 8.5])  # Example sigma values\n",
    "num_steps = 30\n",
    "target = jnp.array([0, 0, 0, 0])\n",
    "max_force = 8\n",
    "\n",
    "initial_p = jnp.array([1, 1, 1, 1])  # initial policy parameters for upright initial starting position\n",
    "\n",
    "model_x_prime = jnp.array(non_linear_model_sin_force['X_prime'])\n",
    "model_sigma = jnp.array(non_linear_model_sin_force['sigma'])\n",
    "model_alpha = jnp.array(non_linear_model_sin_force['alpha'])\n",
    "\n",
    "@jax.jit\n",
    "def kernel_expanded_jax(X, X_prime, sigma):\n",
    "    # create new X where 2 additional dimensions are added, replacing the angle with sin and cos\n",
    "    # angle dimension is removed\n",
    "    X_new = jnp.hstack((X[:,0:2], jnp.sin(X[:, 2:3]), jnp.cos(X[:, 2:3]), X[:, 3:]))  # (N, D+1)\n",
    "    X_prime_new = jnp.hstack((X_prime[:,0:2], jnp.sin(X_prime[:, 2:3]), jnp.cos(X_prime[:, 2:3]), X_prime[:, 3:]))  # (M, D+1)\n",
    "\n",
    "    X_e = jnp.expand_dims(X_new, axis=1)  # (N, 1, D+1)\n",
    "    X_prime_e = jnp.expand_dims(X_prime_new, axis=0)  # (1, M, D+1)\n",
    "\n",
    "    diff = X_e - X_prime_e  # (N, M, D+1)\n",
    "    scaled_squared_diff = (diff ** 2)/(2 * sigma ** 2) # (N, M, D+1)\n",
    "\n",
    "    K = jnp.exp(-jnp.sum(scaled_squared_diff, axis=-1))  # (N, M)\n",
    "    return K\n",
    "\n",
    "@jax.jit\n",
    "def loss_policy_jax(state, target, sigma):\n",
    "    delta = (state - target) / sigma\n",
    "    exponent = 0.5 * jnp.dot(delta, delta)\n",
    "    return 1 - jnp.exp(-exponent)\n",
    "\n",
    "@jax.jit\n",
    "def loss_rollout_linear_jax(P):\n",
    "    def scan_step_jax(state, _):\n",
    "        force = P @ state\n",
    "        force = max_force * jnp.tanh(force/max_force)\n",
    "\n",
    "        # add force as the last element to the state\n",
    "        current_state = jnp.concatenate([state, jnp.array([force])])\n",
    "        K = kernel_expanded_jax(jnp.expand_dims(current_state, axis=0), model_x_prime, model_sigma)\n",
    "        Y_pred = K @ model_alpha\n",
    "        next_state = jnp.ravel(current_state[:-1] + Y_pred)\n",
    "\n",
    "        loss = loss_policy_jax(next_state, target, sigma)\n",
    "        return next_state, loss\n",
    "\n",
    "    init_loss = loss_policy_jax(initial_state, target, sigma)\n",
    "    _, losses = jax.lax.scan(scan_step_jax, initial_state, None, length=num_steps)\n",
    "    return init_loss + losses.sum()\n",
    "\n",
    "grad_loss_linear_jax = jax.grad(loss_rollout_linear_jax)\n",
    "\n",
    "losses = [loss_rollout_linear_jax(initial_p)]\n",
    "print(\"Initial loss:\", losses[0])\n",
    "\n",
    "def callback(intermediate_result):\n",
    "    print(\"Iteration:\", len(losses))\n",
    "    print(\"P:\", intermediate_result.x)\n",
    "    print(\"Loss:\", intermediate_result.fun)\n",
    "    print()\n",
    "    losses.append(intermediate_result.fun)\n",
    "\n",
    "res = scipy.optimize.minimize(loss_rollout_linear_jax, x0=initial_p, method='L-BFGS-B', jac=grad_loss_linear_jax, callback=callback, bounds=[(-30, 30)] * 4) \n",
    "\n",
    "def rollout_linear_force(initial_state, num_steps, P, max_force):\n",
    "    X_forecast = [initial_state.copy()]\n",
    "    \n",
    "    state = initial_state.copy()\n",
    "    for step in range(num_steps):\n",
    "        force = P @ state\n",
    "        force = max_force * np.tanh(force/max_force)\n",
    "        # add force as the last element to the state\n",
    "        current_state = jnp.concatenate([state, jnp.array([force])])\n",
    "        K = kernel_expanded_jax(jnp.expand_dims(current_state, axis=0), model_x_prime, model_sigma)\n",
    "\n",
    "        Y_pred = K @ model_alpha\n",
    "        state = jnp.ravel(current_state[:-1] + Y_pred)\n",
    "\n",
    "        remapped_state = state.copy()\n",
    "        # remap jax angle to be between -pi and pi PURELY FOR PLOTTING\n",
    "        remapped_state = np.array([remapped_state[0], remapped_state[1], remap_angle2(remapped_state[2]), remapped_state[3]])\n",
    "        X_forecast.append(remapped_state)\n",
    "\n",
    "    return np.array(X_forecast)\n",
    "\n",
    "P = res.x  # optimised policy matrix\n",
    "X = rollout_linear_force(initial_state=initial_state, num_steps=50, P=P, max_force=max_force)\n",
    "plot_policy(X, target, f\"Rollout Policy, initial_state: {initial_state}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79d20f1",
   "metadata": {},
   "source": [
    "---\n",
    "# upside down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df1a7700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of Y: [0.57952153 1.47412334 0.88962311 3.76359956]\n"
     ]
    }
   ],
   "source": [
    "N_train, N_test = 4096, 2048\n",
    "X_no_noise, Y_no_noise = generate_data_random_force(num_steps=N_train+N_test)\n",
    "Y_std = get_std(Y_no_noise)\n",
    "print(\"Standard deviation of Y:\", Y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a558a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fun: 0.10061255048589059\n",
      "   x: [ 4.900e-02  5.773e+00  5.753e+00  4.686e-01  4.844e-01  8.635e+00\n",
      "        8.668e+00]\n",
      " fun: 0.09246887923451691\n",
      "   x: [ 3.389e-02  5.799e+00  5.777e+00  5.814e-01  5.649e-01  8.631e+00\n",
      "        8.681e+00]\n",
      " fun: 0.08727051953842183\n",
      "   x: [ 7.715e-02  5.865e+00  5.842e+00  7.622e-01  6.374e-01  8.613e+00\n",
      "        8.716e+00]\n",
      " fun: 0.08512919120443677\n",
      "   x: [ 1.113e-02  5.932e+00  5.909e+00  8.925e-01  6.877e-01  8.593e+00\n",
      "        8.753e+00]\n",
      " fun: 0.08420456941272703\n",
      "   x: [ 4.776e-02  5.960e+00  5.937e+00  9.457e-01  6.976e-01  8.585e+00\n",
      "        8.768e+00]\n",
      " fun: 0.08359739901289251\n",
      "   x: [ 4.179e-02  5.996e+00  5.974e+00  1.000e+00  7.109e-01  8.574e+00\n",
      "        8.788e+00]\n",
      " fun: 0.08072155076042313\n",
      "   x: [ 1.716e-02  6.190e+00  6.169e+00  1.000e+00  7.313e-01  8.518e+00\n",
      "        8.896e+00]\n",
      " fun: 0.07576589888809497\n",
      "   x: [ 1.118e-02  6.628e+00  6.613e+00  1.000e+00  7.707e-01  8.390e+00\n",
      "        9.142e+00]\n",
      " fun: 0.06518580547139785\n",
      "   x: [ 5.053e-02  7.971e+00  7.970e+00  1.000e+00  8.757e-01  8.001e+00\n",
      "        9.892e+00]\n",
      " fun: 0.061641762105825795\n",
      "   x: [ 5.854e-02  8.828e+00  8.837e+00  9.217e-01  9.176e-01  7.754e+00\n",
      "        1.037e+01]\n",
      " fun: 0.06133965077256302\n",
      "   x: [ 3.855e-02  8.829e+00  8.838e+00  9.204e-01  9.067e-01  7.753e+00\n",
      "        1.037e+01]\n",
      " fun: 0.060907997369185084\n",
      "   x: [ 4.163e-02  8.837e+00  8.847e+00  9.191e-01  8.603e-01  7.753e+00\n",
      "        1.038e+01]\n",
      " fun: 0.05980330022524197\n",
      "   x: [ 5.217e-02  8.888e+00  8.902e+00  9.245e-01  6.642e-01  7.750e+00\n",
      "        1.040e+01]\n",
      " fun: 0.05963638696923298\n",
      "   x: [ 5.841e-02  8.934e+00  8.950e+00  9.144e-01  6.393e-01  7.746e+00\n",
      "        1.043e+01]\n",
      " fun: 0.058956100258641675\n",
      "   x: [ 8.204e-02  9.177e+00  9.200e+00  8.539e-01  6.006e-01  7.727e+00\n",
      "        1.057e+01]\n",
      " fun: 0.05768374724171852\n",
      "   x: [ 1.000e-01  9.703e+00  9.744e+00  7.227e-01  5.723e-01  7.685e+00\n",
      "        1.087e+01]\n",
      " fun: 0.054332997085665136\n",
      "   x: [ 1.000e-01  1.150e+01  1.160e+01  7.534e-01  5.177e-01  7.522e+00\n",
      "        1.193e+01]\n",
      " fun: 0.05226746466386518\n",
      "   x: [ 8.033e-02  1.329e+01  1.348e+01  6.466e-01  5.999e-01  7.397e+00\n",
      "        1.301e+01]\n",
      " fun: 0.050895130174417824\n",
      "   x: [ 5.104e-02  1.515e+01  1.543e+01  7.613e-01  6.345e-01  7.259e+00\n",
      "        1.413e+01]\n",
      " fun: 0.04981119818692813\n",
      "   x: [ 4.146e-02  1.773e+01  1.813e+01  8.400e-01  6.698e-01  7.062e+00\n",
      "        1.568e+01]\n",
      " fun: 0.04860940999561362\n",
      "   x: [ 4.760e-02  2.243e+01  2.304e+01  9.508e-01  7.090e-01  6.685e+00\n",
      "        1.851e+01]\n",
      " fun: 0.04814896697680093\n",
      "   x: [ 1.467e-02  2.947e+01  3.040e+01  1.000e+00  6.776e-01  6.127e+00\n",
      "        2.275e+01]\n",
      " fun: 0.047585393809710094\n",
      "   x: [ 4.122e-02  3.000e+01  3.508e+01  1.000e+00  6.567e-01  5.763e+00\n",
      "        2.545e+01]\n",
      " fun: 0.047551992671947436\n",
      "   x: [ 3.985e-02  3.000e+01  3.466e+01  9.704e-01  6.474e-01  5.797e+00\n",
      "        2.520e+01]\n",
      " fun: 0.04751449308613064\n",
      "   x: [ 3.887e-02  3.000e+01  3.399e+01  8.879e-01  6.216e-01  5.851e+00\n",
      "        2.482e+01]\n",
      " fun: 0.047506148640775736\n",
      "   x: [ 4.033e-02  3.000e+01  3.403e+01  8.582e-01  6.129e-01  5.850e+00\n",
      "        2.484e+01]\n",
      " fun: 0.04748548739747577\n",
      "   x: [ 4.431e-02  3.000e+01  3.426e+01  8.143e-01  5.998e-01  5.883e+00\n",
      "        2.496e+01]\n",
      " fun: 0.04746818100243903\n",
      "   x: [ 4.866e-02  3.000e+01  3.446e+01  7.862e-01  5.920e-01  5.950e+00\n",
      "        2.506e+01]\n",
      " fun: 0.047454042736400075\n",
      "   x: [ 5.192e-02  3.000e+01  3.446e+01  7.782e-01  5.905e-01  6.049e+00\n",
      "        2.504e+01]\n",
      " fun: 0.04744336361051194\n",
      "   x: [ 5.379e-02  3.000e+01  3.422e+01  7.797e-01  5.917e-01  6.176e+00\n",
      "        2.488e+01]\n",
      " fun: 0.047438289428852434\n",
      "   x: [ 5.353e-02  3.000e+01  3.394e+01  7.856e-01  5.923e-01  6.261e+00\n",
      "        2.471e+01]\n",
      " fun: 0.0474359889127054\n",
      "   x: [ 5.348e-02  3.000e+01  3.393e+01  8.024e-01  5.781e-01  6.291e+00\n",
      "        2.469e+01]\n",
      " fun: 0.047431885361170836\n",
      "   x: [ 5.166e-02  3.000e+01  3.375e+01  8.039e-01  5.799e-01  6.340e+00\n",
      "        2.458e+01]\n",
      " fun: 0.04741422288234876\n",
      "   x: [ 4.582e-02  3.000e+01  3.434e+01  7.981e-01  5.784e-01  6.530e+00\n",
      "        2.486e+01]\n",
      " fun: 0.04740118872954896\n",
      "   x: [ 3.658e-02  3.000e+01  3.553e+01  8.168e-01  5.847e-01  6.691e+00\n",
      "        2.549e+01]\n",
      " fun: 0.047396258663956796\n",
      "   x: [ 3.608e-02  3.000e+01  3.625e+01  8.225e-01  5.854e-01  6.700e+00\n",
      "        2.589e+01]\n",
      " fun: 0.04739471689774544\n",
      "   x: [ 3.418e-02  3.000e+01  3.671e+01  8.454e-01  5.928e-01  6.696e+00\n",
      "        2.614e+01]\n",
      " fun: 0.04739451366741728\n",
      "   x: [ 3.434e-02  3.000e+01  3.671e+01  8.473e-01  5.924e-01  6.692e+00\n",
      "        2.614e+01]\n",
      " fun: 0.04739328648477693\n",
      "   x: [ 3.470e-02  3.000e+01  3.679e+01  8.580e-01  5.899e-01  6.674e+00\n",
      "        2.615e+01]\n",
      " fun: 0.047391152942669844\n",
      "   x: [ 3.522e-02  3.000e+01  3.692e+01  8.686e-01  5.871e-01  6.656e+00\n",
      "        2.613e+01]\n",
      " fun: 0.047384687275751985\n",
      "   x: [ 3.637e-02  3.000e+01  3.733e+01  8.887e-01  5.814e-01  6.620e+00\n",
      "        2.607e+01]\n",
      " fun: 0.047370151850212996\n",
      "   x: [ 3.843e-02  3.000e+01  3.830e+01  9.150e-01  5.729e-01  6.567e+00\n",
      "        2.590e+01]\n",
      " fun: 0.047348490933599593\n",
      "   x: [ 4.212e-02  3.000e+01  4.000e+01  9.451e-01  5.567e-01  6.492e+00\n",
      "        2.549e+01]\n",
      " fun: 0.047328529763370514\n",
      "   x: [ 4.638e-02  3.000e+01  4.000e+01  9.188e-01  5.522e-01  6.466e+00\n",
      "        2.482e+01]\n",
      " fun: 0.04730803334505834\n",
      "   x: [ 5.744e-02  3.000e+01  4.000e+01  7.770e-01  5.458e-01  6.206e+00\n",
      "        2.314e+01]\n",
      " fun: 0.04729060699299441\n",
      "   x: [ 5.068e-02  3.000e+01  4.000e+01  8.204e-01  5.705e-01  6.350e+00\n",
      "        2.398e+01]\n",
      " fun: 0.047289761934152096\n",
      "   x: [ 5.215e-02  3.000e+01  4.000e+01  8.053e-01  5.737e-01  6.372e+00\n",
      "        2.394e+01]\n",
      " fun: 0.047288613580388175\n",
      "   x: [ 5.041e-02  3.000e+01  4.000e+01  8.010e-01  5.782e-01  6.367e+00\n",
      "        2.402e+01]\n",
      " fun: 0.047288206072590364\n",
      "   x: [ 4.927e-02  3.000e+01  4.000e+01  8.001e-01  5.805e-01  6.375e+00\n",
      "        2.404e+01]\n",
      " fun: 0.04728789796841611\n",
      "   x: [ 4.853e-02  3.000e+01  4.000e+01  8.005e-01  5.816e-01  6.392e+00\n",
      "        2.403e+01]\n",
      " fun: 0.04728766177716275\n",
      "   x: [ 4.817e-02  3.000e+01  4.000e+01  8.021e-01  5.811e-01  6.416e+00\n",
      "        2.399e+01]\n",
      " fun: 0.04728753150024133\n",
      "   x: [ 4.818e-02  3.000e+01  4.000e+01  8.021e-01  5.783e-01  6.433e+00\n",
      "        2.400e+01]\n",
      " fun: 0.04728751925497398\n",
      "   x: [ 4.810e-02  3.000e+01  4.000e+01  8.016e-01  5.775e-01  6.438e+00\n",
      "        2.402e+01]\n"
     ]
    }
   ],
   "source": [
    "# train sine cosine model\n",
    "\n",
    "N_train, N_test, M = 4096, 2048, 1024\n",
    "max_force = 15\n",
    "\n",
    "X, Y = generate_data_random_force_observed_noise(num_steps=N_train+N_test, max_force=max_force, y_std=Y_std, noise_factor=0.1)\n",
    "X = jnp.array(X)\n",
    "Y = jnp.array(Y)\n",
    "X_prime = X[:M]\n",
    "\n",
    "X_train = X[:N_train]\n",
    "Y_train = Y[:N_train]\n",
    "\n",
    "X_val = X[-N_test:]\n",
    "Y_val = Y[-N_test:]\n",
    "\n",
    "def loss(parameters):\n",
    "    lamb = parameters[0]\n",
    "    sigma = parameters[1:]\n",
    "    # train model\n",
    "    alpha, X_prime, _= train_nonlinear_models_j(X_train, Y_train, M=M, lamb=lamb, sigma=sigma, kernel_fn=kernel_expanded_j)\n",
    "\n",
    "    # predict using validation set\n",
    "    K_val = kernel_expanded_j(X_val, X_prime, sigma)\n",
    "    Y_pred = K_val @ alpha\n",
    "\n",
    "    mse = jnp.mean((Y_val - Y_pred) ** 2)\n",
    "    return mse\n",
    "\n",
    "# create a function that calculates the gradient of the loss function using jax.grad\n",
    "grad_loss = jax.grad(loss)\n",
    "\n",
    "initial_lamb = 1E-4\n",
    "std_force = max_force / (3**0.5)  # standard deviation for force\n",
    "x_sigma = get_std(X)\n",
    "# initial_sigma = jnp.array([6, 6, 0.5, 0.5, 6])\n",
    "std_sine, std_cos = (0.125)**0.5, (0.125)**0.5  # standard deviation for sine and cosine\n",
    "initial_sigma = jnp.array([x_sigma[0], x_sigma[1], std_sine, std_cos, x_sigma[-1], std_force])\n",
    "initial_hyperparameters = jnp.array([initial_lamb] + initial_sigma.tolist())\n",
    "\n",
    "losses = [loss(initial_hyperparameters)]\n",
    "\n",
    "def callback(intermediate_result):\n",
    "    print(intermediate_result)\n",
    "    losses.append(intermediate_result.fun)\n",
    "\n",
    "\n",
    "\n",
    "bounds = [(1E-6, 1E-1)] + [(0, 30)] + [(0, 40)] + [(0, 1)] * 2 +[(0, 10)] + [(0, max_force*3)]  # bounds for lamb and sigma\n",
    "res = scipy.optimize.minimize(loss, x0=initial_hyperparameters, method='L-BFGS-B', jac=grad_loss, bounds=bounds, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67785657",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, M, lamb = 4096, 1024, res.x[0]\n",
    "# N, M, lamb = 4096, 1024, 4.543e-03 # mine\n",
    "# N, M, lamb = 4096, 1024, 4.918e-04 # andrew\n",
    "max_force=15\n",
    "# generate training data\n",
    "X, Y = generate_data_random_force_observed_noise(num_steps=N, max_force=max_force, y_std=Y_std, noise_factor=0.1)\n",
    "\n",
    "# Get the standard deviation of X\n",
    "sigma = res.x[1:]\n",
    "# sigma = np.array([1.000e+01,  1.000e+01,  9.916e-01,  6.063e-01, 7.005e+00,  2.000e+01]) # mine\n",
    "# sigma = np.array([15.41,  1.413e+01,  5.24,  0.97, 7.356,  13.52])    # andrew\n",
    "\n",
    "# train model\n",
    "alpha, X_prime, K = train_nonlinear_models(X, Y, M=M, lamb=lamb, sigma=sigma, kernel_fn=kernel_expanded)\n",
    "\n",
    "# predict using training set\n",
    "Y_pred = K @ alpha\n",
    "\n",
    "# plot_fit(X, Y, Y_pred, graph_title=\"Fit of the model\")\n",
    "plot_fit(Y, Y_pred, graph_title=\"Change in state\")\n",
    "\n",
    "\n",
    "# Example initial states for testing\n",
    "initial_states = [[0, -2, np.pi, 4, 1], [0, 0, np.pi, 5, 2], [0, 0, np.pi, 0, 10], [0, 0, 0.1, 0, 8]]\n",
    "# initial_states = [[0, 0, np.pi, 0, 15]]\n",
    "for initial_state in initial_states:\n",
    "    forecast_nonlinear_force(initial_state, num_steps=100, alpha=alpha, sigma=sigma, X_prime=X_prime, kernel_fn=kernel_expanded)\n",
    "\n",
    "non_linear_model_sin_force_down = {\n",
    "    'lambda': res.x[0],\n",
    "    'sigma': res.x[1:],\n",
    "    'alpha': alpha,\n",
    "    'X_prime': X_prime,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0ba6aa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 44.73514973977988\n",
      "Iteration: 1\n",
      "P: [4.99979854 4.99934721 4.96191524 5.00002948]\n",
      "Loss: 44.73368200338194\n",
      "\n",
      "Iteration: 2\n",
      "P: [ 4.92894554  4.76962384 -8.32715493  5.01011429]\n",
      "Loss: 42.757886731917004\n",
      "\n",
      "Iteration: 3\n",
      "P: [ 3.89503935  1.62755109 -0.02973801  6.73723119]\n",
      "Loss: 33.902541640525826\n",
      "\n",
      "Iteration: 4\n",
      "P: [ 3.89823588  1.63726419 -0.05702683  6.73187845]\n",
      "Loss: 32.898943905470304\n",
      "\n",
      "Iteration: 5\n",
      "P: [ 3.46609999  1.24601196 -0.06442387  6.97179706]\n",
      "Loss: 30.66591333522328\n",
      "\n",
      "Iteration: 6\n",
      "P: [ 4.55362085 -0.69799225 -0.01469503  8.16387402]\n",
      "Loss: 29.006304247064907\n",
      "\n",
      "Iteration: 7\n",
      "P: [ 5.12638719 -1.47038746  0.00904864  8.63751215]\n",
      "Loss: 27.019404438762255\n",
      "\n",
      "Iteration: 8\n",
      "P: [ 4.88676845e+00 -1.59578100e+00  6.76968099e-03  8.66404382e+00]\n",
      "Loss: 23.829526068438884\n",
      "\n",
      "Iteration: 9\n",
      "P: [ 4.88276325e+00 -1.59732656e+00  6.69700724e-03  8.66400947e+00]\n",
      "Loss: 23.82840118468955\n",
      "\n",
      "Iteration: 10\n",
      "P: [ 4.85619387e+00 -1.60391652e+00  6.02260134e-03  8.66098125e+00]\n",
      "Loss: 23.810326841978256\n",
      "\n",
      "Iteration: 11\n",
      "P: [ 5.01617588e+00 -1.81275640e+00  2.40927811e-03  8.70953976e+00]\n",
      "Loss: 23.645932324544916\n",
      "\n",
      "Iteration: 12\n",
      "P: [ 5.10280170e+00 -1.92198281e+00  5.58519585e-04  8.73513222e+00]\n",
      "Loss: 23.570572420068324\n",
      "\n",
      "Iteration: 13\n",
      "P: [ 5.45206496e+00 -2.35855302e+00 -6.30592677e-03  8.82837899e+00]\n",
      "Loss: 23.35092956331096\n",
      "\n",
      "Iteration: 14\n",
      "P: [ 5.45783034e+00 -2.36556834e+00 -6.42311786e-03  8.83038558e+00]\n",
      "Loss: 23.345794567546918\n",
      "\n",
      "Iteration: 15\n",
      "P: [ 5.30251226e+00 -2.04763698e+00 -4.08908323e-03  9.01724331e+00]\n",
      "Loss: 18.16382652040654\n",
      "\n",
      "Iteration: 16\n",
      "P: [ 4.38240566 -1.24589145  0.02044327  9.4166229 ]\n",
      "Loss: 17.10776371099453\n",
      "\n",
      "Iteration: 17\n",
      "P: [ 4.36988096 -1.21964503  0.02062526  9.43236482]\n",
      "Loss: 16.86958131650712\n",
      "\n",
      "Iteration: 18\n",
      "P: [ 4.36948421 -1.2184024   0.02063024  9.43340418]\n",
      "Loss: 16.868660520216405\n",
      "\n",
      "Iteration: 19\n",
      "P: [ 4.37341426 -1.20770618  0.02043543  9.44403968]\n",
      "Loss: 16.852856403727944\n",
      "\n",
      "Iteration: 20\n",
      "P: [ 4.37595994 -1.20023666  0.02030651  9.45138353]\n",
      "Loss: 16.843733370045424\n",
      "\n",
      "Iteration: 21\n",
      "P: [ 4.37974201 -1.1877743   0.02010755  9.46373833]\n",
      "Loss: 16.832874835150015\n",
      "\n",
      "Iteration: 22\n",
      "P: [ 4.38217843 -1.17935985  0.01998075  9.47312967]\n",
      "Loss: 16.828741514498233\n",
      "\n",
      "Iteration: 23\n",
      "P: [ 4.3910117  -1.17268733  0.01973942  9.49757676]\n",
      "Loss: 16.82111871546271\n",
      "\n",
      "Iteration: 24\n",
      "P: [ 5.46363359e+00 -1.04914122e+00 -2.31241702e-03  1.17416065e+01]\n",
      "Loss: 14.40496398854805\n",
      "\n",
      "Iteration: 25\n",
      "P: [ 5.46330100e+00 -1.04918149e+00 -2.30555870e-03  1.17409110e+01]\n",
      "Loss: 13.886014033265353\n",
      "\n",
      "Iteration: 26\n",
      "P: [ 5.46228522e+00 -1.04882516e+00 -2.28963348e-03  1.17392091e+01]\n",
      "Loss: 13.881234102861116\n",
      "\n",
      "Iteration: 27\n",
      "P: [ 5.45198872e+00 -1.03977227e+00 -2.17845587e-03  1.17371177e+01]\n",
      "Loss: 13.822125415972373\n",
      "\n",
      "Iteration: 28\n",
      "P: [ 5.36112822e+00 -9.63846803e-01 -1.31526052e-03  1.17364724e+01]\n",
      "Loss: 10.45523739122053\n",
      "\n",
      "Iteration: 29\n",
      "P: [ 5.35999664e+00 -9.62979826e-01 -1.30379160e-03  1.17362479e+01]\n",
      "Loss: 10.386085869349964\n",
      "\n",
      "Iteration: 30\n",
      "P: [ 5.35720593e+00 -9.60954827e-01 -1.27355383e-03  1.17352110e+01]\n",
      "Loss: 10.245805551869308\n",
      "\n",
      "Iteration: 31\n",
      "P: [ 5.35693786e+00 -9.60857459e-01 -1.27045010e-03  1.17349724e+01]\n",
      "Loss: 10.237203337441153\n",
      "\n",
      "Iteration: 32\n",
      "P: [ 5.35533230e+00 -9.61178585e-01 -1.25151267e-03  1.17325310e+01]\n",
      "Loss: 10.210963002875891\n",
      "\n",
      "Iteration: 33\n",
      "P: [ 5.35389917e+00 -9.62496435e-01 -1.23553361e-03  1.17294439e+01]\n",
      "Loss: 10.194697056371455\n",
      "\n",
      "Iteration: 34\n",
      "P: [ 5.34278462e+00 -9.74835361e-01 -1.11336841e-03  1.17036108e+01]\n",
      "Loss: 10.081742028286943\n",
      "\n",
      "Iteration: 35\n",
      "P: [ 5.33458829e+00 -9.85142907e-01 -1.02050460e-03  1.16827760e+01]\n",
      "Loss: 10.01875479359205\n",
      "\n",
      "Iteration: 36\n",
      "P: [ 5.31774984e+00 -1.00336851e+00 -8.39449333e-04  1.16448808e+01]\n",
      "Loss: 9.951309074769997\n",
      "\n",
      "Iteration: 37\n",
      "P: [ 5.30738790e+00 -1.01281980e+00 -7.38362623e-04  1.16253399e+01]\n",
      "Loss: 9.887065793129757\n",
      "\n",
      "Iteration: 38\n",
      "P: [ 5.30321285e+00 -1.01673555e+00 -6.97154458e-04  1.16172650e+01]\n",
      "Loss: 9.875971263337716\n",
      "\n",
      "Iteration: 39\n",
      "P: [ 5.30003143e+00 -1.01940406e+00 -6.67702969e-04  1.16118068e+01]\n",
      "Loss: 9.862145663127423\n",
      "\n",
      "Iteration: 40\n",
      "P: [ 5.29626244e+00 -1.02257584e+00 -6.32802407e-04  1.16053280e+01]\n",
      "Loss: 9.8504874941862\n",
      "\n",
      "Iteration: 41\n",
      "P: [ 5.28363989e+00 -1.03223359e+00 -5.21898667e-04  1.15857616e+01]\n",
      "Loss: 9.817545548486036\n",
      "\n",
      "Iteration: 42\n",
      "P: [ 5.28231773e+00 -1.03286746e+00 -5.12663088e-04  1.15845538e+01]\n",
      "Loss: 9.807677118465328\n",
      "\n",
      "Iteration: 43\n",
      "P: [ 5.27831510e+00 -1.03564733e+00 -4.79310006e-04  1.15789851e+01]\n",
      "Loss: 9.797428119047588\n",
      "\n",
      "Iteration: 44\n",
      "P: [ 5.27784126e+00 -1.03596762e+00 -4.75418227e-04  1.15783457e+01]\n",
      "Loss: 9.796486486674342\n",
      "\n",
      "Iteration: 45\n",
      "P: [ 5.27485181e+00 -1.03791953e+00 -4.51320403e-04  1.15744690e+01]\n",
      "Loss: 9.791746383067784\n",
      "\n",
      "Iteration: 46\n",
      "P: [ 5.27270225e+00 -1.03922200e+00 -4.34633862e-04  1.15719076e+01]\n",
      "Loss: 9.787508064438493\n",
      "\n",
      "Iteration: 47\n",
      "P: [ 5.26876274e+00 -1.04135549e+00 -4.05644694e-04  1.15677781e+01]\n",
      "Loss: 9.77510246119615\n",
      "\n",
      "Iteration: 48\n",
      "P: [ 5.26495227e+00 -1.04335932e+00 -3.77979444e-04  1.15639170e+01]\n",
      "Loss: 9.767458047168416\n",
      "\n",
      "Iteration: 49\n",
      "P: [ 5.25835896e+00 -1.04624463e+00 -3.33766896e-04  1.15585335e+01]\n",
      "Loss: 9.751293836281985\n",
      "\n",
      "Iteration: 50\n",
      "P: [ 5.21528344e+00 -1.06658533e+00 -3.55476878e-05  1.15200387e+01]\n",
      "Loss: 9.20663091667229\n",
      "\n",
      "Iteration: 51\n",
      "P: [ 5.21394894e+00 -1.06652857e+00 -3.05884791e-05  1.15203778e+01]\n",
      "Loss: 9.199337827213823\n",
      "\n",
      "Iteration: 52\n",
      "P: [ 5.20726050e+00 -1.06043780e+00 -4.19171417e-05  1.15350235e+01]\n",
      "Loss: 9.104343296883085\n",
      "\n",
      "Iteration: 53\n",
      "P: [ 5.19223336e+00 -1.05252952e+00 -3.08769507e-05  1.15548273e+01]\n",
      "Loss: 8.9898604709587\n",
      "\n",
      "Iteration: 54\n",
      "P: [ 5.18871616e+00 -1.05953374e+00  2.86209487e-05  1.15389815e+01]\n",
      "Loss: 8.873272158248321\n",
      "\n",
      "Iteration: 55\n",
      "P: [ 5.18228223e+00 -1.06025316e+00  5.94841507e-05  1.15380668e+01]\n",
      "Loss: 8.787379334012437\n",
      "\n",
      "Iteration: 56\n",
      "P: [ 5.17968539e+00 -1.06136390e+00  7.72179344e-05  1.15357987e+01]\n",
      "Loss: 8.775709893104448\n",
      "\n",
      "Iteration: 57\n",
      "P: [ 5.17819589e+00 -1.06512684e+00  1.07208358e-04  1.15273729e+01]\n",
      "Loss: 8.757109996588982\n",
      "\n",
      "Iteration: 58\n",
      "P: [ 5.17519221e+00 -1.07767808e+00  1.99449946e-04  1.14989933e+01]\n",
      "Loss: 8.70696444846679\n",
      "\n",
      "Iteration: 59\n",
      "P: [ 5.17433287e+00 -1.07667654e+00  1.97291118e-04  1.15012282e+01]\n",
      "Loss: 8.70317134095304\n",
      "\n",
      "Iteration: 60\n",
      "P: [ 5.17076785e+00 -1.08232154e+00  2.50736033e-04  1.14880923e+01]\n",
      "Loss: 8.672660841774631\n",
      "\n",
      "Iteration: 61\n",
      "P: [ 5.16868702e+00 -1.08510332e+00  2.78151310e-04  1.14817066e+01]\n",
      "Loss: 8.656601465949462\n",
      "\n",
      "Iteration: 62\n",
      "P: [ 5.16794865e+00 -1.08623968e+00  2.88885200e-04  1.14790877e+01]\n",
      "Loss: 8.65289781470047\n",
      "\n",
      "Iteration: 63\n",
      "P: [ 5.16693501e+00 -1.08861834e+00  3.08871886e-04  1.14736118e+01]\n",
      "Loss: 8.648569059562066\n",
      "\n",
      "Iteration: 64\n",
      "P: [ 5.16604412e+00 -1.09142866e+00  3.31132789e-04  1.14671288e+01]\n",
      "Loss: 8.644365752327362\n",
      "\n",
      "Iteration: 65\n",
      "P: [ 5.16492039e+00 -1.09414689e+00  3.54187836e-04  1.14607883e+01]\n",
      "Loss: 8.635516125939724\n",
      "\n",
      "Iteration: 66\n",
      "P: [ 5.16317171e+00 -1.09817385e+00  3.88023892e-04  1.14514935e+01]\n",
      "Loss: 8.618667595757053\n",
      "\n",
      "Iteration: 67\n",
      "P: [ 5.16223991e+00 -1.10023162e+00  4.05588063e-04  1.14467340e+01]\n",
      "Loss: 8.614197915642228\n",
      "\n",
      "Iteration: 68\n",
      "P: [ 5.16102553e+00 -1.10302691e+00  4.29082571e-04  1.14402846e+01]\n",
      "Loss: 8.609647583709735\n",
      "\n",
      "Iteration: 69\n",
      "P: [ 5.15989855e+00 -1.10581363e+00  4.51866590e-04  1.14338887e+01]\n",
      "Loss: 8.602671050714797\n",
      "\n",
      "Iteration: 70\n",
      "P: [ 5.15695893e+00 -1.10396267e+00  4.43651002e-04  1.14397163e+01]\n",
      "Loss: 8.586374691634203\n",
      "\n",
      "Iteration: 71\n",
      "P: [ 5.15648062e+00 -1.10683670e+00  4.57164978e-04  1.14342696e+01]\n",
      "Loss: 8.583244041703022\n",
      "\n",
      "Iteration: 72\n",
      "P: [ 5.15455110e+00 -1.11068610e+00  4.82643548e-04  1.14267090e+01]\n",
      "Loss: 8.559995730259631\n",
      "\n",
      "Iteration: 73\n",
      "P: [ 5.15441249e+00 -1.11096904e+00  4.84362064e-04  1.14261765e+01]\n",
      "Loss: 8.559328434554725\n",
      "\n",
      "Iteration: 74\n",
      "P: [ 5.15388431e+00 -1.11148655e+00  4.85530352e-04  1.14257362e+01]\n",
      "Loss: 8.55630681253462\n",
      "\n",
      "Iteration: 75\n",
      "P: [ 5.15326852e+00 -1.11217609e+00  4.84593249e-04  1.14255023e+01]\n",
      "Loss: 8.551550042883672\n",
      "\n",
      "Iteration: 76\n",
      "P: [ 5.15283627e+00 -1.11377715e+00  4.83792945e-04  1.14239919e+01]\n",
      "Loss: 8.540076722988347\n",
      "\n",
      "Iteration: 77\n",
      "P: [ 5.15291661e+00 -1.11808455e+00  4.69298642e-04  1.14210949e+01]\n",
      "Loss: 8.5045984611949\n",
      "\n",
      "Iteration: 78\n",
      "P: [ 5.15287253e+00 -1.11865062e+00  4.68117073e-04  1.14206329e+01]\n",
      "Loss: 8.50117661365818\n",
      "\n",
      "Iteration: 79\n",
      "P: [ 5.15282400e+00 -1.12238928e+00  4.50963184e-04  1.14189749e+01]\n",
      "Loss: 8.489598273562397\n",
      "\n",
      "Iteration: 80\n",
      "P: [ 5.15323159e+00 -1.12269853e+00  4.48517709e-04  1.14187101e+01]\n",
      "Loss: 8.473299172610977\n",
      "\n",
      "Iteration: 81\n",
      "P: [ 5.15398163e+00 -1.12666673e+00  4.25243315e-04  1.14172173e+01]\n",
      "Loss: 8.44721374350566\n",
      "\n",
      "Iteration: 82\n",
      "P: [ 5.15429565e+00 -1.12850333e+00  4.14830577e-04  1.14164901e+01]\n",
      "Loss: 8.436083507100927\n",
      "\n",
      "Iteration: 83\n",
      "P: [ 5.15444257e+00 -1.12921579e+00  4.10412502e-04  1.14162535e+01]\n",
      "Loss: 8.432192038219414\n",
      "\n",
      "Iteration: 84\n",
      "P: [ 5.15505336e+00 -1.13181238e+00  3.93367897e-04  1.14154955e+01]\n",
      "Loss: 8.419876254869436\n",
      "\n",
      "Iteration: 85\n",
      "P: [ 5.15577228e+00 -1.13437493e+00  3.75304766e-04  1.14148733e+01]\n",
      "Loss: 8.40914349302094\n",
      "\n",
      "Iteration: 86\n",
      "P: [ 5.15782238e+00 -1.14038278e+00  3.28846562e-04  1.14138474e+01]\n",
      "Loss: 8.376399791418697\n",
      "\n",
      "Iteration: 87\n",
      "P: [ 5.16347685e+00 -1.15373354e+00  2.06485671e-04  1.14140175e+01]\n",
      "Loss: 8.293420780542133\n",
      "\n",
      "Iteration: 88\n",
      "P: [ 5.16402890e+00 -1.15509220e+00  1.94402562e-04  1.14139891e+01]\n",
      "Loss: 8.284570464381222\n",
      "\n",
      "Iteration: 89\n",
      "P: [ 5.16463729e+00 -1.15649845e+00  1.81242381e-04  1.14140440e+01]\n",
      "Loss: 8.278465930785943\n",
      "\n",
      "Iteration: 90\n",
      "P: [ 5.16557810e+00 -1.15860326e+00  1.61014752e-04  1.14141944e+01]\n",
      "Loss: 8.271822508582305\n",
      "\n",
      "Iteration: 91\n",
      "P: [ 5.16686840e+00 -1.16133801e+00  1.33487159e-04  1.14145529e+01]\n",
      "Loss: 8.262910680547625\n",
      "\n",
      "Iteration: 92\n",
      "P: [ 5.16870117e+00 -1.16494601e+00  9.48088435e-05  1.14153343e+01]\n",
      "Loss: 8.239657261028446\n",
      "\n",
      "Iteration: 93\n",
      "P: [ 5.17096556e+00 -1.16911767e+00  4.77767836e-05  1.14165295e+01]\n",
      "Loss: 8.21875551324088\n",
      "\n",
      "Iteration: 94\n",
      "P: [ 5.18427446e+00 -1.19470325e+00 -2.30960458e-04  1.14226150e+01]\n",
      "Loss: 7.7425995581946605\n",
      "\n",
      "Iteration: 95\n",
      "P: [ 5.18423106e+00 -1.19461663e+00 -2.30018897e-04  1.14225938e+01]\n",
      "Loss: 7.742532892310853\n",
      "\n",
      "Iteration: 96\n",
      "P: [ 5.18893313e+00 -1.20042265e+00 -3.11529840e-04  1.14260204e+01]\n",
      "Loss: 7.689396857924502\n",
      "\n",
      "Iteration: 97\n",
      "P: [ 5.20294376e+00 -1.21869404e+00 -5.59949209e-04  1.14359213e+01]\n",
      "Loss: 7.684753187677728\n",
      "\n",
      "Iteration: 98\n",
      "P: [ 5.20928441e+00 -1.22698455e+00 -6.72496430e-04  1.14403950e+01]\n",
      "Loss: 7.529679416374801\n",
      "\n",
      "Iteration: 99\n",
      "P: [ 5.20935797e+00 -1.22708046e+00 -6.73800457e-04  1.14404470e+01]\n",
      "Loss: 7.52955269432487\n",
      "\n",
      "Iteration: 100\n",
      "P: [ 5.20968355e+00 -1.22750266e+00 -6.79422600e-04  1.14406555e+01]\n",
      "Loss: 7.528620349664568\n",
      "\n",
      "Iteration: 101\n",
      "P: [ 5.21037789e+00 -1.22840112e+00 -6.91270749e-04  1.14410797e+01]\n",
      "Loss: 7.526286479514756\n",
      "\n",
      "Iteration: 102\n",
      "P: [ 5.21192720e+00 -1.23040303e+00 -7.17480828e-04  1.14419927e+01]\n",
      "Loss: 7.521554340786775\n",
      "\n",
      "Iteration: 103\n",
      "P: [ 5.21292967e+00 -1.23169569e+00 -7.34113149e-04  1.14425336e+01]\n",
      "Loss: 7.513248957239386\n",
      "\n",
      "Iteration: 104\n",
      "P: [ 5.21527266e+00 -1.23467456e+00 -7.72836069e-04  1.14438306e+01]\n",
      "Loss: 7.497424298619498\n",
      "\n",
      "Iteration: 105\n",
      "P: [ 5.21565752e+00 -1.23516654e+00 -7.79249507e-04  1.14440487e+01]\n",
      "Loss: 7.495668193834474\n",
      "\n",
      "Iteration: 106\n",
      "P: [ 5.21632558e+00 -1.23601678e+00 -7.90323505e-04  1.14444228e+01]\n",
      "Loss: 7.492739355181099\n",
      "\n",
      "Iteration: 107\n",
      "P: [ 5.21729418e+00 -1.23724518e+00 -8.06330909e-04  1.14449634e+01]\n",
      "Loss: 7.489111821160472\n",
      "\n",
      "Iteration: 108\n",
      "P: [ 5.21821464e+00 -1.23840615e+00 -8.21457599e-04  1.14454725e+01]\n",
      "Loss: 7.48594774320221\n",
      "\n",
      "Iteration: 109\n",
      "P: [ 5.22023043e+00 -1.24093533e+00 -8.54187712e-04  1.14465460e+01]\n",
      "Loss: 7.478749823275405\n",
      "\n",
      "Iteration: 110\n",
      "P: [ 5.22217096e+00 -1.24335415e+00 -8.84727122e-04  1.14474598e+01]\n",
      "Loss: 7.465127512739793\n",
      "\n",
      "Iteration: 111\n",
      "P: [ 5.22298277e+00 -1.24436911e+00 -8.97658273e-04  1.14478607e+01]\n",
      "Loss: 7.4620451627239905\n",
      "\n",
      "Iteration: 112\n",
      "P: [ 5.22387342e+00 -1.24548094e+00 -9.11725292e-04  1.14482855e+01]\n",
      "Loss: 7.458521711499735\n",
      "\n",
      "Iteration: 113\n",
      "P: [ 5.22577656e+00 -1.24785496e+00 -9.41543432e-04  1.14491613e+01]\n",
      "Loss: 7.4517021968535735\n",
      "\n",
      "Iteration: 114\n",
      "P: [ 5.22781691e+00 -1.25039275e+00 -9.73149972e-04  1.14500594e+01]\n",
      "Loss: 7.443692981400789\n",
      "\n",
      "Iteration: 115\n",
      "P: [ 5.23540332e+00 -1.25964926e+00 -1.08837713e-03  1.14533636e+01]\n",
      "Loss: 7.411330065040872\n",
      "\n",
      "Iteration: 116\n",
      "P: [ 5.23594339e+00 -1.26030995e+00 -1.09661380e-03  1.14536009e+01]\n",
      "Loss: 7.4098062191798855\n",
      "\n",
      "Iteration: 117\n",
      "P: [ 5.23776999e+00 -1.26252529e+00 -1.12421623e-03  1.14543984e+01]\n",
      "Loss: 7.403951360701215\n",
      "\n",
      "Iteration: 118\n",
      "P: [ 5.23930247e+00 -1.26437776e+00 -1.14729799e-03  1.14550671e+01]\n",
      "Loss: 7.399156190875269\n",
      "\n",
      "Iteration: 119\n",
      "P: [ 5.24228325e+00 -1.26797155e+00 -1.19199876e-03  1.14563574e+01]\n",
      "Loss: 7.3897696681261795\n",
      "\n",
      "Iteration: 120\n",
      "P: [ 5.24842431e+00 -1.27538224e+00 -1.28324349e-03  1.14589025e+01]\n",
      "Loss: 7.373368337605164\n",
      "\n",
      "Iteration: 121\n",
      "P: [ 5.25041657e+00 -1.27779860e+00 -1.31227310e-03  1.14596410e+01]\n",
      "Loss: 7.360015487676845\n",
      "\n",
      "Iteration: 122\n",
      "P: [ 5.25290290e+00 -1.28080291e+00 -1.34894428e-03  1.14606330e+01]\n",
      "Loss: 7.3519102366336755\n",
      "\n",
      "Iteration: 123\n",
      "P: [ 5.25313334e+00 -1.28108159e+00 -1.35233324e-03  1.14607235e+01]\n",
      "Loss: 7.351432137330278\n",
      "\n",
      "Iteration: 124\n",
      "P: [ 5.25580925e+00 -1.28431978e+00 -1.39154612e-03  1.14617551e+01]\n",
      "Loss: 7.348468192152024\n",
      "\n",
      "Iteration: 125\n",
      "P: [ 5.25571998e+00 -1.28421085e+00 -1.39010630e-03  1.14617088e+01]\n",
      "Loss: 7.343009525636559\n",
      "\n",
      "Iteration: 126\n",
      "P: [ 5.25797257e+00 -1.28693553e+00 -1.42286506e-03  1.14625538e+01]\n",
      "Loss: 7.335634245974186\n",
      "\n",
      "Iteration: 127\n",
      "P: [ 5.27424898e+00 -1.30662268e+00 -1.65980999e-03  1.14686853e+01]\n",
      "Loss: 7.301366777969208\n",
      "\n",
      "Iteration: 128\n",
      "P: [ 5.27737617e+00 -1.31037571e+00 -1.70464548e-03  1.14698740e+01]\n",
      "Loss: 7.296590527788349\n",
      "\n",
      "Iteration: 129\n",
      "P: [ 5.30485158e+00 -1.34315733e+00 -2.09407889e-03  1.14803882e+01]\n",
      "Loss: 7.205491165235168\n",
      "\n",
      "Iteration: 130\n",
      "P: [ 5.30570442e+00 -1.34416033e+00 -2.10580882e-03  1.14807188e+01]\n",
      "Loss: 7.1720444643239185\n",
      "\n",
      "Iteration: 131\n",
      "P: [ 5.31347434e+00 -1.35340044e+00 -2.21520081e-03  1.14837017e+01]\n",
      "Loss: 7.1420481503024345\n",
      "\n",
      "Iteration: 132\n",
      "P: [ 5.31488156e+00 -1.35507519e+00 -2.23504465e-03  1.14842416e+01]\n",
      "Loss: 7.139051302217766\n",
      "\n",
      "Iteration: 133\n",
      "P: [ 5.31989732e+00 -1.36103698e+00 -2.30558865e-03  1.14861684e+01]\n",
      "Loss: 7.133732042479243\n",
      "\n",
      "Iteration: 134\n",
      "P: [ 5.31925575e+00 -1.36027090e+00 -2.29648435e-03  1.14859234e+01]\n",
      "Loss: 7.124525387608334\n",
      "\n",
      "Iteration: 135\n",
      "P: [ 5.32213718e+00 -1.36369001e+00 -2.33687539e-03  1.14870328e+01]\n",
      "Loss: 7.115428944693211\n",
      "\n",
      "Iteration: 136\n",
      "P: [ 5.32592671e+00 -1.36818843e+00 -2.39003640e-03  1.14884911e+01]\n",
      "Loss: 7.108168214057137\n",
      "\n",
      "Iteration: 137\n",
      "P: [ 5.32628361e+00 -1.36861079e+00 -2.39501179e-03  1.14886290e+01]\n",
      "Loss: 7.10481035490905\n",
      "\n",
      "Iteration: 138\n",
      "P: [ 5.32892892e+00 -1.37174680e+00 -2.43202158e-03  1.14896488e+01]\n",
      "Loss: 7.0975632240619575\n",
      "\n",
      "Iteration: 139\n",
      "P: [ 5.33288097e+00 -1.37642979e+00 -2.48722054e-03  1.14911736e+01]\n",
      "Loss: 7.085197422605531\n",
      "\n",
      "Iteration: 140\n",
      "P: [ 5.33643425e+00 -1.38063958e+00 -2.53681560e-03  1.14925449e+01]\n",
      "Loss: 7.078760083670215\n",
      "\n",
      "Iteration: 141\n",
      "P: [ 5.34091043e+00 -1.38593862e+00 -2.59914486e-03  1.14942746e+01]\n",
      "Loss: 7.0648859814154\n",
      "\n",
      "Iteration: 142\n",
      "P: [ 5.34093366e+00 -1.38596589e+00 -2.59945897e-03  1.14942837e+01]\n",
      "Loss: 7.063902241866785\n",
      "\n",
      "Iteration: 143\n",
      "P: [ 5.34473439e+00 -1.39046438e+00 -2.65233531e-03  1.14957529e+01]\n",
      "Loss: 7.05808852071321\n",
      "\n",
      "Iteration: 144\n",
      "P: [ 5.34476254e+00 -1.39049695e+00 -2.65269366e-03  1.14957642e+01]\n",
      "Loss: 7.053887937208615\n",
      "\n",
      "Iteration: 145\n",
      "P: [ 5.34771437e+00 -1.39398956e+00 -2.69370941e-03  1.14969059e+01]\n",
      "Loss: 7.04880318574444\n",
      "\n",
      "Iteration: 146\n",
      "P: [ 5.34880258e+00 -1.39527661e+00 -2.70880627e-03  1.14973271e+01]\n",
      "Loss: 7.045496764097673\n",
      "\n",
      "Iteration: 147\n",
      "P: [ 5.34926082e+00 -1.39581822e+00 -2.71514509e-03  1.14975047e+01]\n",
      "Loss: 7.042951628191785\n",
      "\n",
      "Iteration: 148\n",
      "P: [ 5.35118327e+00 -1.39809199e+00 -2.74181534e-03  1.14982488e+01]\n",
      "Loss: 7.038987417738969\n",
      "\n",
      "Iteration: 149\n",
      "P: [ 5.35212275e+00 -1.39920303e+00 -2.75484298e-03  1.14986124e+01]\n",
      "Loss: 7.037932066661245\n",
      "\n",
      "Iteration: 150\n",
      "P: [ 5.35306469e+00 -1.40031672e+00 -2.76789150e-03  1.14989772e+01]\n",
      "Loss: 7.035493278486703\n",
      "\n",
      "Iteration: 151\n",
      "P: [ 5.35505004e+00 -1.40266388e+00 -2.79536958e-03  1.14997462e+01]\n",
      "Loss: 7.0293811023696415\n",
      "\n",
      "Iteration: 152\n",
      "P: [ 5.35584074e+00 -1.40359876e+00 -2.80631935e-03  1.15000524e+01]\n",
      "Loss: 7.028202543520487\n",
      "\n",
      "Iteration: 153\n",
      "P: [ 5.35713785e+00 -1.40513221e+00 -2.82426890e-03  1.15005549e+01]\n",
      "Loss: 7.026136702749981\n",
      "\n",
      "Iteration: 154\n",
      "P: [ 5.35857821e+00 -1.40683479e+00 -2.84418393e-03  1.15011129e+01]\n",
      "Loss: 7.022695405900677\n",
      "\n",
      "Iteration: 155\n",
      "P: [ 5.36010236e+00 -1.40863760e+00 -2.86523039e-03  1.15017028e+01]\n",
      "Loss: 7.0181838664829765\n",
      "\n",
      "Iteration: 156\n",
      "P: [ 5.36100051e+00 -1.40969969e+00 -2.87764303e-03  1.15020505e+01]\n",
      "Loss: 7.015907913903925\n",
      "\n",
      "Iteration: 157\n",
      "P: [ 5.36163902e+00 -1.41045480e+00 -2.88646546e-03  1.15022977e+01]\n",
      "Loss: 7.0148057939504005\n",
      "\n",
      "Iteration: 158\n",
      "P: [ 5.36295811e+00 -1.41201490e+00 -2.90468720e-03  1.15028083e+01]\n",
      "Loss: 7.014309788821048\n",
      "\n",
      "Iteration: 159\n",
      "P: [ 5.36256348e+00 -1.41154826e+00 -2.89923258e-03  1.15026555e+01]\n",
      "Loss: 7.013349812557656\n",
      "\n",
      "Iteration: 160\n",
      "P: [ 5.36274925e+00 -1.41176816e+00 -2.90179120e-03  1.15027273e+01]\n",
      "Loss: 7.012191132168223\n",
      "\n",
      "Iteration: 161\n",
      "P: [ 5.36397118e+00 -1.41321389e+00 -2.91865127e-03  1.15032000e+01]\n",
      "Loss: 7.009390642872724\n",
      "\n",
      "Iteration: 162\n",
      "P: [ 5.36471873e+00 -1.41409832e+00 -2.92896740e-03  1.15034892e+01]\n",
      "Loss: 7.007958691680853\n",
      "\n",
      "Iteration: 163\n",
      "P: [ 5.36565206e+00 -1.41520261e+00 -2.94184411e-03  1.15038503e+01]\n",
      "Loss: 7.006712582515549\n",
      "\n",
      "Iteration: 164\n",
      "P: [ 5.36657929e+00 -1.41629986e+00 -2.95463073e-03  1.15042088e+01]\n",
      "Loss: 7.005462677215451\n",
      "\n",
      "Iteration: 165\n",
      "P: [ 5.36754800e+00 -1.41744650e+00 -2.96797892e-03  1.15045833e+01]\n",
      "Loss: 7.002716167248121\n",
      "\n",
      "Iteration: 166\n",
      "P: [ 5.36886577e+00 -1.41900671e+00 -2.98612372e-03  1.15050925e+01]\n",
      "Loss: 6.998969424582608\n",
      "\n",
      "Iteration: 167\n",
      "P: [ 5.36956718e+00 -1.41983699e+00 -2.99578750e-03  1.15053636e+01]\n",
      "Loss: 6.997519023484173\n",
      "\n",
      "Iteration: 168\n",
      "P: [ 5.37031711e+00 -1.42072479e+00 -3.00611730e-03  1.15056534e+01]\n",
      "Loss: 6.996481329215829\n",
      "\n",
      "Iteration: 169\n",
      "P: [ 5.37128080e+00 -1.42186576e+00 -3.01938698e-03  1.15060258e+01]\n",
      "Loss: 6.995630710213264\n",
      "\n",
      "Iteration: 170\n",
      "P: [ 5.37160619e+00 -1.42225117e+00 -3.02386203e-03  1.15061515e+01]\n",
      "Loss: 6.99419672525425\n",
      "\n",
      "Iteration: 171\n",
      "P: [ 5.37324718e+00 -1.42419477e+00 -3.04643341e-03  1.15067851e+01]\n",
      "Loss: 6.990031702705869\n",
      "\n",
      "Iteration: 172\n",
      "P: [ 5.37422633e+00 -1.42535450e+00 -3.05990142e-03  1.15071632e+01]\n",
      "Loss: 6.988625643036412\n",
      "\n",
      "Iteration: 173\n",
      "P: [ 5.37622297e+00 -1.42771990e+00 -3.08734533e-03  1.15079340e+01]\n",
      "Loss: 6.984865264175552\n",
      "\n",
      "Iteration: 174\n",
      "P: [ 5.37667106e+00 -1.42825110e+00 -3.09349364e-03  1.15081067e+01]\n",
      "Loss: 6.982875343147418\n",
      "\n",
      "Iteration: 175\n",
      "P: [ 5.37792647e+00 -1.42973861e+00 -3.11074191e-03  1.15085912e+01]\n",
      "Loss: 6.980735535704865\n",
      "\n",
      "Iteration: 176\n",
      "P: [ 5.37859486e+00 -1.43053066e+00 -3.11992257e-03  1.15088491e+01]\n",
      "Loss: 6.980118043073075\n",
      "\n",
      "Iteration: 177\n",
      "P: [ 5.37919078e+00 -1.43123699e+00 -3.12810258e-03  1.15090789e+01]\n",
      "Loss: 6.97870965182797\n",
      "\n",
      "Iteration: 178\n",
      "P: [ 5.38049066e+00 -1.43277800e+00 -3.14593675e-03  1.15095801e+01]\n",
      "Loss: 6.975276135042206\n",
      "\n",
      "Iteration: 179\n",
      "P: [ 5.38104974e+00 -1.43344070e+00 -3.15361015e-03  1.15097958e+01]\n",
      "Loss: 6.974490612360631\n",
      "\n",
      "Iteration: 180\n",
      "P: [ 5.38181968e+00 -1.43435346e+00 -3.16417360e-03  1.15100926e+01]\n",
      "Loss: 6.973489303500478\n",
      "\n",
      "Iteration: 181\n",
      "P: [ 5.38283501e+00 -1.43555731e+00 -3.17809802e-03  1.15104840e+01]\n",
      "Loss: 6.971894239060673\n",
      "\n",
      "Iteration: 182\n",
      "P: [ 5.38377295e+00 -1.43666972e+00 -3.19095165e-03  1.15108454e+01]\n",
      "Loss: 6.969033339134965\n",
      "\n",
      "Iteration: 183\n",
      "P: [ 5.38471573e+00 -1.43778774e+00 -3.20387549e-03  1.15112087e+01]\n",
      "Loss: 6.967945449325958\n",
      "\n",
      "Iteration: 184\n",
      "P: [ 5.38620008e+00 -1.43954838e+00 -3.22421114e-03  1.15117805e+01]\n",
      "Loss: 6.965416523095338\n",
      "\n",
      "Iteration: 185\n",
      "P: [ 5.38695653e+00 -1.44044614e+00 -3.23455925e-03  1.15120717e+01]\n",
      "Loss: 6.9639746553301975\n",
      "\n",
      "Iteration: 186\n",
      "P: [ 5.38813131e+00 -1.44183977e+00 -3.25064876e-03  1.15125241e+01]\n",
      "Loss: 6.960610546898668\n",
      "\n",
      "Iteration: 187\n",
      "P: [ 5.38847615e+00 -1.44224888e+00 -3.25537080e-03  1.15126569e+01]\n",
      "Loss: 6.960265553111947\n",
      "\n",
      "Iteration: 188\n",
      "P: [ 5.38879472e+00 -1.44262685e+00 -3.25973167e-03  1.15127796e+01]\n",
      "Loss: 6.959930457265437\n",
      "\n",
      "Iteration: 189\n",
      "P: [ 5.38949699e+00 -1.44346018e+00 -3.26934302e-03  1.15130499e+01]\n",
      "Loss: 6.959122664917243\n",
      "\n",
      "Iteration: 190\n",
      "P: [ 5.39006784e+00 -1.44413767e+00 -3.27715219e-03  1.15132696e+01]\n",
      "Loss: 6.957839631074898\n",
      "\n",
      "Iteration: 191\n",
      "P: [ 5.39107878e+00 -1.44533771e+00 -3.29097457e-03  1.15136586e+01]\n",
      "Loss: 6.9550666068757145\n",
      "\n",
      "Iteration: 192\n",
      "P: [ 5.39168332e+00 -1.44605523e+00 -3.29924371e-03  1.15138912e+01]\n",
      "Loss: 6.954183761896333\n",
      "\n",
      "Iteration: 193\n",
      "P: [ 5.39243730e+00 -1.44695020e+00 -3.30955403e-03  1.15141813e+01]\n",
      "Loss: 6.953450215209635\n",
      "\n",
      "Iteration: 194\n",
      "P: [ 5.39292300e+00 -1.44752685e+00 -3.31619253e-03  1.15143681e+01]\n",
      "Loss: 6.952369633732722\n",
      "\n",
      "Iteration: 195\n",
      "P: [ 5.39396204e+00 -1.44876066e+00 -3.33038712e-03  1.15147677e+01]\n",
      "Loss: 6.949781343827835\n",
      "\n",
      "Iteration: 196\n",
      "P: [ 5.39446920e+00 -1.44936282e+00 -3.33731823e-03  1.15149627e+01]\n",
      "Loss: 6.948942597223543\n",
      "\n",
      "Iteration: 197\n",
      "P: [ 5.39510592e+00 -1.45011884e+00 -3.34601800e-03  1.15152076e+01]\n",
      "Loss: 6.948274230706394\n",
      "\n",
      "Iteration: 198\n",
      "P: [ 5.39563022e+00 -1.45074147e+00 -3.35317954e-03  1.15154091e+01]\n",
      "Loss: 6.947582259692016\n",
      "\n",
      "Iteration: 199\n",
      "P: [ 5.39652250e+00 -1.45180125e+00 -3.36536271e-03  1.15157521e+01]\n",
      "Loss: 6.945726870935806\n",
      "\n",
      "Iteration: 200\n",
      "P: [ 5.39737067e+00 -1.45280886e+00 -3.37693767e-03  1.15160780e+01]\n",
      "Loss: 6.943614556423233\n",
      "\n",
      "Iteration: 201\n",
      "P: [ 5.39787505e+00 -1.45340796e+00 -3.38382330e-03  1.15162718e+01]\n",
      "Loss: 6.942815885753904\n",
      "\n",
      "Iteration: 202\n",
      "P: [ 5.39848709e+00 -1.45413500e+00 -3.39217725e-03  1.15165070e+01]\n",
      "Loss: 6.942173757234432\n",
      "\n",
      "Iteration: 203\n",
      "P: [ 5.39905082e+00 -1.45480472e+00 -3.39986949e-03  1.15167236e+01]\n",
      "Loss: 6.941472092773251\n",
      "\n",
      "Iteration: 204\n",
      "P: [ 5.39982519e+00 -1.45572485e+00 -3.41043181e-03  1.15170211e+01]\n",
      "Loss: 6.9397696838140295\n",
      "\n",
      "Iteration: 205\n",
      "P: [ 5.40065230e+00 -1.45670782e+00 -3.42170840e-03  1.15173387e+01]\n",
      "Loss: 6.937792129971887\n",
      "\n",
      "Iteration: 206\n",
      "P: [ 5.40111285e+00 -1.45725509e+00 -3.42798963e-03  1.15175155e+01]\n",
      "Loss: 6.937058948786504\n",
      "\n",
      "Iteration: 207\n",
      "P: [ 5.40170868e+00 -1.45796315e+00 -3.43611438e-03  1.15177444e+01]\n",
      "Loss: 6.936429535366516\n",
      "\n",
      "Iteration: 208\n",
      "P: [ 5.40224846e+00 -1.45860467e+00 -3.44347293e-03  1.15179516e+01]\n",
      "Loss: 6.93580682066552\n",
      "\n",
      "Iteration: 209\n",
      "P: [ 5.40294171e+00 -1.45942872e+00 -3.45291999e-03  1.15182177e+01]\n",
      "Loss: 6.934333498539635\n",
      "\n",
      "Iteration: 210\n",
      "P: [ 5.40374932e+00 -1.46038889e+00 -3.46392072e-03  1.15185276e+01]\n",
      "Loss: 6.932386523181856\n",
      "\n",
      "Iteration: 211\n",
      "P: [ 5.40423296e+00 -1.46096380e+00 -3.47051070e-03  1.15187133e+01]\n",
      "Loss: 6.93164537706914\n",
      "\n",
      "Iteration: 212\n",
      "P: [ 5.40480022e+00 -1.46163817e+00 -3.47823873e-03  1.15189310e+01]\n",
      "Loss: 6.9310818816211786\n",
      "\n",
      "Iteration: 213\n",
      "P: [ 5.40528950e+00 -1.46221990e+00 -3.48490258e-03  1.15191187e+01]\n",
      "Loss: 6.930451367216887\n",
      "\n",
      "Iteration: 214\n",
      "P: [ 5.40609608e+00 -1.46317902e+00 -3.49588423e-03  1.15194281e+01]\n",
      "Loss: 6.9288032890528575\n",
      "\n",
      "Iteration: 215\n",
      "P: [ 5.40685391e+00 -1.46408033e+00 -3.50619766e-03  1.15197187e+01]\n",
      "Loss: 6.9270524349126985\n",
      "\n",
      "Iteration: 216\n",
      "P: [ 5.40728067e+00 -1.46458784e+00 -3.51200743e-03  1.15198824e+01]\n",
      "Loss: 6.926400855119175\n",
      "\n",
      "Iteration: 217\n",
      "P: [ 5.40783206e+00 -1.46524357e+00 -3.51951244e-03  1.15200939e+01]\n",
      "Loss: 6.925833468685679\n",
      "\n",
      "Iteration: 218\n",
      "P: [ 5.40837078e+00 -1.46588431e+00 -3.52684339e-03  1.15203005e+01]\n",
      "Loss: 6.92526426622078\n",
      "\n",
      "Iteration: 219\n",
      "P: [ 5.40894473e+00 -1.46656706e+00 -3.53465082e-03  1.15205206e+01]\n",
      "Loss: 6.923999356967856\n",
      "\n",
      "Iteration: 220\n",
      "P: [ 5.40970350e+00 -1.46746981e+00 -3.54496854e-03  1.15208114e+01]\n",
      "Loss: 6.922235639054809\n",
      "\n",
      "Iteration: 221\n",
      "P: [ 5.41015059e+00 -1.46800165e+00 -3.55104981e-03  1.15209828e+01]\n",
      "Loss: 6.921556457589347\n",
      "\n",
      "Iteration: 222\n",
      "P: [ 5.41067839e+00 -1.46862956e+00 -3.55822794e-03  1.15211851e+01]\n",
      "Loss: 6.921039538631095\n",
      "\n",
      "Iteration: 223\n",
      "P: [ 5.41113537e+00 -1.46917327e+00 -3.56444135e-03  1.15213602e+01]\n",
      "Loss: 6.920499693614803\n",
      "\n",
      "Iteration: 224\n",
      "P: [ 5.41184433e+00 -1.47001690e+00 -3.57407794e-03  1.15216319e+01]\n",
      "Loss: 6.919132204978354\n",
      "\n",
      "Iteration: 225\n",
      "P: [ 5.41256403e+00 -1.47087344e+00 -3.58385634e-03  1.15219076e+01]\n",
      "Loss: 6.917459855304246\n",
      "\n",
      "Iteration: 226\n",
      "P: [ 5.41300954e+00 -1.47140360e+00 -3.58991125e-03  1.15220783e+01]\n",
      "Loss: 6.916829138091314\n",
      "\n",
      "Iteration: 227\n",
      "P: [ 5.41357332e+00 -1.47207454e+00 -3.59757219e-03  1.15222942e+01]\n",
      "Loss: 6.9163150329834835\n",
      "\n",
      "Iteration: 228\n",
      "P: [ 5.41399766e+00 -1.47257960e+00 -3.60333674e-03  1.15224568e+01]\n",
      "Loss: 6.915707232994446\n",
      "\n",
      "Iteration: 229\n",
      "P: [ 5.41481998e+00 -1.47355849e+00 -3.61450414e-03  1.15227717e+01]\n",
      "Loss: 6.913931452842853\n",
      "\n",
      "Iteration: 230\n",
      "P: [ 5.41571024e+00 -1.47461828e+00 -3.62659313e-03  1.15231126e+01]\n",
      "Loss: 6.912660925156192\n",
      "\n",
      "Iteration: 231\n",
      "P: [ 5.41715913e+00 -1.47634343e+00 -3.64625822e-03  1.15236672e+01]\n",
      "Loss: 6.909943857749218\n",
      "\n",
      "Iteration: 232\n",
      "P: [ 5.41742920e+00 -1.47666497e+00 -3.64992450e-03  1.15237705e+01]\n",
      "Loss: 6.909599767086687\n",
      "\n",
      "Iteration: 233\n",
      "P: [ 5.41823634e+00 -1.47762605e+00 -3.66087846e-03  1.15240795e+01]\n",
      "Loss: 6.9090814106021305\n",
      "\n",
      "Iteration: 234\n",
      "P: [ 5.41826746e+00 -1.47766315e+00 -3.66129917e-03  1.15240914e+01]\n",
      "Loss: 6.908427453530041\n",
      "\n",
      "Iteration: 235\n",
      "P: [ 5.41921472e+00 -1.47879131e+00 -3.67414821e-03  1.15244538e+01]\n",
      "Loss: 6.9067165417113605\n",
      "\n",
      "Iteration: 236\n",
      "P: [ 5.41969894e+00 -1.47936801e+00 -3.68071637e-03  1.15246391e+01]\n",
      "Loss: 6.906167291064295\n",
      "\n",
      "Iteration: 237\n",
      "P: [ 5.42048165e+00 -1.48030030e+00 -3.69133022e-03  1.15249385e+01]\n",
      "Loss: 6.90505330575607\n",
      "\n",
      "Iteration: 238\n",
      "P: [ 5.42124947e+00 -1.48121503e+00 -3.70173813e-03  1.15252321e+01]\n",
      "Loss: 6.903399637821767\n",
      "\n",
      "Iteration: 239\n",
      "P: [ 5.42160478e+00 -1.48163828e+00 -3.70655529e-03  1.15253680e+01]\n",
      "Loss: 6.903042305561026\n",
      "\n",
      "Iteration: 240\n",
      "P: [ 5.42264893e+00 -1.48288222e+00 -3.72070828e-03  1.15257673e+01]\n",
      "Loss: 6.902492434547438\n",
      "\n",
      "Iteration: 241\n",
      "P: [ 5.42251355e+00 -1.48272103e+00 -3.71887090e-03  1.15257155e+01]\n",
      "Loss: 6.901454531260569\n",
      "\n",
      "Iteration: 242\n",
      "P: [ 5.42310478e+00 -1.48342553e+00 -3.72688154e-03  1.15259415e+01]\n",
      "Loss: 6.900456282397355\n",
      "\n",
      "Iteration: 243\n",
      "P: [ 5.42350272e+00 -1.48389967e+00 -3.73227349e-03  1.15260937e+01]\n",
      "Loss: 6.899954516924495\n",
      "\n",
      "Iteration: 244\n",
      "P: [ 5.42408774e+00 -1.48459679e+00 -3.74019941e-03  1.15263173e+01]\n",
      "Loss: 6.899434650582654\n",
      "\n",
      "Iteration: 245\n",
      "P: [ 5.42448152e+00 -1.48506607e+00 -3.74553270e-03  1.15264678e+01]\n",
      "Loss: 6.898759444560748\n",
      "\n",
      "Iteration: 246\n",
      "P: [ 5.42521138e+00 -1.48593603e+00 -3.75541454e-03  1.15267467e+01]\n",
      "Loss: 6.897157108521455\n",
      "\n",
      "Iteration: 247\n",
      "P: [ 5.42561101e+00 -1.48641232e+00 -3.76082649e-03  1.15268994e+01]\n",
      "Loss: 6.89662247575791\n",
      "\n",
      "Iteration: 248\n",
      "P: [ 5.42609415e+00 -1.48698818e+00 -3.76736859e-03  1.15270840e+01]\n",
      "Loss: 6.896221937027303\n",
      "\n",
      "Iteration: 249\n",
      "P: [ 5.42645712e+00 -1.48742085e+00 -3.77228224e-03  1.15272227e+01]\n",
      "Loss: 6.895740289755775\n",
      "\n",
      "Iteration: 250\n",
      "P: [ 5.42717562e+00 -1.48827743e+00 -3.78200617e-03  1.15274971e+01]\n",
      "Loss: 6.894294578591303\n",
      "\n",
      "Iteration: 251\n",
      "P: [ 5.42790746e+00 -1.48914997e+00 -3.79190951e-03  1.15277766e+01]\n",
      "Loss: 6.89313060062403\n",
      "\n",
      "Iteration: 252\n",
      "P: [ 5.42886885e+00 -1.49029637e+00 -3.80491465e-03  1.15281437e+01]\n",
      "Loss: 6.89156647904326\n",
      "\n",
      "Iteration: 253\n",
      "P: [ 5.42948723e+00 -1.49103370e+00 -3.81328083e-03  1.15283798e+01]\n",
      "Loss: 6.890806360854757\n",
      "\n",
      "Iteration: 254\n",
      "P: [ 5.42988990e+00 -1.49151388e+00 -3.81872733e-03  1.15285336e+01]\n",
      "Loss: 6.890496519063826\n",
      "\n",
      "Iteration: 255\n",
      "P: [ 5.43031585e+00 -1.49202189e+00 -3.82448688e-03  1.15286962e+01]\n",
      "Loss: 6.8896703570369064\n",
      "\n",
      "Iteration: 256\n",
      "P: [ 5.43095543e+00 -1.49278480e+00 -3.83313285e-03  1.15289402e+01]\n",
      "Loss: 6.888331193630661\n",
      "\n",
      "Iteration: 257\n",
      "P: [ 5.43132349e+00 -1.49322378e+00 -3.83810945e-03  1.15290807e+01]\n",
      "Loss: 6.887837554576161\n",
      "\n",
      "Iteration: 258\n",
      "P: [ 5.43176503e+00 -1.49375043e+00 -3.84407881e-03  1.15292492e+01]\n",
      "Loss: 6.887461439612585\n",
      "\n",
      "Iteration: 259\n",
      "P: [ 5.43212815e+00 -1.49418359e+00 -3.84898708e-03  1.15293878e+01]\n",
      "Loss: 6.887050874516092\n",
      "\n",
      "Iteration: 260\n",
      "P: [ 5.43274123e+00 -1.49491499e+00 -3.85727187e-03  1.15296217e+01]\n",
      "Loss: 6.885939095902385\n",
      "\n",
      "Iteration: 261\n",
      "P: [ 5.43333032e+00 -1.49561787e+00 -3.86523030e-03  1.15298464e+01]\n",
      "Loss: 6.884746327253297\n",
      "\n",
      "Iteration: 262\n",
      "P: [ 5.43366518e+00 -1.49601738e+00 -3.86975504e-03  1.15299741e+01]\n",
      "Loss: 6.884316324258926\n",
      "\n",
      "Iteration: 263\n",
      "P: [ 5.43414416e+00 -1.49658886e+00 -3.87622644e-03  1.15301568e+01]\n",
      "Loss: 6.8839112415085655\n",
      "\n",
      "Iteration: 264\n",
      "P: [ 5.43449363e+00 -1.49700586e+00 -3.88094708e-03  1.15302901e+01]\n",
      "Loss: 6.8834720848020075\n",
      "\n",
      "Iteration: 265\n",
      "P: [ 5.43516306e+00 -1.49780474e+00 -3.88998733e-03  1.15305454e+01]\n",
      "Loss: 6.882182233942316\n",
      "\n",
      "Iteration: 266\n",
      "P: [ 5.43583518e+00 -1.49860688e+00 -3.89906283e-03  1.15308017e+01]\n",
      "Loss: 6.881114683118356\n",
      "\n",
      "Iteration: 267\n",
      "P: [ 5.43675507e+00 -1.49970483e+00 -3.91148145e-03  1.15311523e+01]\n",
      "Loss: 6.879724821907468\n",
      "\n",
      "Iteration: 268\n",
      "P: [ 5.43778153e+00 -1.50093015e+00 -3.92533310e-03  1.15315435e+01]\n",
      "Loss: 6.878698394984663\n",
      "\n",
      "Iteration: 269\n",
      "P: [ 5.43838915e+00 -1.50165547e+00 -3.93353337e-03  1.15317751e+01]\n",
      "Loss: 6.877267862849547\n",
      "\n",
      "Iteration: 270\n",
      "P: [ 5.43874895e+00 -1.50208496e+00 -3.93838894e-03  1.15319123e+01]\n",
      "Loss: 6.876879465950815\n",
      "\n",
      "Iteration: 271\n",
      "P: [ 5.43889563e+00 -1.50226008e+00 -3.94036813e-03  1.15319682e+01]\n",
      "Loss: 6.87675105783447\n",
      "\n",
      "Iteration: 272\n",
      "P: [ 5.43943386e+00 -1.50290265e+00 -3.94762934e-03  1.15321733e+01]\n",
      "Loss: 6.876290488922458\n",
      "\n",
      "Iteration: 273\n",
      "P: [ 5.43968724e+00 -1.50320519e+00 -3.95104662e-03  1.15322698e+01]\n",
      "Loss: 6.875706997519041\n",
      "\n",
      "Iteration: 274\n",
      "P: [ 5.44028811e+00 -1.50392272e+00 -3.95914891e-03  1.15324987e+01]\n",
      "Loss: 6.874487619545111\n",
      "\n",
      "Iteration: 275\n",
      "P: [ 5.44061607e+00 -1.50431430e+00 -3.96357201e-03  1.15326236e+01]\n",
      "Loss: 6.874030958498969\n",
      "\n",
      "Iteration: 276\n",
      "P: [ 5.44101629e+00 -1.50479219e+00 -3.96896941e-03  1.15327761e+01]\n",
      "Loss: 6.873684482757891\n",
      "\n",
      "Iteration: 277\n",
      "P: [ 5.44133732e+00 -1.50517555e+00 -3.97329809e-03  1.15328983e+01]\n",
      "Loss: 6.873388060074171\n",
      "\n",
      "Iteration: 278\n",
      "P: [ 5.44180551e+00 -1.50573469e+00 -3.97960971e-03  1.15330767e+01]\n",
      "Loss: 6.872656156438713\n",
      "\n",
      "Iteration: 279\n",
      "P: [ 5.44238828e+00 -1.50643074e+00 -3.98746385e-03  1.15332986e+01]\n",
      "Loss: 6.871450374649293\n",
      "\n",
      "Iteration: 280\n",
      "P: [ 5.44278132e+00 -1.50690015e+00 -3.99276192e-03  1.15334482e+01]\n",
      "Loss: 6.871093327054563\n",
      "\n",
      "Iteration: 281\n",
      "P: [ 5.44363259e+00 -1.50791691e+00 -4.00423449e-03  1.15337724e+01]\n",
      "Loss: 6.870707990272079\n",
      "\n",
      "Iteration: 282\n",
      "P: [ 5.44353628e+00 -1.50780194e+00 -4.00293481e-03  1.15337357e+01]\n",
      "Loss: 6.8698435903610235\n",
      "\n",
      "Iteration: 283\n",
      "P: [ 5.44409813e+00 -1.50847311e+00 -4.01050444e-03  1.15339495e+01]\n",
      "Loss: 6.868994625873524\n",
      "\n",
      "Iteration: 284\n",
      "P: [ 5.44446432e+00 -1.50891053e+00 -4.01543814e-03  1.15340889e+01]\n",
      "Loss: 6.868620660148657\n",
      "\n",
      "Iteration: 285\n",
      "P: [ 5.44491702e+00 -1.50945134e+00 -4.02153665e-03  1.15342613e+01]\n",
      "Loss: 6.868196402474444\n",
      "\n",
      "Iteration: 286\n",
      "P: [ 5.44540718e+00 -1.51003694e+00 -4.02813818e-03  1.15344478e+01]\n",
      "Loss: 6.867472999606931\n",
      "\n",
      "Iteration: 287\n",
      "P: [ 5.44597317e+00 -1.51071332e+00 -4.03575886e-03  1.15346631e+01]\n",
      "Loss: 6.866319960384956\n",
      "\n",
      "Iteration: 288\n",
      "P: [ 5.44636937e+00 -1.51118672e+00 -4.04109437e-03  1.15348139e+01]\n",
      "Loss: 6.865856626906484\n",
      "\n",
      "Iteration: 289\n",
      "P: [ 5.44676018e+00 -1.51165373e+00 -4.04635680e-03  1.15349626e+01]\n",
      "Loss: 6.865584228906273\n",
      "\n",
      "Iteration: 290\n",
      "P: [ 5.44702193e+00 -1.51196656e+00 -4.04988059e-03  1.15350621e+01]\n",
      "Loss: 6.865185887808327\n",
      "\n",
      "Iteration: 291\n",
      "P: [ 5.44768956e+00 -1.51276459e+00 -4.05886655e-03  1.15353160e+01]\n",
      "Loss: 6.863915865412961\n",
      "\n",
      "Iteration: 292\n",
      "P: [ 5.44805517e+00 -1.51320157e+00 -4.06378807e-03  1.15354551e+01]\n",
      "Loss: 6.863622978465005\n",
      "\n",
      "Iteration: 293\n",
      "P: [ 5.44877158e+00 -1.51405797e+00 -4.07342970e-03  1.15357275e+01]\n",
      "Loss: 6.862971819182425\n",
      "\n",
      "Iteration: 294\n",
      "P: [ 5.44905879e+00 -1.51440144e+00 -4.07729296e-03  1.15358366e+01]\n",
      "Loss: 6.861997938616682\n",
      "\n",
      "Iteration: 295\n",
      "P: [ 5.44951997e+00 -1.51495282e+00 -4.08349835e-03  1.15360119e+01]\n",
      "Loss: 6.861479636937743\n",
      "\n",
      "Iteration: 296\n",
      "P: [ 5.45010270e+00 -1.51564959e+00 -4.09133831e-03  1.15362334e+01]\n",
      "Loss: 6.860986958654733\n",
      "\n",
      "Iteration: 297\n",
      "P: [ 5.45046182e+00 -1.51607909e+00 -4.09616824e-03  1.15363698e+01]\n",
      "Loss: 6.860172415016566\n",
      "\n",
      "Iteration: 298\n",
      "P: [ 5.45117453e+00 -1.51693146e+00 -4.10575374e-03  1.15366406e+01]\n",
      "Loss: 6.859237656182063\n",
      "\n",
      "Iteration: 299\n",
      "P: [ 5.45197815e+00 -1.51789285e+00 -4.11655758e-03  1.15369457e+01]\n",
      "Loss: 6.858664949268963\n",
      "\n",
      "Iteration: 300\n",
      "P: [ 5.45272862e+00 -1.51879055e+00 -4.12664847e-03  1.15372308e+01]\n",
      "Loss: 6.8568852768480575\n",
      "\n",
      "Iteration: 301\n",
      "P: [ 5.45284611e+00 -1.51893109e+00 -4.12822812e-03  1.15372754e+01]\n",
      "Loss: 6.856783632363401\n",
      "\n",
      "Iteration: 302\n",
      "P: [ 5.45300026e+00 -1.51911550e+00 -4.13030068e-03  1.15373339e+01]\n",
      "Loss: 6.856699545571351\n",
      "\n",
      "Iteration: 303\n",
      "P: [ 5.45313187e+00 -1.51927295e+00 -4.13206995e-03  1.15373839e+01]\n",
      "Loss: 6.856614112189844\n",
      "\n",
      "Iteration: 304\n",
      "P: [ 5.45339991e+00 -1.51959365e+00 -4.13567292e-03  1.15374857e+01]\n",
      "Loss: 6.856376110882802\n",
      "\n",
      "Iteration: 305\n",
      "P: [ 5.45378829e+00 -1.52005838e+00 -4.14089289e-03  1.15376331e+01]\n",
      "Loss: 6.855906490023868\n",
      "\n",
      "Iteration: 306\n",
      "P: [ 5.45424742e+00 -1.52060784e+00 -4.14706242e-03  1.15378073e+01]\n",
      "Loss: 6.855000248804849\n",
      "\n",
      "Iteration: 307\n",
      "P: [ 5.45480926e+00 -1.52128030e+00 -4.15461117e-03  1.15380205e+01]\n",
      "Loss: 6.854036628274312\n",
      "\n",
      "Iteration: 308\n",
      "P: [ 5.45511239e+00 -1.52164308e+00 -4.15868444e-03  1.15381355e+01]\n",
      "Loss: 6.853789127860878\n",
      "\n",
      "Iteration: 309\n",
      "P: [ 5.45578485e+00 -1.52244796e+00 -4.16771884e-03  1.15383907e+01]\n",
      "Loss: 6.853265578371226\n",
      "\n",
      "Iteration: 310\n",
      "P: [ 5.45599766e+00 -1.52270279e+00 -4.17057651e-03  1.15384713e+01]\n",
      "Loss: 6.852507591807987\n",
      "\n",
      "Iteration: 311\n",
      "P: [ 5.45654319e+00 -1.52335587e+00 -4.17790399e-03  1.15386783e+01]\n",
      "Loss: 6.851912079609838\n",
      "\n",
      "Iteration: 312\n",
      "P: [ 5.45735220e+00 -1.52432453e+00 -4.18876827e-03  1.15389850e+01]\n",
      "Loss: 6.8508580536540595\n",
      "\n",
      "Iteration: 313\n",
      "P: [ 5.45758248e+00 -1.52460038e+00 -4.19185908e-03  1.15390723e+01]\n",
      "Loss: 6.850276073560237\n",
      "\n",
      "Iteration: 314\n",
      "P: [ 5.45815402e+00 -1.52528479e+00 -4.19953336e-03  1.15392889e+01]\n",
      "Loss: 6.8496026095413045\n",
      "\n",
      "Iteration: 315\n",
      "P: [ 5.45844703e+00 -1.52563569e+00 -4.20346742e-03  1.15394000e+01]\n",
      "Loss: 6.849437822686993\n",
      "\n",
      "Iteration: 316\n",
      "P: [ 5.45866146e+00 -1.52589253e+00 -4.20634583e-03  1.15394813e+01]\n",
      "Loss: 6.849118475458246\n",
      "\n",
      "Iteration: 317\n",
      "P: [ 5.45931557e+00 -1.52667614e+00 -4.21512490e-03  1.15397291e+01]\n",
      "Loss: 6.8479711706455175\n",
      "\n",
      "Iteration: 318\n",
      "P: [ 5.45972791e+00 -1.52717008e+00 -4.22065947e-03  1.15398853e+01]\n",
      "Loss: 6.847673433942945\n",
      "\n",
      "Iteration: 319\n",
      "P: [ 5.46046014e+00 -1.52804740e+00 -4.23048537e-03  1.15401626e+01]\n",
      "Loss: 6.846833894573963\n",
      "\n",
      "Iteration: 320\n",
      "P: [ 5.46083108e+00 -1.52849206e+00 -4.23546066e-03  1.15403030e+01]\n",
      "Loss: 6.84604506534795\n",
      "\n",
      "Iteration: 321\n",
      "P: [ 5.46141707e+00 -1.52919425e+00 -4.24332305e-03  1.15405249e+01]\n",
      "Loss: 6.845205394054392\n",
      "\n",
      "Iteration: 322\n",
      "P: [ 5.46165524e+00 -1.52947967e+00 -4.24651836e-03  1.15406150e+01]\n",
      "Loss: 6.8450929635502336\n",
      "\n",
      "Iteration: 323\n",
      "P: [ 5.46182105e+00 -1.52967841e+00 -4.24874258e-03  1.15406778e+01]\n",
      "Loss: 6.84490440602326\n",
      "\n",
      "Iteration: 324\n",
      "P: [ 5.46245674e+00 -1.53044042e+00 -4.25726864e-03  1.15409184e+01]\n",
      "Loss: 6.844036863931602\n",
      "\n",
      "Iteration: 325\n",
      "P: [ 5.46290866e+00 -1.53098235e+00 -4.26332852e-03  1.15410893e+01]\n",
      "Loss: 6.843158883449986\n",
      "\n",
      "Iteration: 326\n",
      "P: [ 5.46330451e+00 -1.53145695e+00 -4.26863733e-03  1.15412390e+01]\n",
      "Loss: 6.842835601257189\n",
      "\n",
      "Iteration: 327\n",
      "P: [ 5.46400845e+00 -1.53230111e+00 -4.27807672e-03  1.15415053e+01]\n",
      "Loss: 6.842481495026108\n",
      "\n",
      "Iteration: 328\n",
      "P: [ 5.46400264e+00 -1.53229429e+00 -4.27799764e-03  1.15415030e+01]\n",
      "Loss: 6.841776153340629\n",
      "\n",
      "Iteration: 329\n",
      "P: [ 5.46460036e+00 -1.53301132e+00 -4.28601036e-03  1.15417289e+01]\n",
      "Loss: 6.840931667260321\n",
      "\n",
      "Iteration: 330\n",
      "P: [ 5.46494039e+00 -1.53341921e+00 -4.29056893e-03  1.15418574e+01]\n",
      "Loss: 6.840652464148497\n",
      "\n",
      "Iteration: 331\n",
      "P: [ 5.46561436e+00 -1.53422784e+00 -4.29960309e-03  1.15421121e+01]\n",
      "Loss: 6.840215794001874\n",
      "\n",
      "Iteration: 332\n",
      "P: [ 5.46570999e+00 -1.53434272e+00 -4.30088375e-03  1.15421481e+01]\n",
      "Loss: 6.83954807223393\n",
      "\n",
      "Iteration: 333\n",
      "P: [ 5.46643731e+00 -1.53521566e+00 -4.31063057e-03  1.15424228e+01]\n",
      "Loss: 6.83863282780127\n",
      "\n",
      "Iteration: 334\n",
      "P: [ 5.46729252e+00 -1.53624229e+00 -4.32208985e-03  1.15427456e+01]\n",
      "Loss: 6.837876866240592\n",
      "\n",
      "Iteration: 335\n",
      "P: [ 5.46787452e+00 -1.53694138e+00 -4.32988498e-03  1.15429651e+01]\n",
      "Loss: 6.836873460770519\n",
      "\n",
      "Iteration: 336\n",
      "P: [ 5.46850332e+00 -1.53769644e+00 -4.33830858e-03  1.15432024e+01]\n",
      "Loss: 6.835947893288855\n",
      "\n",
      "Iteration: 337\n",
      "P: [ 5.46869818e+00 -1.53793046e+00 -4.34091889e-03  1.15432759e+01]\n",
      "Loss: 6.835876894151279\n",
      "\n",
      "Iteration: 338\n",
      "P: [ 5.46880715e+00 -1.53806137e+00 -4.34237830e-03  1.15433170e+01]\n",
      "Loss: 6.835715690114136\n",
      "\n",
      "Iteration: 339\n",
      "P: [ 5.46953279e+00 -1.53893320e+00 -4.35209562e-03  1.15435905e+01]\n",
      "Loss: 6.834605080203486\n",
      "\n",
      "Iteration: 340\n",
      "P: [ 5.47014003e+00 -1.53966288e+00 -4.36022686e-03  1.15438193e+01]\n",
      "Loss: 6.833893350158176\n",
      "\n",
      "Iteration: 341\n",
      "P: [ 5.47117599e+00 -1.54090821e+00 -4.37409511e-03  1.15442095e+01]\n",
      "Loss: 6.832453203131183\n",
      "\n",
      "Iteration: 342\n",
      "P: [ 5.47151365e+00 -1.54131405e+00 -4.37861558e-03  1.15443367e+01]\n",
      "Loss: 6.832055295981271\n",
      "\n",
      "Iteration: 343\n",
      "P: [ 5.47179406e+00 -1.54165116e+00 -4.38236930e-03  1.15444423e+01]\n",
      "Loss: 6.831900307712652\n",
      "\n",
      "Iteration: 344\n",
      "P: [ 5.47202716e+00 -1.54193143e+00 -4.38548929e-03  1.15445300e+01]\n",
      "Loss: 6.831681796037366\n",
      "\n",
      "Iteration: 345\n",
      "P: [ 5.47250659e+00 -1.54250801e+00 -4.39190536e-03  1.15447104e+01]\n",
      "Loss: 6.830991148917803\n",
      "\n",
      "Iteration: 346\n",
      "P: [ 5.47301195e+00 -1.54311597e+00 -4.39866723e-03  1.15449005e+01]\n",
      "Loss: 6.830064928155591\n",
      "\n",
      "Iteration: 347\n",
      "P: [ 5.47337777e+00 -1.54355596e+00 -4.40356261e-03  1.15450382e+01]\n",
      "Loss: 6.829753743772548\n",
      "\n",
      "Iteration: 348\n",
      "P: [ 5.47408002e+00 -1.54440076e+00 -4.41295907e-03  1.15453023e+01]\n",
      "Loss: 6.8294901297947375\n",
      "\n",
      "Iteration: 349\n",
      "P: [ 5.47398352e+00 -1.54428478e+00 -4.41166700e-03  1.15452659e+01]\n",
      "Loss: 6.828961890493623\n",
      "\n",
      "Iteration: 350\n",
      "P: [ 5.47437509e+00 -1.54475611e+00 -4.41690453e-03  1.15454131e+01]\n",
      "Loss: 6.828433763615956\n",
      "\n",
      "Iteration: 351\n",
      "P: [ 5.47497048e+00 -1.54547258e+00 -4.42486936e-03  1.15456369e+01]\n",
      "Loss: 6.82764969085086\n",
      "\n",
      "Iteration: 352\n",
      "P: [ 5.47523792e+00 -1.54579444e+00 -4.42844698e-03  1.15457374e+01]\n",
      "Loss: 6.8275380932604515\n",
      "\n",
      "Iteration: 353\n",
      "P: [ 5.47533833e+00 -1.54591532e+00 -4.42978992e-03  1.15457751e+01]\n",
      "Loss: 6.827406897972365\n",
      "\n",
      "Iteration: 354\n",
      "P: [ 5.47606141e+00 -1.54678602e+00 -4.43946004e-03  1.15460467e+01]\n",
      "Loss: 6.826343728715165\n",
      "\n",
      "Iteration: 355\n",
      "P: [ 5.47658296e+00 -1.54741424e+00 -4.44643395e-03  1.15462424e+01]\n",
      "Loss: 6.8255709186957905\n",
      "\n",
      "Iteration: 356\n",
      "P: [ 5.47676470e+00 -1.54763311e+00 -4.44886429e-03  1.15463106e+01]\n",
      "Loss: 6.8254253829179445\n",
      "\n",
      "Iteration: 357\n",
      "P: [ 5.47766644e+00 -1.54871937e+00 -4.46092157e-03  1.15466490e+01]\n",
      "Loss: 6.82498573564331\n",
      "\n",
      "Iteration: 358\n",
      "P: [ 5.47752482e+00 -1.54854893e+00 -4.45902720e-03  1.15465958e+01]\n",
      "Loss: 6.824450074851875\n",
      "\n",
      "Iteration: 359\n",
      "P: [ 5.47791945e+00 -1.54902460e+00 -4.46430226e-03  1.15467437e+01]\n",
      "Loss: 6.823911123156548\n",
      "\n",
      "Iteration: 360\n",
      "P: [ 5.47825631e+00 -1.54943056e+00 -4.46880555e-03  1.15468700e+01]\n",
      "Loss: 6.82347205477619\n",
      "\n",
      "Iteration: 361\n",
      "P: [ 5.47839705e+00 -1.54960018e+00 -4.47068701e-03  1.15469228e+01]\n",
      "Loss: 6.823327100729192\n",
      "\n",
      "Iteration: 362\n",
      "P: [ 5.47880129e+00 -1.55008740e+00 -4.47609083e-03  1.15470743e+01]\n",
      "Loss: 6.82309537229082\n",
      "\n",
      "Iteration: 363\n",
      "P: [ 5.47907270e+00 -1.55041468e+00 -4.47971820e-03  1.15471760e+01]\n",
      "Loss: 6.822656274851845\n",
      "\n",
      "Iteration: 364\n",
      "P: [ 5.47970559e+00 -1.55117810e+00 -4.48817573e-03  1.15474129e+01]\n",
      "Loss: 6.821686393776123\n",
      "\n",
      "Iteration: 365\n",
      "P: [ 5.48015079e+00 -1.55171499e+00 -4.49412567e-03  1.15475797e+01]\n",
      "Loss: 6.821251625202036\n",
      "\n",
      "Iteration: 366\n",
      "P: [ 5.48059662e+00 -1.55225277e+00 -4.50008341e-03  1.15477466e+01]\n",
      "Loss: 6.821033006617663\n",
      "\n",
      "Iteration: 367\n",
      "P: [ 5.48071319e+00 -1.55239348e+00 -4.50164069e-03  1.15477902e+01]\n",
      "Loss: 6.820704587148676\n",
      "\n",
      "Iteration: 368\n",
      "P: [ 5.48136890e+00 -1.55318506e+00 -4.51040003e-03  1.15480353e+01]\n",
      "Loss: 6.819772563097115\n",
      "\n",
      "Iteration: 369\n",
      "P: [ 5.48182594e+00 -1.55373665e+00 -4.51650625e-03  1.15482063e+01]\n",
      "Loss: 6.819062347629914\n",
      "\n",
      "Iteration: 370\n",
      "P: [ 5.48210972e+00 -1.55407918e+00 -4.52029745e-03  1.15483124e+01]\n",
      "Loss: 6.818884980539676\n",
      "\n",
      "Iteration: 371\n",
      "P: [ 5.48225686e+00 -1.55425680e+00 -4.52226299e-03  1.15483674e+01]\n",
      "Loss: 6.818790347170836\n",
      "\n",
      "Iteration: 372\n",
      "P: [ 5.48261488e+00 -1.55468909e+00 -4.52704536e-03  1.15485012e+01]\n",
      "Loss: 6.818510508741444\n",
      "\n",
      "Iteration: 373\n",
      "P: [ 5.48294835e+00 -1.55509185e+00 -4.53149912e-03  1.15486258e+01]\n",
      "Loss: 6.818062792450338\n",
      "\n",
      "Iteration: 374\n",
      "P: [ 5.48353743e+00 -1.55580370e+00 -4.53936567e-03  1.15488456e+01]\n",
      "Loss: 6.816965719991343\n",
      "\n",
      "Iteration: 375\n",
      "P: [ 5.48400787e+00 -1.55637204e+00 -4.54564846e-03  1.15490213e+01]\n",
      "Loss: 6.816655977327224\n",
      "\n",
      "Iteration: 376\n",
      "P: [ 5.48462192e+00 -1.55711423e+00 -4.55384788e-03  1.15492504e+01]\n",
      "Loss: 6.815991254068715\n",
      "\n",
      "Iteration: 377\n",
      "P: [ 5.48509596e+00 -1.55768771e+00 -4.56017619e-03  1.15494269e+01]\n",
      "Loss: 6.815077609539243\n",
      "\n",
      "Iteration: 378\n",
      "P: [ 5.48537170e+00 -1.55802111e+00 -4.56385779e-03  1.15495297e+01]\n",
      "Loss: 6.81471676808725\n",
      "\n",
      "Iteration: 379\n",
      "P: [ 5.48570656e+00 -1.55842604e+00 -4.56832854e-03  1.15496546e+01]\n",
      "Loss: 6.814426434374316\n",
      "\n",
      "Iteration: 380\n",
      "P: [ 5.48618496e+00 -1.55900463e+00 -4.57471556e-03  1.15498328e+01]\n",
      "Loss: 6.814283584003498\n",
      "\n",
      "Iteration: 381\n",
      "P: [ 5.48610169e+00 -1.55890398e+00 -4.57360361e-03  1.15498018e+01]\n",
      "Loss: 6.814138494263064\n",
      "\n",
      "Iteration: 382\n",
      "P: [ 5.48611328e+00 -1.55891815e+00 -4.57375780e-03  1.15498060e+01]\n",
      "Loss: 6.81385730812177\n",
      "\n",
      "Iteration: 383\n",
      "P: [ 5.48640118e+00 -1.55926669e+00 -4.57760045e-03  1.15499131e+01]\n",
      "Loss: 6.813534657749928\n",
      "\n",
      "Iteration: 384\n",
      "P: [ 5.48721632e+00 -1.56025306e+00 -4.58848141e-03  1.15502166e+01]\n",
      "Loss: 6.812757796989999\n",
      "\n",
      "Iteration: 385\n",
      "P: [ 5.48741194e+00 -1.56048984e+00 -4.59109254e-03  1.15502894e+01]\n",
      "Loss: 6.812694066818408\n",
      "\n",
      "Iteration: 386\n",
      "P: [ 5.48755344e+00 -1.56066122e+00 -4.59298088e-03  1.15503420e+01]\n",
      "Loss: 6.8124308607748105\n",
      "\n",
      "Iteration: 387\n",
      "P: [ 5.48828128e+00 -1.56154316e+00 -4.60269298e-03  1.15506123e+01]\n",
      "Loss: 6.8113242865627965\n",
      "\n",
      "Iteration: 388\n",
      "P: [ 5.48881567e+00 -1.56219043e+00 -4.60982440e-03  1.15508110e+01]\n",
      "Loss: 6.810622019397389\n",
      "\n",
      "Iteration: 389\n",
      "P: [ 5.48913009e+00 -1.56257135e+00 -4.61402013e-03  1.15509278e+01]\n",
      "Loss: 6.810475344282054\n",
      "\n",
      "Iteration: 390\n",
      "P: [ 5.48924681e+00 -1.56271281e+00 -4.61557763e-03  1.15509711e+01]\n",
      "Loss: 6.810369006071695\n",
      "\n",
      "Iteration: 391\n",
      "P: [ 5.48992756e+00 -1.56353809e+00 -4.62466024e-03  1.15512237e+01]\n",
      "Loss: 6.809652815337821\n",
      "\n",
      "Iteration: 392\n",
      "P: [ 5.49038744e+00 -1.56409612e+00 -4.63079516e-03  1.15513941e+01]\n",
      "Loss: 6.808808451236295\n",
      "\n",
      "Iteration: 393\n",
      "P: [ 5.49108886e+00 -1.56494752e+00 -4.64015162e-03  1.15516539e+01]\n",
      "Loss: 6.807855430460352\n",
      "\n",
      "Iteration: 394\n",
      "P: [ 5.49150964e+00 -1.56545812e+00 -4.64576490e-03  1.15518098e+01]\n",
      "Loss: 6.807420227994995\n",
      "\n",
      "Iteration: 395\n",
      "P: [ 5.49217529e+00 -1.56626609e+00 -4.65464425e-03  1.15520562e+01]\n",
      "Loss: 6.807210784530986\n",
      "\n",
      "Iteration: 396\n",
      "P: [ 5.49197886e+00 -1.56602778e+00 -4.65202383e-03  1.15519834e+01]\n",
      "Loss: 6.807009049473064\n",
      "\n",
      "Iteration: 397\n",
      "P: [ 5.49207567e+00 -1.56614553e+00 -4.65331475e-03  1.15520192e+01]\n",
      "Loss: 6.806716340700444\n",
      "\n",
      "Iteration: 398\n",
      "P: [ 5.49278489e+00 -1.56700738e+00 -4.66277343e-03  1.15522813e+01]\n",
      "Loss: 6.805854305379533\n",
      "\n",
      "Iteration: 399\n",
      "P: [ 5.49333737e+00 -1.56767864e+00 -4.67014189e-03  1.15524855e+01]\n",
      "Loss: 6.805271762322259\n",
      "\n",
      "Iteration: 400\n",
      "P: [ 5.49360439e+00 -1.56800313e+00 -4.67370296e-03  1.15525841e+01]\n",
      "Loss: 6.805125668585512\n",
      "\n",
      "Iteration: 401\n",
      "P: [ 5.49388217e+00 -1.56834079e+00 -4.67740759e-03  1.15526868e+01]\n",
      "Loss: 6.805004272398121\n",
      "\n",
      "Iteration: 402\n",
      "P: [ 5.49403841e+00 -1.56853086e+00 -4.67949086e-03  1.15527444e+01]\n",
      "Loss: 6.804762908274413\n",
      "\n",
      "Iteration: 403\n",
      "P: [ 5.49476412e+00 -1.56941408e+00 -4.68916728e-03  1.15530118e+01]\n",
      "Loss: 6.803629271310569\n",
      "\n",
      "Iteration: 404\n",
      "P: [ 5.49546727e+00 -1.57027020e+00 -4.69854234e-03  1.15532708e+01]\n",
      "Loss: 6.802704864490891\n",
      "\n",
      "Iteration: 405\n",
      "P: [ 5.49657366e+00 -1.57161782e+00 -4.71329295e-03  1.15536780e+01]\n",
      "Loss: 6.801605674674599\n",
      "\n",
      "Iteration: 406\n",
      "P: [ 5.49679417e+00 -1.57188688e+00 -4.71623217e-03  1.15537589e+01]\n",
      "Loss: 6.801137774693605\n",
      "\n",
      "Iteration: 407\n",
      "P: [ 5.49721622e+00 -1.57240134e+00 -4.72185856e-03  1.15539140e+01]\n",
      "Loss: 6.800723967969144\n",
      "\n",
      "Iteration: 408\n",
      "P: [ 5.49801778e+00 -1.57337897e+00 -4.73254340e-03  1.15542083e+01]\n",
      "Loss: 6.799888518084155\n",
      "\n",
      "Iteration: 409\n",
      "P: [ 5.49917260e+00 -1.57478827e+00 -4.74793456e-03  1.15546318e+01]\n",
      "Loss: 6.798576824066681\n",
      "\n",
      "Iteration: 410\n",
      "P: [ 5.49934338e+00 -1.57499659e+00 -4.75020904e-03  1.15546945e+01]\n",
      "Loss: 6.798168709491898\n",
      "\n",
      "Iteration: 411\n",
      "P: [ 5.49976147e+00 -1.57550660e+00 -4.75577983e-03  1.15548480e+01]\n",
      "Loss: 6.797733068642636\n",
      "\n",
      "Iteration: 412\n",
      "P: [ 5.50009381e+00 -1.57591192e+00 -4.76020759e-03  1.15549700e+01]\n",
      "Loss: 6.7974040524527295\n",
      "\n",
      "Iteration: 413\n",
      "P: [ 5.50057730e+00 -1.57650153e+00 -4.76664817e-03  1.15551475e+01]\n",
      "Loss: 6.796904486764829\n",
      "\n",
      "Iteration: 414\n",
      "P: [ 5.50129224e+00 -1.57737329e+00 -4.77616989e-03  1.15554101e+01]\n",
      "Loss: 6.796095792382001\n",
      "\n",
      "Iteration: 415\n",
      "P: [ 5.50235942e+00 -1.57867437e+00 -4.79037894e-03  1.15558022e+01]\n",
      "Loss: 6.794748549876288\n",
      "\n",
      "Iteration: 416\n",
      "P: [ 5.50257410e+00 -1.57893610e+00 -4.79323733e-03  1.15558811e+01]\n",
      "Loss: 6.794579919270037\n",
      "\n",
      "Iteration: 417\n",
      "P: [ 5.50284221e+00 -1.57926294e+00 -4.79680633e-03  1.15559796e+01]\n",
      "Loss: 6.79425788959862\n",
      "\n",
      "Iteration: 418\n",
      "P: [ 5.50317550e+00 -1.57966921e+00 -4.80124264e-03  1.15561021e+01]\n",
      "Loss: 6.79387073990382\n",
      "\n",
      "Iteration: 419\n",
      "P: [ 5.50363963e+00 -1.58023497e+00 -4.80741993e-03  1.15562727e+01]\n",
      "Loss: 6.793316792531712\n",
      "\n",
      "Iteration: 420\n",
      "P: [ 5.50467233e+00 -1.58149375e+00 -4.82116282e-03  1.15566523e+01]\n",
      "Loss: 6.792529724700637\n",
      "\n",
      "Iteration: 421\n",
      "P: [ 5.50584790e+00 -1.58292644e+00 -4.83680005e-03  1.15570844e+01]\n",
      "Loss: 6.790652881684182\n",
      "\n",
      "Iteration: 422\n",
      "P: [ 5.50591283e+00 -1.58300559e+00 -4.83766400e-03  1.15571083e+01]\n",
      "Loss: 6.790592083715161\n",
      "\n",
      "Iteration: 423\n",
      "P: [ 5.50620808e+00 -1.58336541e+00 -4.84159139e-03  1.15572169e+01]\n",
      "Loss: 6.790369938905712\n",
      "\n",
      "Iteration: 424\n",
      "P: [ 5.50666554e+00 -1.58392290e+00 -4.84767568e-03  1.15573851e+01]\n",
      "Loss: 6.790102943284953\n",
      "\n",
      "Iteration: 425\n",
      "P: [ 5.50703416e+00 -1.58437207e+00 -4.85257704e-03  1.15575206e+01]\n",
      "Loss: 6.789437452307133\n",
      "\n",
      "Iteration: 426\n",
      "P: [ 5.50732184e+00 -1.58472261e+00 -4.85640176e-03  1.15576264e+01]\n",
      "Loss: 6.788967529479229\n",
      "\n",
      "Iteration: 427\n",
      "P: [ 5.50750801e+00 -1.58494946e+00 -4.85887713e-03  1.15576949e+01]\n",
      "Loss: 6.788792925731159\n",
      "\n",
      "Iteration: 428\n",
      "P: [ 5.50785628e+00 -1.58537382e+00 -4.86350761e-03  1.15578230e+01]\n",
      "Loss: 6.788493138770779\n",
      "\n",
      "Iteration: 429\n",
      "P: [ 5.50843059e+00 -1.58607358e+00 -4.87114240e-03  1.15580342e+01]\n",
      "Loss: 6.788113063886409\n",
      "\n",
      "Iteration: 430\n",
      "P: [ 5.50861946e+00 -1.58630366e+00 -4.87365184e-03  1.15581037e+01]\n",
      "Loss: 6.787447530195571\n",
      "\n",
      "Iteration: 431\n",
      "P: [ 5.50886778e+00 -1.58660620e+00 -4.87695235e-03  1.15581951e+01]\n",
      "Loss: 6.787180718902507\n",
      "\n",
      "Iteration: 432\n",
      "P: [ 5.50907924e+00 -1.58686382e+00 -4.87976288e-03  1.15582728e+01]\n",
      "Loss: 6.786980138511054\n",
      "\n",
      "Iteration: 433\n",
      "P: [ 5.50946216e+00 -1.58733034e+00 -4.88485197e-03  1.15584137e+01]\n",
      "Loss: 6.786699263949846\n",
      "\n",
      "Iteration: 434\n",
      "P: [ 5.50978301e+00 -1.58772121e+00 -4.88911546e-03  1.15585318e+01]\n",
      "Loss: 6.786311124031336\n",
      "\n",
      "Iteration: 435\n",
      "P: [ 5.51019153e+00 -1.58821882e+00 -4.89454251e-03  1.15586821e+01]\n",
      "Loss: 6.7856136700145075\n",
      "\n",
      "Iteration: 436\n",
      "P: [ 5.51038867e+00 -1.58845898e+00 -4.89716198e-03  1.15587546e+01]\n",
      "Loss: 6.785405937162675\n",
      "\n",
      "Iteration: 437\n",
      "P: [ 5.51052443e+00 -1.58862435e+00 -4.89896561e-03  1.15588046e+01]\n",
      "Loss: 6.785277379114368\n",
      "\n",
      "Iteration: 438\n",
      "P: [ 5.51080622e+00 -1.58896761e+00 -4.90270940e-03  1.15589083e+01]\n",
      "Loss: 6.785060524254698\n",
      "\n",
      "Iteration: 439\n",
      "P: [ 5.51123951e+00 -1.58949538e+00 -4.90846525e-03  1.15590677e+01]\n",
      "Loss: 6.784891070064055\n",
      "\n",
      "Iteration: 440\n",
      "P: [ 5.51124470e+00 -1.58950168e+00 -4.90853362e-03  1.15590696e+01]\n",
      "Loss: 6.7844792310164035\n",
      "\n",
      "Iteration: 441\n",
      "P: [ 5.51180954e+00 -1.59018964e+00 -4.91603559e-03  1.15592775e+01]\n",
      "Loss: 6.783883793330353\n",
      "\n",
      "Iteration: 442\n",
      "P: [ 5.51230455e+00 -1.59079251e+00 -4.92260932e-03  1.15594597e+01]\n",
      "Loss: 6.783492635248713\n",
      "\n",
      "Iteration: 443\n",
      "P: [ 5.51275515e+00 -1.59134123e+00 -4.92859160e-03  1.15596256e+01]\n",
      "Loss: 6.782658585663461\n",
      "\n",
      "Iteration: 444\n",
      "P: [ 5.51289855e+00 -1.59151587e+00 -4.93049575e-03  1.15596784e+01]\n",
      "Loss: 6.782523118124324\n",
      "\n",
      "Iteration: 445\n",
      "P: [ 5.51316403e+00 -1.59183917e+00 -4.93402056e-03  1.15597762e+01]\n",
      "Loss: 6.782312130295057\n",
      "\n",
      "Iteration: 446\n",
      "P: [ 5.51341193e+00 -1.59214105e+00 -4.93731170e-03  1.15598674e+01]\n",
      "Loss: 6.782128709417341\n",
      "\n",
      "Iteration: 447\n",
      "P: [ 5.51380202e+00 -1.59261605e+00 -4.94248981e-03  1.15600111e+01]\n",
      "Loss: 6.781705283575847\n",
      "\n",
      "Iteration: 448\n",
      "P: [ 5.51411929e+00 -1.59300233e+00 -4.94670022e-03  1.15601279e+01]\n",
      "Loss: 6.7810924469208596\n",
      "\n",
      "Iteration: 449\n",
      "P: [ 5.51443970e+00 -1.59339247e+00 -4.95095309e-03  1.15602459e+01]\n",
      "Loss: 6.780822330371139\n",
      "\n",
      "Iteration: 450\n",
      "P: [ 5.51493519e+00 -1.59399576e+00 -4.95752890e-03  1.15604284e+01]\n",
      "Loss: 6.780631528198687\n",
      "\n",
      "Iteration: 451\n",
      "P: [ 5.51502065e+00 -1.59409977e+00 -4.95866214e-03  1.15604599e+01]\n",
      "Loss: 6.78008955498934\n",
      "\n",
      "Iteration: 452\n",
      "P: [ 5.51568411e+00 -1.59490751e+00 -4.96746561e-03  1.15607043e+01]\n",
      "Loss: 6.779662660270897\n",
      "\n",
      "Iteration: 453\n",
      "P: [ 5.51579225e+00 -1.59503914e+00 -4.96889980e-03  1.15607441e+01]\n",
      "Loss: 6.779215201561597\n",
      "\n",
      "Iteration: 454\n",
      "P: [ 5.51637378e+00 -1.59574705e+00 -4.97661446e-03  1.15609583e+01]\n",
      "Loss: 6.7788004063380045\n",
      "\n",
      "Iteration: 455\n",
      "P: [ 5.51655844e+00 -1.59597182e+00 -4.97906344e-03  1.15610264e+01]\n",
      "Loss: 6.778336817247563\n",
      "\n",
      "Iteration: 456\n",
      "P: [ 5.51683249e+00 -1.59630540e+00 -4.98269844e-03  1.15611273e+01]\n",
      "Loss: 6.778115574552388\n",
      "\n",
      "Iteration: 457\n",
      "P: [ 5.51714343e+00 -1.59668388e+00 -4.98682238e-03  1.15612419e+01]\n",
      "Loss: 6.777833401345919\n",
      "\n",
      "Iteration: 458\n",
      "P: [ 5.51752858e+00 -1.59715266e+00 -4.99192969e-03  1.15613839e+01]\n",
      "Loss: 6.777246278718446\n",
      "\n",
      "Iteration: 459\n",
      "P: [ 5.51785708e+00 -1.59755248e+00 -4.99628583e-03  1.15615049e+01]\n",
      "Loss: 6.777017410767488\n",
      "\n",
      "Iteration: 460\n",
      "P: [ 5.51825414e+00 -1.59803572e+00 -5.00155036e-03  1.15616512e+01]\n",
      "Loss: 6.7765453792323544\n",
      "\n",
      "Iteration: 461\n",
      "P: [ 5.51853679e+00 -1.59837967e+00 -5.00529673e-03  1.15617554e+01]\n",
      "Loss: 6.776067245431084\n",
      "\n",
      "Iteration: 462\n",
      "P: [ 5.51887808e+00 -1.59879502e+00 -5.00982143e-03  1.15618812e+01]\n",
      "Loss: 6.775652291982045\n",
      "\n",
      "Iteration: 463\n",
      "P: [ 5.51904360e+00 -1.59899646e+00 -5.01201572e-03  1.15619422e+01]\n",
      "Loss: 6.775527112264201\n",
      "\n",
      "Iteration: 464\n",
      "P: [ 5.51906765e+00 -1.59902571e+00 -5.01233433e-03  1.15619511e+01]\n",
      "Loss: 6.775463233809087\n",
      "\n",
      "Iteration: 465\n",
      "P: [ 5.51935274e+00 -1.59937265e+00 -5.01611326e-03  1.15620562e+01]\n",
      "Loss: 6.775154411227714\n",
      "\n",
      "Iteration: 466\n",
      "P: [ 5.51965388e+00 -1.59973909e+00 -5.02010468e-03  1.15621672e+01]\n",
      "Loss: 6.774908799254508\n",
      "\n",
      "Iteration: 467\n",
      "P: [ 5.51999326e+00 -1.60015204e+00 -5.02460223e-03  1.15622923e+01]\n",
      "Loss: 6.774507589442168\n",
      "\n",
      "Iteration: 468\n",
      "P: [ 5.52038874e+00 -1.60063323e+00 -5.02984245e-03  1.15624382e+01]\n",
      "Loss: 6.773933738310375\n",
      "\n",
      "Iteration: 469\n",
      "P: [ 5.52048894e+00 -1.60075515e+00 -5.03117028e-03  1.15624751e+01]\n",
      "Loss: 6.773836613563835\n",
      "\n",
      "Iteration: 470\n",
      "P: [ 5.52075519e+00 -1.60107910e+00 -5.03469825e-03  1.15625733e+01]\n",
      "Loss: 6.773622395625515\n",
      "\n",
      "Iteration: 471\n",
      "P: [ 5.52102867e+00 -1.60141185e+00 -5.03832175e-03  1.15626741e+01]\n",
      "Loss: 6.773401641926802\n",
      "\n",
      "Iteration: 472\n",
      "P: [ 5.52136967e+00 -1.60182671e+00 -5.04283915e-03  1.15627999e+01]\n",
      "Loss: 6.772938172037216\n",
      "\n",
      "Iteration: 473\n",
      "P: [ 5.52169628e+00 -1.60222404e+00 -5.04716527e-03  1.15629204e+01]\n",
      "Loss: 6.7724618097756055\n",
      "\n",
      "Iteration: 474\n",
      "P: [ 5.52178865e+00 -1.60233643e+00 -5.04838903e-03  1.15629544e+01]\n",
      "Loss: 6.772377215552548\n",
      "\n",
      "Iteration: 475\n",
      "P: [ 5.52206042e+00 -1.60266704e+00 -5.05198883e-03  1.15630547e+01]\n",
      "Loss: 6.772152799376399\n",
      "\n",
      "Iteration: 476\n",
      "P: [ 5.52225752e+00 -1.60290682e+00 -5.05459948e-03  1.15631274e+01]\n",
      "Loss: 6.7720038349482365\n",
      "\n",
      "Iteration: 477\n",
      "P: [ 5.52256783e+00 -1.60328430e+00 -5.05870909e-03  1.15632418e+01]\n",
      "Loss: 6.771620891547623\n",
      "\n",
      "Iteration: 478\n",
      "P: [ 5.52289702e+00 -1.60368471e+00 -5.06306800e-03  1.15633633e+01]\n",
      "Loss: 6.771114310137675\n",
      "\n",
      "Iteration: 479\n",
      "P: [ 5.52306381e+00 -1.60388760e+00 -5.06527677e-03  1.15634248e+01]\n",
      "Loss: 6.770979680310501\n",
      "\n",
      "Iteration: 480\n",
      "P: [ 5.52332406e+00 -1.60420416e+00 -5.06872289e-03  1.15635208e+01]\n",
      "Loss: 6.770758753650497\n",
      "\n",
      "Iteration: 481\n",
      "P: [ 5.52387093e+00 -1.60486934e+00 -5.07596364e-03  1.15637226e+01]\n",
      "Loss: 6.770543818341269\n",
      "\n",
      "Iteration: 482\n",
      "P: [ 5.52384408e+00 -1.60483665e+00 -5.07560735e-03  1.15637127e+01]\n",
      "Loss: 6.770038166435461\n",
      "\n",
      "Iteration: 483\n",
      "P: [ 5.52427197e+00 -1.60535708e+00 -5.08127201e-03  1.15638705e+01]\n",
      "Loss: 6.7696197251517045\n",
      "\n",
      "Iteration: 484\n",
      "P: [ 5.52447380e+00 -1.60560256e+00 -5.08394385e-03  1.15639450e+01]\n",
      "Loss: 6.769478203249192\n",
      "\n",
      "Iteration: 485\n",
      "P: [ 5.52470991e+00 -1.60588971e+00 -5.08706891e-03  1.15640322e+01]\n",
      "Loss: 6.769132943908918\n",
      "\n",
      "Iteration: 486\n",
      "P: [ 5.52494197e+00 -1.60617192e+00 -5.09014032e-03  1.15641178e+01]\n",
      "Loss: 6.768920047452333\n",
      "\n",
      "Iteration: 487\n",
      "P: [ 5.52560783e+00 -1.60698168e+00 -5.09895241e-03  1.15643635e+01]\n",
      "Loss: 6.768300415833183\n",
      "\n",
      "Iteration: 488\n",
      "P: [ 5.52581578e+00 -1.60723451e+00 -5.10170288e-03  1.15644403e+01]\n",
      "Loss: 6.768019796418204\n",
      "\n",
      "Iteration: 489\n",
      "P: [ 5.52630438e+00 -1.60782867e+00 -5.10816847e-03  1.15646206e+01]\n",
      "Loss: 6.767347221397767\n",
      "\n",
      "Iteration: 490\n",
      "P: [ 5.52635051e+00 -1.60788477e+00 -5.10877891e-03  1.15646377e+01]\n",
      "Loss: 6.7673298811999345\n",
      "\n",
      "Iteration: 491\n",
      "P: [ 5.52653538e+00 -1.60810957e+00 -5.11122480e-03  1.15647059e+01]\n",
      "Loss: 6.7671580987594755\n",
      "\n",
      "Iteration: 492\n",
      "P: [ 5.52697724e+00 -1.60864684e+00 -5.11707026e-03  1.15648690e+01]\n",
      "Loss: 6.76682024248453\n",
      "\n",
      "Iteration: 493\n",
      "P: [ 5.52711696e+00 -1.60881670e+00 -5.11891791e-03  1.15649206e+01]\n",
      "Loss: 6.766393081974988\n",
      "\n",
      "Iteration: 494\n",
      "P: [ 5.52731964e+00 -1.60906313e+00 -5.12159893e-03  1.15649955e+01]\n",
      "Loss: 6.766190869553368\n",
      "\n",
      "Iteration: 495\n",
      "P: [ 5.52756240e+00 -1.60935829e+00 -5.12480990e-03  1.15650851e+01]\n",
      "Loss: 6.765997136412746\n",
      "\n",
      "Iteration: 496\n",
      "P: [ 5.52801396e+00 -1.60990730e+00 -5.13078228e-03  1.15652518e+01]\n",
      "Loss: 6.765846572342395\n",
      "\n",
      "Iteration: 497\n",
      "P: [ 5.52790520e+00 -1.60977505e+00 -5.12934334e-03  1.15652117e+01]\n",
      "Loss: 6.7655140733487675\n",
      "\n",
      "Iteration: 498\n",
      "P: [ 5.52842449e+00 -1.61040637e+00 -5.13621064e-03  1.15654034e+01]\n",
      "Loss: 6.765109624890038\n",
      "\n",
      "Iteration: 499\n",
      "P: [ 5.52849989e+00 -1.61049803e+00 -5.13720752e-03  1.15654313e+01]\n",
      "Loss: 6.764884747087725\n",
      "\n",
      "Iteration: 500\n",
      "P: [ 5.52885152e+00 -1.61092550e+00 -5.14185704e-03  1.15655611e+01]\n",
      "Loss: 6.764600661643501\n",
      "\n",
      "Iteration: 501\n",
      "P: [ 5.52919748e+00 -1.61134605e+00 -5.14643095e-03  1.15656889e+01]\n",
      "Loss: 6.7642519771206215\n",
      "\n",
      "Iteration: 502\n",
      "P: [ 5.52949531e+00 -1.61170807e+00 -5.15036762e-03  1.15657989e+01]\n",
      "Loss: 6.76377235155209\n",
      "\n",
      "Iteration: 503\n",
      "P: [ 5.52968530e+00 -1.61193902e+00 -5.15287937e-03  1.15658691e+01]\n",
      "Loss: 6.7635376461700325\n",
      "\n",
      "Iteration: 504\n",
      "P: [ 5.52989079e+00 -1.61218880e+00 -5.15559581e-03  1.15659450e+01]\n",
      "Loss: 6.763380417789348\n",
      "\n",
      "Iteration: 505\n",
      "P: [ 5.52998097e+00 -1.61229842e+00 -5.15678777e-03  1.15659783e+01]\n",
      "Loss: 6.763288314570173\n",
      "\n",
      "Iteration: 506\n",
      "P: [ 5.53059466e+00 -1.61304434e+00 -5.16489907e-03  1.15662050e+01]\n",
      "Loss: 6.762925277789261\n",
      "\n",
      "Iteration: 507\n",
      "P: [ 5.53062666e+00 -1.61308322e+00 -5.16532130e-03  1.15662168e+01]\n",
      "Loss: 6.762508915747315\n",
      "\n",
      "Iteration: 508\n",
      "P: [ 5.53115019e+00 -1.61371953e+00 -5.17224016e-03  1.15664102e+01]\n",
      "Loss: 6.762131814129027\n",
      "\n",
      "Iteration: 509\n",
      "P: [ 5.53111491e+00 -1.61367663e+00 -5.17177355e-03  1.15663972e+01]\n",
      "Loss: 6.761977682908765\n",
      "\n",
      "Iteration: 510\n",
      "P: [ 5.53133739e+00 -1.61394702e+00 -5.17471324e-03  1.15664794e+01]\n",
      "Loss: 6.761723368907208\n",
      "\n",
      "Iteration: 511\n",
      "P: [ 5.53144433e+00 -1.61407699e+00 -5.17612630e-03  1.15665189e+01]\n",
      "Loss: 6.7616172566570265\n",
      "\n",
      "Iteration: 512\n",
      "P: [ 5.53154881e+00 -1.61420398e+00 -5.17750685e-03  1.15665575e+01]\n",
      "Loss: 6.761516182744819\n",
      "\n",
      "Iteration: 513\n",
      "P: [ 5.53183518e+00 -1.61455199e+00 -5.18129041e-03  1.15666633e+01]\n",
      "Loss: 6.761301264729873\n",
      "\n",
      "Iteration: 514\n",
      "P: [ 5.53204712e+00 -1.61480956e+00 -5.18409039e-03  1.15667416e+01]\n",
      "Loss: 6.761094911735849\n",
      "\n",
      "Iteration: 515\n",
      "P: [ 5.53239583e+00 -1.61523331e+00 -5.18869672e-03  1.15668705e+01]\n",
      "Loss: 6.760580743777604\n",
      "\n",
      "Iteration: 516\n",
      "P: [ 5.53257081e+00 -1.61544595e+00 -5.19100821e-03  1.15669351e+01]\n",
      "Loss: 6.76046607232584\n",
      "\n",
      "Iteration: 517\n",
      "P: [ 5.53290813e+00 -1.61585585e+00 -5.19546370e-03  1.15670598e+01]\n",
      "Loss: 6.760110990222051\n",
      "\n",
      "Iteration: 518\n",
      "P: [ 5.53324484e+00 -1.61626498e+00 -5.19991042e-03  1.15671843e+01]\n",
      "Loss: 6.759635458443343\n",
      "\n",
      "Iteration: 519\n",
      "P: [ 5.53334362e+00 -1.61638501e+00 -5.20121508e-03  1.15672208e+01]\n",
      "Loss: 6.75955672683291\n",
      "\n",
      "Iteration: 520\n",
      "P: [ 5.53347511e+00 -1.61654477e+00 -5.20295141e-03  1.15672694e+01]\n",
      "Loss: 6.759392159748779\n",
      "\n",
      "Iteration: 521\n",
      "P: [ 5.53366616e+00 -1.61677691e+00 -5.20547441e-03  1.15673400e+01]\n",
      "Loss: 6.759225983249455\n",
      "\n",
      "Iteration: 522\n",
      "P: [ 5.53397896e+00 -1.61715697e+00 -5.20960502e-03  1.15674556e+01]\n",
      "Loss: 6.758989900393549\n",
      "\n",
      "Iteration: 523\n",
      "P: [ 5.53417047e+00 -1.61738964e+00 -5.21213339e-03  1.15675264e+01]\n",
      "Loss: 6.758650939399258\n",
      "\n",
      "Iteration: 524\n",
      "P: [ 5.53429937e+00 -1.61754625e+00 -5.21383541e-03  1.15675741e+01]\n",
      "Loss: 6.758550383196793\n",
      "\n",
      "Iteration: 525\n",
      "P: [ 5.53465557e+00 -1.61797901e+00 -5.21853813e-03  1.15677058e+01]\n",
      "Loss: 6.758210053170973\n",
      "\n",
      "Iteration: 526\n",
      "P: [ 5.53499680e+00 -1.61839355e+00 -5.22304266e-03  1.15678319e+01]\n",
      "Loss: 6.7577766526176\n",
      "\n",
      "Iteration: 527\n",
      "P: [ 5.53526641e+00 -1.61872108e+00 -5.22660134e-03  1.15679316e+01]\n",
      "Loss: 6.757424557209614\n",
      "\n",
      "Iteration: 528\n",
      "P: [ 5.53535519e+00 -1.61882893e+00 -5.22777325e-03  1.15679644e+01]\n",
      "Loss: 6.757338286709105\n",
      "\n",
      "Iteration: 529\n",
      "P: [ 5.53547915e+00 -1.61897951e+00 -5.22940945e-03  1.15680103e+01]\n",
      "Loss: 6.7572268157146675\n",
      "\n",
      "Iteration: 530\n",
      "P: [ 5.53569700e+00 -1.61924416e+00 -5.23228493e-03  1.15680908e+01]\n",
      "Loss: 6.75708097796482\n",
      "\n",
      "Iteration: 531\n",
      "P: [ 5.53597408e+00 -1.61958075e+00 -5.23594202e-03  1.15681933e+01]\n",
      "Loss: 6.756964430570403\n",
      "\n",
      "Iteration: 532\n",
      "P: [ 5.53608782e+00 -1.61971891e+00 -5.23744284e-03  1.15682353e+01]\n",
      "Loss: 6.756644452254942\n",
      "\n",
      "Iteration: 533\n",
      "P: [ 5.53620860e+00 -1.61986560e+00 -5.23903639e-03  1.15682800e+01]\n",
      "Loss: 6.756402630469288\n",
      "\n",
      "Iteration: 534\n",
      "P: [ 5.53620860e+00 -1.61986560e+00 -5.23903638e-03  1.15682800e+01]\n",
      "Loss: 6.756402366151355\n",
      "\n",
      "Iteration: 535\n",
      "P: [ 5.53620860e+00 -1.61986560e+00 -5.23903636e-03  1.15682800e+01]\n",
      "Loss: 6.75640196635104\n",
      "\n",
      "Iteration: 536\n",
      "P: [ 5.53620860e+00 -1.61986560e+00 -5.23903636e-03  1.15682800e+01]\n",
      "Loss: 6.756401965104201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train policy\n",
    "initial_state = jnp.array([0, 0, np.pi, 0])\n",
    "sigma = jnp.array([10, 8, 4, 10])\n",
    "# sigma = jnp.array([5.8, 5.8, 1.5, 8.5])  # Example sigma values\n",
    "num_steps = 50\n",
    "target = jnp.array([0, 0, 0, 0])\n",
    "max_force = 10\n",
    "\n",
    "initial_p = jnp.array([5, 5, 5, 5])  # initial policy parameters for upright initial starting position\n",
    "\n",
    "model_x_prime = jnp.array(non_linear_model_sin_force_down['X_prime'])\n",
    "model_sigma = jnp.array(non_linear_model_sin_force_down['sigma'])\n",
    "model_alpha = jnp.array(non_linear_model_sin_force_down['alpha'])\n",
    "\n",
    "@jax.jit\n",
    "def kernel_expanded_jax(X, X_prime, sigma):\n",
    "    # create new X where 2 additional dimensions are added, replacing the angle with sin and cos\n",
    "    # angle dimension is removed\n",
    "    X_new = jnp.hstack((X[:,0:2], jnp.sin(X[:, 2:3]), jnp.cos(X[:, 2:3]), X[:, 3:]))  # (N, D+1)\n",
    "    X_prime_new = jnp.hstack((X_prime[:,0:2], jnp.sin(X_prime[:, 2:3]), jnp.cos(X_prime[:, 2:3]), X_prime[:, 3:]))  # (M, D+1)\n",
    "\n",
    "    X_e = jnp.expand_dims(X_new, axis=1)  # (N, 1, D+1)\n",
    "    X_prime_e = jnp.expand_dims(X_prime_new, axis=0)  # (1, M, D+1)\n",
    "\n",
    "    diff = X_e - X_prime_e  # (N, M, D+1)\n",
    "    scaled_squared_diff = (diff ** 2)/(2 * sigma ** 2) # (N, M, D+1)\n",
    "\n",
    "    K = jnp.exp(-jnp.sum(scaled_squared_diff, axis=-1))  # (N, M)\n",
    "    return K\n",
    "\n",
    "@jax.jit\n",
    "def loss_policy_jax(state, target, sigma):\n",
    "    delta = (state - target) / sigma\n",
    "    exponent = 0.5 * jnp.dot(delta, delta)\n",
    "    return 1 - jnp.exp(-exponent)\n",
    "\n",
    "@jax.jit\n",
    "def loss_rollout_linear_jax(P):\n",
    "    def scan_step_jax(state, _):\n",
    "        force = P @ state\n",
    "        force = max_force * jnp.tanh(force/max_force)\n",
    "\n",
    "        # add force as the last element to the state\n",
    "        current_state = jnp.concatenate([state, jnp.array([force])])\n",
    "        K = kernel_expanded_jax(jnp.expand_dims(current_state, axis=0), model_x_prime, model_sigma)\n",
    "        Y_pred = K @ model_alpha\n",
    "        next_state = jnp.ravel(current_state[:-1] + Y_pred)\n",
    "\n",
    "        loss = loss_policy_jax(next_state, target, sigma)\n",
    "        return next_state, loss\n",
    "\n",
    "    init_loss = loss_policy_jax(initial_state, target, sigma)\n",
    "    _, losses = jax.lax.scan(scan_step_jax, initial_state, None, length=num_steps)\n",
    "    return init_loss + losses.sum()\n",
    "\n",
    "grad_loss_linear_jax = jax.grad(loss_rollout_linear_jax)\n",
    "\n",
    "losses = [loss_rollout_linear_jax(initial_p)]\n",
    "print(\"Initial loss:\", losses[0])\n",
    "\n",
    "def callback(intermediate_result):\n",
    "    print(\"Iteration:\", len(losses))\n",
    "    print(\"P:\", intermediate_result.x)\n",
    "    print(\"Loss:\", intermediate_result.fun)\n",
    "    print()\n",
    "    losses.append(intermediate_result.fun)\n",
    "\n",
    "res = scipy.optimize.minimize(loss_rollout_linear_jax, x0=initial_p, method='L-BFGS-B', jac=grad_loss_linear_jax, callback=callback, bounds=[(-20, 20)] * 2 + [(-30, 30)] + [(-20, 20)]) \n",
    "\n",
    "def rollout_linear_force(initial_state, num_steps, P, max_force):\n",
    "    X_forecast = [initial_state.copy()]\n",
    "    \n",
    "    state = initial_state.copy()\n",
    "    for step in range(num_steps):\n",
    "        force = P @ state\n",
    "        force = max_force * np.tanh(force/max_force)\n",
    "        # add force as the last element to the state\n",
    "        current_state = jnp.concatenate([state, jnp.array([force])])\n",
    "        K = kernel_expanded_jax(jnp.expand_dims(current_state, axis=0), model_x_prime, model_sigma)\n",
    "\n",
    "        Y_pred = K @ model_alpha\n",
    "        state = jnp.ravel(current_state[:-1] + Y_pred)\n",
    "\n",
    "        remapped_state = state.copy()\n",
    "        # remap jax angle to be between -pi and pi PURELY FOR PLOTTING\n",
    "        remapped_state = np.array([remapped_state[0], remapped_state[1], remap_angle2(remapped_state[2]), remapped_state[3]])\n",
    "        X_forecast.append(remapped_state)\n",
    "\n",
    "    return np.array(X_forecast)\n",
    "\n",
    "P = res.x  # optimised policy matrix\n",
    "X = rollout_linear_force(initial_state=initial_state, num_steps=25, P=P, max_force=max_force)\n",
    "plot_policy(X, target, f\"Rollout Policy, initial_state: {initial_state}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
